1
00:00:00,217 --> 00:00:06,963
这次讲座

2
00:00:06,963 --> 00:00:11,480
是关于为文本聚类生成概率模型

3
00:00:13,860 --> 00:00:17,730
这次讲座 我们会继续讨论文本聚类

4
00:00:17,730 --> 00:00:21,740
和介绍生成概率模型

5
00:00:21,740 --> 00:00:25,770
来做文本聚类

6
00:00:25,770 --> 00:00:30,720
因此 这就是为了覆盖文本聚类的整个计划

7
00:00:30,720 --> 00:00:34,893
在过去的讲座
我们曾讨论什么是文本聚类

8
00:00:34,893 --> 00:00:37,062
以及为什么文本聚类很有趣

9
00:00:37,062 --> 00:00:40,607
这个讲座 我们会讨论如何做文本聚类

10
00:00:40,607 --> 00:00:44,707
一般而言 如你所见 这里有两种方法

11
00:00:44,707 --> 00:00:49,660
第一个是生成概率模型 也就是我们这节课的主题

12
00:00:49,660 --> 00:00:52,259
稍后 我们会讨论以相似度为基础的方法

13
00:00:53,840 --> 00:00:58,530
所以 来讨论为文本聚类生成的模型

14
00:00:58,530 --> 00:01:03,460
用这个主题模型来回顾文本挖掘的问题 

15
00:01:03,460 --> 00:01:08,900
会很有帮助
因为这两个问题很相似

16
00:01:08,900 --> 00:01:15,089
这个课件你曾在先前那个主题模型讲座看过

17
00:01:15,089 --> 00:01:19,827
这里我们会展示我们如何输入文本集合C

18
00:01:19,827 --> 00:01:23,334
和一系列主题K 和单词表V

19
00:01:23,334 --> 00:01:27,760
我们希望输出两个东西

20
00:01:27,760 --> 00:01:31,478
一个是一系列主题 有Theta i 表示

21
00:01:31,478 --> 00:01:35,750
每个都是有贡献的
另一个是pi i j

22
00:01:35,750 --> 00:01:42,120
这里是每个文件都覆盖每个主题的概率

23
00:01:42,120 --> 00:01:47,190
所以这是一个文本覆盖
和这也是在这个课件看到的

24
00:01:47,190 --> 00:01:51,279
你可以看到我们通过主题模型可以得到什么

25
00:01:51,279 --> 00:01:58,101
现在 这个和文本聚类问题的主要区别在这里

26
00:01:58,101 --> 00:02:02,758
一个文件 被假设为可能覆盖不同主题

27
00:02:02,758 --> 00:02:07,946
而且一般而言 一个文件会覆盖

28
00:02:07,946 --> 00:02:12,802
一个以上主题 并且概率非零

29
00:02:12,802 --> 00:02:17,624
在文本聚类 然而 我们只允许一个文件

30
00:02:17,624 --> 00:02:22,460
覆盖一个主题 如果我们假设一个主题是一个聚类的话

31
00:02:24,270 --> 00:02:30,610
这意味着如果我们稍微改变题目的定义

32
00:02:30,610 --> 00:02:35,800
假设每个文件只能被一个主题组成

33
00:02:37,200 --> 00:02:41,987
这样 我们会拥有一个聚类问题的定义

34
00:02:41,987 --> 00:02:44,431
所以这里的输出也会改变

35
00:02:44,431 --> 00:02:49,703
我们不在拥有细节的覆盖贡献 pi i  

36
00:02:49,703 --> 00:02:55,084
然而 我们会聚类课题决定 C 

37
00:02:55,084 --> 00:03:02,015
Ci 是一个文件i的决定

38
00:03:02,015 --> 00:03:06,943
然后C 下面会有从1到k的值 表示其中一个

39
00:03:06,943 --> 00:03:08,180
k 聚类

40
00:03:09,230 --> 00:03:15,766
基本上告诉我们 
d i 实在聚类里

41
00:03:15,766 --> 00:03:21,772
如这里所描述 我们不再拥有多个主题被一个文档覆盖

42
00:03:21,772 --> 00:03:23,862
只有准确的一个主题

43
00:03:23,862 --> 00:03:27,330
尽管是哪个主题仍不确定

44
00:03:27,330 --> 00:03:28,950
这里有一个连接

45
00:03:29,980 --> 00:03:34,800
与一个先前讨论过的挖掘问题

46
00:03:34,800 --> 00:03:38,980
这个课件你们之前看过

47
00:03:38,980 --> 00:03:43,130
这里我希望估计一个主题模型

48
00:03:43,130 --> 00:03:47,145
或者分布 基于一个文档

49
00:03:47,145 --> 00:03:51,065
然后当我们假设这个文档精确覆盖一个主题

50
00:03:52,955 --> 00:03:55,585
不过我们仍考虑问题的变化

51
00:03:55,585 --> 00:03:59,000
比如 我们可以认为这里有N个文档

52
00:03:59,000 --> 00:04:04,410
每个覆盖不容的主题
所以 这里有 N文档 和主题

53
00:04:04,410 --> 00:04:07,232
当然 在这个案例 这些文档时独立的

54
00:04:07,232 --> 00:04:09,090
而且主题也是独立的

55
00:04:09,090 --> 00:04:13,811
不过 我们会让这些文档分享主题

56
00:04:13,811 --> 00:04:18,869
而且我们会假设这里的主题数量会比

57
00:04:18,869 --> 00:04:23,862
文档的数量少
所以这些文档会分享多个主题

58
00:04:23,862 --> 00:04:27,243
如果我们拥有N个分享K个主题的文档

59
00:04:27,243 --> 00:04:32,290
我们会有一个精确地文档聚类问题

60
00:04:34,350 --> 00:04:37,430
所以因为这些关联
我们会想如何

61
00:04:37,430 --> 00:04:41,310
用概率生成模型来解决文本聚类问题

62
00:04:43,450 --> 00:04:47,640
现在问题是 怎样的生成模型可以被用来聚类

63
00:04:49,700 --> 00:04:54,960
在所有设计生成模型的案例里 我们希望生成一个

64
00:04:54,960 --> 00:05:00,008
能够输出我们想要的结果的模型
或者我们希望模型的结构如此

65
00:05:00,008 --> 00:05:04,071
所以在这案例
这是一个聚类结构

66
00:05:04,071 --> 00:05:08,346
主题们 还有每个文档覆盖一个主题

67
00:05:08,346 --> 00:05:15,407
然后我们希望嵌入我们的优先选择于生成模型

68
00:05:15,407 --> 00:05:18,987
不过 如果你们想到这个问题和我们

69
00:05:18,987 --> 00:05:21,407
之前讨论过的一个模型的主要区别

70
00:05:21,407 --> 00:05:26,391
你会看见一个主要的要求 是
我们如何迫使所有

71
00:05:26,391 --> 00:05:30,867
文档都精确的由一个主题生成

72
00:05:30,867 --> 00:05:34,650
而不是k主题 在这个主题模型里

73
00:05:35,930 --> 00:05:41,630
让我们更为细节地回顾这个模型

74
00:05:41,630 --> 00:05:46,360
这就是两个成分混合模型的细节

75
00:05:46,360 --> 00:05:49,920
当我们拥有K个成分时 看起来很相似

76
00:05:49,920 --> 00:05:52,759
所以我们会看见当我们生成一个文档时

77
00:05:53,860 --> 00:05:56,210
我们生成的每个词都是独立的

78
00:05:57,480 --> 00:06:03,969
而当我们生成这些词的时候
我们首先在这些分布中做出选择

79
00:06:03,969 --> 00:06:10,205
我们按概率选择其中一个

80
00:06:10,205 --> 00:06:17,743
这里p(θ1)是选择上面这个分布的概率

81
00:06:17,743 --> 00:06:22,383
现在我们先来选择

82
00:06:22,383 --> 00:06:23,587
生成词的分布

83
00:06:23,587 --> 00:06:27,664
然后我们用这个分布来抽样产生单词

84
00:06:27,664 --> 00:06:31,042
现在注意
在这样一个生成模型当中

85
00:06:31,042 --> 00:06:37,550
对于每个词所用分布的选择是独立的

86
00:06:37,550 --> 00:06:38,820
也就是说
比如

87
00:06:38,820 --> 00:06:43,173
here这个词可以从第二个分布θ2当中产生

88
00:06:43,173 --> 00:06:48,580
而text这个词在第一个分布中更容易出现

89
00:06:49,620 --> 00:06:55,060
也就是说文档中的词

90
00:06:55,060 --> 00:06:56,649
可能来自多个分布

91
00:06:58,390 --> 00:07:02,880
现在这不是我们想要的
如我们之前说的

92
00:07:02,880 --> 00:07:04,090
文本聚类或者说文档聚类

93
00:07:04,090 --> 00:07:08,060
我们希望文档是精确地从一个话题中产生的

94
00:07:09,550 --> 00:07:12,880
现在意味着我们要改变模型

95
00:07:12,880 --> 00:07:13,970
怎么改呢?

96
00:07:13,970 --> 00:07:20,170
首先我们来想这个模型为什么不能用在聚类上

97
00:07:20,170 --> 00:07:23,760
像我说的
原因就是

98
00:07:23,760 --> 00:07:27,890
它允许多个话题对文档产生同一个词

99
00:07:28,890 --> 00:07:33,000
这就会带来混乱
因为我们不知道

100
00:07:33,000 --> 00:07:34,380
文档究竟来自哪个聚类

101
00:07:34,380 --> 00:07:37,280
更重要的是
它违背了我们

102
00:07:37,280 --> 00:07:41,258
对于集聚中文档分区的假设

103
00:07:41,258 --> 00:07:45,950
如果我们让一个话题对应到文档中的一个聚类

104
00:07:45,950 --> 00:07:50,670
那么我们需要文档完全从一个话题中生成

105
00:07:50,670 --> 00:07:54,050
也就是说文档中的所有词

106
00:07:54,050 --> 00:07:57,530
都需要从一个分布中生成

107
00:07:57,530 --> 00:08:01,950
对于我们看到的这样的主题模型
这点并不成立

108
00:08:01,950 --> 00:08:07,640
这也是为什么
这个模型不能用来做聚类

109
00:08:07,640 --> 00:08:12,890
因为它不能保证一个文档中的所有词都来自一个分布

110
00:08:15,110 --> 00:08:17,180
如果你意识到这个问题

111
00:08:17,180 --> 00:08:22,110
我们就可以可以设计另外的混合模型来做聚类

112
00:08:22,110 --> 00:08:24,320
这就是你会看到的内容

113
00:08:24,320 --> 00:08:29,027
我们还是要在分布上做出选择

114
00:08:29,027 --> 00:08:33,421
来生成文档
因为文档可以

115
00:08:33,421 --> 00:08:37,592
从我们有的任何k词分布中产生

116
00:08:37,592 --> 00:08:42,581
但这次
当我们选出一个话题之后

117
00:08:42,581 --> 00:08:47,999
我们会用这个话题生成文档中的所有词

118
00:08:49,768 --> 00:08:54,719
也就是说
一旦我们选定了产生第一个词的分布

119
00:08:54,719 --> 00:08:59,397
我们会一直用这个分布

120
00:08:59,397 --> 00:09:04,643
生成文档中的其他所有词

121
00:09:04,643 --> 00:09:09,448
换句话说
我们只做出一次选择

122
00:09:09,448 --> 00:09:14,671
基本上我们只对文档做一次选择

123
00:09:14,671 --> 00:09:18,754
这个状态会用以生成所有词

124
00:09:18,754 --> 00:09:22,794
同样地如果我选择了第二个分布
这里的θ2

125
00:09:22,794 --> 00:09:24,824
你可以看到状态就是这个

126
00:09:24,824 --> 00:09:27,669
然后生成整个文档d

127
00:09:27,669 --> 00:09:32,540
现在如果你将这张图与之前比较

128
00:09:32,540 --> 00:09:37,717
你会看到对于分布的决定

129
00:09:37,717 --> 00:09:44,740
在文档聚类当中
对于这篇文档只进行了一次

130
00:09:44,740 --> 00:09:46,310
但是在话题模型当中

131
00:09:46,310 --> 00:09:51,080
我们需要进行决定的次数是文档中单词的个数

132
00:09:51,080 --> 00:09:54,990
因为每一个词都可能做出一个不同的决定

133
00:09:54,990 --> 00:09:57,140
这就是两个模型的关键不同

134
00:09:58,240 --> 00:10:01,363
但是这个很明显也是个混合模型

135
00:10:01,363 --> 00:10:05,824
所以我们可以将其一同分组

136
00:10:05,824 --> 00:10:10,214
来说明这个模型能够以一定概率生成文档

137
00:10:10,214 --> 00:10:11,766
现在在模型当中

138
00:10:11,766 --> 00:10:15,335
还有一个选择不同分部的开关

139
00:10:15,335 --> 00:10:18,908
但是我们看不到它
所以这是一个混合模型

140
00:10:18,908 --> 00:10:23,324
当然文档聚类的主要问题是推断

141
00:10:23,324 --> 00:10:26,810
文档生成使用了哪个分布

142
00:10:26,810 --> 00:10:31,165
让我们能够还原文档的聚类情况

143
00:10:37,518 --> 00:10:41,911
所以需要来考虑与话题模型的不同

144
00:10:41,911 --> 00:10:44,339
像我之前多次提过的那样

145
00:10:46,110 --> 00:10:52,370
这里有两个主要的不同

146
00:10:52,370 --> 00:10:55,100
一个是选择特定分布的决定

147
00:10:56,620 --> 00:11:02,315
在文本聚类当中只进行一次

148
00:11:02,315 --> 00:11:08,230
而在话题模型当中
不同的词可能会有多次选择

149
00:11:08,230 --> 00:11:12,600
第二个是词的分布

150
00:11:12,600 --> 00:11:17,800
这里会是用来重新生成文档中所有的词

151
00:11:19,260 --> 00:11:23,612
但是在话题模型当中
一个分布

152
00:11:23,612 --> 00:11:26,467
不需要生成文档中所有的词

153
00:11:26,467 --> 00:11:31,022
文档可以使用多个分布来生成词

154
00:11:34,322 --> 00:11:37,179
我们来考虑一个特别的情况

155
00:11:37,179 --> 00:11:42,990
当选择某个特定分布的概率等于1时

156
00:11:42,990 --> 00:11:46,750
也就是我们现在没有不确定因素了

157
00:11:46,750 --> 00:11:50,842
我们只用一个特定的分布

158
00:11:50,842 --> 00:11:55,189
在这情况下
显然我们看到这不再是混合模型

159
00:11:55,189 --> 00:11:57,686
因为没有不确定性

160
00:11:57,686 --> 00:12:02,414
我们看到的只是一个分布生成整个文档

161
00:12:02,414 --> 00:12:07,202
现在我们回到

162
00:12:07,202 --> 00:12:11,420
通过一个文档估计分布的问题当中

163
00:12:12,880 --> 00:12:15,529
我们之前提到过

164
00:12:15,529 --> 00:12:19,010
现在你可以看得更清楚

165
00:12:19,010 --> 00:12:22,667
如在所有利用生成模型解决问题的示例当中

166
00:12:22,667 --> 00:12:26,480
我们先看了数据
然后思考如何去设计模型

167
00:12:26,480 --> 00:12:27,720
但一旦我们设定了模型

168
00:12:27,720 --> 00:12:31,640
下一步就是来写似然函数

169
00:12:31,640 --> 00:12:35,070
之后我们要来考虑如何去估计参数

170
00:12:36,350 --> 00:12:39,030
这里的似然函数是什么呢?

171
00:12:39,030 --> 00:12:43,060
它会跟你之前在话题模型中看到的很相似

172
00:12:43,060 --> 00:12:43,960
但是也会有所不同

173
00:12:45,210 --> 00:12:49,563
现在如果你还想得起来之前的似然函数

174
00:12:49,563 --> 00:12:54,515
你会意识到
从混合模型中观测到某个数据点的概率

175
00:12:54,515 --> 00:12:59,010
等于生成数据所有可能性之和

176
00:13:00,520 --> 00:13:03,680
这里就会是所有k个话题之和

177
00:13:03,680 --> 00:13:06,970
因为每一个都可用来生成文档

178
00:13:06,970 --> 00:13:12,110
在总和当中
你还能想到公式是怎样的

179
00:13:12,110 --> 00:13:18,950
它会是两个概率的乘积

180
00:13:18,950 --> 00:13:23,450
一个是选择分布的概率

181
00:13:23,450 --> 00:13:26,480
一个是从该分布观测到该数据点的概率

182
00:13:27,630 --> 00:13:33,457
如果你写出我们问题的式子

183
00:13:33,457 --> 00:13:36,195
你会看到观测到文档d的概率

184
00:13:37,225 --> 00:13:41,997
基本上等于两个不同分布的和

185
00:13:41,997 --> 00:13:47,617
因为我们这里情况很简单
只有两个聚类

186
00:13:47,617 --> 00:13:51,657
所以这里只是两个情况的总和

187
00:13:51,657 --> 00:13:56,461
每个情形下
就是由选择分布的概率

188
00:13:56,461 --> 00:14:03,600
θ1或者θ2

189
00:14:03,600 --> 00:14:08,810
然后乘以

190
00:14:08,810 --> 00:14:13,790
从该分布观测到文档的概率

191
00:14:16,430 --> 00:14:21,540
如果你进一步展开

192
00:14:21,540 --> 00:14:28,100
观测到整个文档的概率
我们看它就是观测到每个词Xi的(概率)之积

193
00:14:28,100 --> 00:14:33,110
现在我们做一个假设
假设每个词的生成过程是独立的

194
00:14:33,110 --> 00:14:36,270
也就是说整个文档的概率就是

195
00:14:36,270 --> 00:14:38,690
文档中每个词的概率的乘积

196
00:14:40,050 --> 00:14:44,120
这个形式跟话题模型是十分类似的

197
00:14:44,120 --> 00:14:48,790
但是我们也要考虑其中的区别
出于这一点

198
00:14:48,790 --> 00:14:56,350
我也把话题模型概率的这两类元素拷贝到了这里

199
00:14:56,350 --> 00:15:01,301
你可以看到
公式从许多方面看都很相似

200
00:15:02,480 --> 00:15:05,060
但是其中也有一些不同

201
00:15:06,110 --> 00:15:09,740
尤其是在顶部这里的不同

202
00:15:09,740 --> 00:15:14,850
你可以看到文档聚类的混合模型上
我们先是取积

203
00:15:14,850 --> 00:15:15,510
然后求和

204
00:15:16,610 --> 00:15:19,770
对应到我们的假设

205
00:15:19,770 --> 00:15:22,680
我们先是选择一个分布

206
00:15:22,680 --> 00:15:26,320
然后我们一直用这个分布生成所有的词

207
00:15:26,320 --> 00:15:29,170
这就是为什么乘法是在求和之内的

208
00:15:30,880 --> 00:15:34,790
求和对应的选择

209
00:15:34,790 --> 00:15:39,659
现在话题模型当中呢
和是在乘积当中的

210
00:15:39,659 --> 00:15:42,990
这是因为我们每个词是独立生成的

211
00:15:42,990 --> 00:15:46,789
这就是为什么乘法是在外面

212
00:15:46,789 --> 00:15:51,602
但是当我们生成每一个词的时候

213
00:15:51,602 --> 00:15:56,437
我们需要选择使用的分布
所以这里有个对每个词的求和

214
00:15:56,437 --> 00:16:01,306
但是总的来讲
这些都是混合模型

215
00:16:01,306 --> 00:16:06,887
我们可以利用EM算法来估计这些模型

216
00:16:06,887 --> 00:16:09,990
之后我们还会更多讲到这一点

217
00:16:09,990 --> 00:16:18,399
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community