1
00:00:00,192 --> 00:00:03,512
[声音]

2
00:00:06,614 --> 00:00:09,660
这节课将围绕文本分类展开

3
00:00:11,360 --> 00:00:15,320
在这一课中，我们主要将讨论有关文本分类的内容

4
00:00:16,390 --> 00:00:21,320
这是文本数据挖掘和分析中一项非常重要的技术

5
00:00:22,470 --> 00:00:27,035
它与接下来呈现的各种类型的知识

6
00:00:27,035 --> 00:00:29,134
的发现相关

7
00:00:29,134 --> 00:00:33,380
首先，它与主题挖掘与分析相关

8
00:00:33,380 --> 00:00:36,060
并且，那是因为它与

9
00:00:36,060 --> 00:00:40,970
基于某些预定主题的文本数据分析相关

10
00:00:40,970 --> 00:00:46,239
其次，它也关系到意见挖掘和情绪分析

11
00:00:46,239 --> 00:00:51,941
那与有关观察者和人类感应传感器的知识发现相关

12
00:00:51,941 --> 00:00:56,301
因为我们可以将作者分类，比如说

13
00:00:56,301 --> 00:01:01,813
基于他们撰写过的文章的内容，对吗？

14
00:01:01,813 --> 00:01:06,611
通常来说，我们可以将观察者

15
00:01:06,611 --> 00:01:10,800
以他们所生产的内容进行分类

16
00:01:12,300 --> 00:01:16,720
最后，它也涉及基于文本的预测

17
00:01:16,720 --> 00:01:21,760
因为我们经常可以使用文本分类的方法来预测

18
00:01:21,760 --> 00:01:26,180
一些现实世界中的与文本数据联系不太紧密的变量

19
00:01:27,230 --> 00:01:32,490
因此，对文本数据挖掘而言，这是一项非常重要的技术

20
00:01:34,820 --> 00:01:37,860
下面我们来讲讲围绕这个话题的大致计划

21
00:01:37,860 --> 00:01:40,750
首先，我们将探讨什么是文本分类

22
00:01:40,750 --> 00:01:44,510
以及我们为什么在这节课中有兴趣研究这个问题

23
00:01:44,510 --> 00:01:47,920
紧接着我们要再讲一讲如何实现文本分类

24
00:01:47,920 --> 00:01:50,780
以及如何评价分类结果

25
00:01:50,780 --> 00:01:56,140
所以，文本分类的问题定义如下

26
00:01:56,140 --> 00:02:03,461
我们被给出一组预定义的类别，这组类别大概会形成一个层级

27
00:02:03,461 --> 00:02:07,462
并且通常来说，一组训练样例或者

28
00:02:07,462 --> 00:02:12,519
标记文本对象的训练集也会被同时给出

29
00:02:12,519 --> 00:02:17,810
这意味着该文本对象已经与被启用了已知类别

30
00:02:17,810 --> 00:02:23,040
然后，任务是将任一文本对象分类至

31
00:02:23,040 --> 00:02:26,320
一个或多个预定义的类别

32
00:02:26,320 --> 00:02:29,139
所以，这张幻灯片上的图片会显示发生了什么

33
00:02:30,270 --> 00:02:32,120
当我们实现文本分类的时候

34
00:02:32,120 --> 00:02:37,630
我们有大量的文本对象需要被一个分类系统处理

35
00:02:37,630 --> 00:02:43,820
并且这个系统通常会通过这些文件来分配类别

36
00:02:43,820 --> 00:02:49,110
正如显示在右侧的和分类的结果所示

37
00:02:49,110 --> 00:02:54,280
我们通常假定训练样例和

38
00:02:54,280 --> 00:02:59,060
这些已知类别标记的文件

39
00:02:59,060 --> 00:03:01,660
这些实例对帮助系统

40
00:03:01,660 --> 00:03:06,110
学习不同类别的模式中是至关重要的

41
00:03:06,110 --> 00:03:10,180
并且，者将会进一步帮助系统了解如何识别

42
00:03:11,280 --> 00:03:16,560
从未见过的新文本对象的类别

43
00:03:16,560 --> 00:03:20,950
所以这里有一些文本分类的典型例子

44
00:03:20,950 --> 00:03:26,140
而事实上例子很多，
这里只能列举少数几个

45
00:03:27,230 --> 00:03:33,000
首先，文本对象可能会有所不同
所以我们也许要分类一个文件、

46
00:03:33,000 --> 00:03:36,730
一个段落、一个句子或者文本集合

47
00:03:36,730 --> 00:03:41,400
在这种混杂的情况下
待分析的文本可能存在巨大的差异

48
00:03:41,400 --> 00:03:44,090
因此这也创造了很多可能性

49
00:03:44,090 --> 00:03:46,690
其次，类别也可能有所不同

50
00:03:46,690 --> 00:03:49,880
一般而言，分配有两种主要的类别

51
00:03:49,880 --> 00:03:51,560
一项是内部类别

52
00:03:51,560 --> 00:03:55,890
这些都是针对文本对象内容的类别

53
00:03:55,890 --> 00:04:00,850
比方说，主题类别或者情绪类别

54
00:04:00,850 --> 00:04:04,810
并且它们通常与文本对象的内容相关

55
00:04:04,810 --> 00:04:06,930
贯穿内容分类的全过程

56
00:04:08,210 --> 00:04:13,430
另一种是外部类别

57
00:04:13,430 --> 00:04:16,120
能够表征与文本对象相关的一个实体

58
00:04:16,120 --> 00:04:17,630
比如

59
00:04:17,630 --> 00:04:22,810
作者是与他们生产的内容相关的实体

60
00:04:22,810 --> 00:04:28,340
因此，我们可以利用它们的内容
来确定这是哪个作家写的

61
00:04:28,340 --> 00:04:31,670
或者比方说写了那一部分
这就是所谓的作者归属

62
00:04:33,540 --> 00:04:38,048
或者，我们也可以有其他最小的类别

63
00:04:38,048 --> 00:04:43,147
与文本数据相关

64
00:04:43,147 --> 00:04:47,788
只要在实体和文本数据之间存在极小联系均可

65
00:04:47,788 --> 00:04:54,025
比如，我们可以收集很多关于一家餐馆的评价

66
00:04:54,025 --> 00:04:58,073
或者对一项产品的评价

67
00:04:58,073 --> 00:05:04,770
紧接着这一文本数据能够帮助我们推断出
这项产品或者餐厅的性能

68
00:05:04,770 --> 00:05:07,770
在那种情况下，我们可以把它当作一个分类问题

69
00:05:07,770 --> 00:05:09,921
我们可以将餐厅或者产品

70
00:05:09,921 --> 00:05:13,924
基于它们相对应的评价进行分类

71
00:05:13,924 --> 00:05:17,245
所以，这是一个外部类别的例子

72
00:05:17,245 --> 00:05:20,400
关于这些应用有不少具体的实例

73
00:05:20,400 --> 00:05:25,110
新闻分类由于被大量采用，是很常见的

74
00:05:25,110 --> 00:05:30,009
新闻机构喜欢将每天生产出来的新闻

75
00:05:30,009 --> 00:05:35,672
分配给预定义的类别

76
00:05:35,672 --> 00:05:39,824
当然，这些虚拟物品的分类不算太重要

77
00:05:39,824 --> 00:05:43,650
比方说，在生物医学领域有主题词注释 (MeSH)

78
00:05:43,650 --> 00:05:47,930
主题词 (MeSH) 代表医学主题词 (Medical Subject Heading)

79
00:05:49,090 --> 00:05:52,490
这是就本体而言对文章内容的细节进行分类

80
00:05:54,590 --> 00:05:59,860
另一个应用的实例是垃圾邮件的检测和过滤，对吧？

81
00:05:59,860 --> 00:06:04,940
我们通常都有一个垃圾邮件的过滤器

82
00:06:04,940 --> 00:06:10,260
来帮助我们识别合法的和垃圾电子邮件

83
00:06:10,260 --> 00:06:13,000
这显然是一个二元分类问题

84
00:06:14,500 --> 00:06:18,460
对产品评价或者微博进行情感分类

85
00:06:18,460 --> 00:06:23,120
是另一项我们能够进行分类的应用

86
00:06:23,120 --> 00:06:26,380
要么是积极或消极，要么是积极、消极或者中立

87
00:06:27,460 --> 00:06:32,820
所以，你可以将它们归类，分配两个文本的内容

88
00:06:35,520 --> 00:06:39,480
另一项应用是电子邮件的自动排序

89
00:06:39,480 --> 00:06:43,750
你可能希望邮件能够自动归类到不同的文件夹

90
00:06:43,750 --> 00:06:47,320
那就是文本分类的另一种应用
在这里每个文件夹就是一个类别

91
00:06:48,370 --> 00:06:52,580
而这些结果正是另一种重要的应用

92
00:06:52,580 --> 00:06:55,910
即按某路线将邮件发送给合适的人进行处理

93
00:06:55,910 --> 00:07:01,890
所以在服务台，电子邮件收发通常
发送给一个特定的人来处理

94
00:07:01,890 --> 00:07:05,820
不同的人倾向于处理不同种类的请求

95
00:07:05,820 --> 00:07:11,220
在很多情况下，会有一个人将这些消息手动分配给合适的人

96
00:07:11,220 --> 00:07:15,231
但是，你要是设想一下，你不可能

97
00:07:15,231 --> 00:07:18,794
文本自动分类系统来帮助分发请求

98
00:07:18,794 --> 00:07:24,969
并且，这是一个类别文件
某一类别传入的请求

99
00:07:24,969 --> 00:07:31,265
其中，每个类别实际上与一个人相对应，来处理这一请求

100
00:07:31,265 --> 00:07:35,975
最后，正如我刚才提到的
作者归属又是另一个应用程序

101
00:07:35,975 --> 00:07:39,759
并且它是另一个利用文本来推断

102
00:07:41,480 --> 00:07:42,960
其他一些实体的性能的例子

103
00:07:42,960 --> 00:07:46,890
并且这一问题的构想还有多种变体

104
00:07:46,890 --> 00:07:50,980
因此，首先，假如我们处于最简单的情况中
也就是二元分类的情况下

105
00:07:50,980 --> 00:07:52,990
一共只有两个类别

106
00:07:52,990 --> 00:07:57,660
而且这样的实例也很多，比如说信息检索和搜索引擎

107
00:07:59,040 --> 00:08:03,600
区别相关的文件和不相关文件

108
00:08:03,600 --> 00:08:04,940
这一特殊查询的应用

109
00:08:06,040 --> 00:08:12,330
垃圾邮件过滤知识区分将垃圾邮件与
非垃圾邮件相区别，所以也就是两类

110
00:08:12,330 --> 00:08:16,800
有时候，意见分类也可以是两类

111
00:08:16,800 --> 00:08:17,800
积极的和消极的

112
00:08:19,120 --> 00:08:22,650
更普遍的情况是K种类别分类

113
00:08:22,650 --> 00:08:26,755
这样的应用也有很多，
可能有两个以上的类别

114
00:08:26,755 --> 00:08:30,155
主题分类通常可以作为这样的一个例子

115
00:08:30,155 --> 00:08:31,935
在主题分类中你可以有多个主题

116
00:08:31,935 --> 00:08:36,205
电子邮件分发可以作为另一个例子
当你有多个文件夹或者

117
00:08:36,205 --> 00:08:39,322
当你要把邮件分发给合适的人处理的时候

118
00:08:39,322 --> 00:08:44,550
那么也有多个人进行分类

119
00:08:44,550 --> 00:08:48,212
这样，在所有这些情况下，
就有两种以上的类别了

120
00:08:49,272 --> 00:08:52,382
另一种变体是有层次的分类

121
00:08:52,382 --> 00:08:54,442
在这种情况下，类别形成了一个层级

122
00:08:54,442 --> 00:08:56,602
同样地，主题层次是很常见的

123
00:08:58,232 --> 00:09:00,742
但另一种变体是合并分类

124
00:09:00,742 --> 00:09:04,550
这时候，你有多项相关的分类任务

125
00:09:04,550 --> 00:09:08,150
并且你有点希望合并这些分类

126
00:09:08,150 --> 00:09:13,340
进一步利用这些任务之间的相关性

127
00:09:13,340 --> 00:09:15,250
来提高每一单独任务的精度

128
00:09:15,250 --> 00:09:19,870
在所有这些分类中，二元分类是最基础的

129
00:09:19,870 --> 00:09:25,170
一部分也是因为它相对简单

130
00:09:25,170 --> 00:09:31,000
也可能是因为实际上它被用来执行所有其他分类任务

131
00:09:31,000 --> 00:09:34,839
例如，一个K类别分类任务事实上可以

132
00:09:34,839 --> 00:09:38,665
通过使用二元分类来实现

133
00:09:40,075 --> 00:09:43,405
我们可以首先分别观察每一个类别

134
00:09:43,405 --> 00:09:49,385
二元分类的问题也就是
这个对象是否从属于于这个类别

135
00:09:49,385 --> 00:09:52,005
若不是那也就意味着它从属于其他类别

136
00:09:53,485 --> 00:09:59,820
并且，分层分类也可以通过

137
00:09:59,820 --> 00:10:04,300
执行每一个层级的平级分类逐级实现

138
00:10:04,300 --> 00:10:07,000
因为，我们首先要将所有的对象归入

139
00:10:07,000 --> 00:10:09,140
我们所说的少数高层次类别

140
00:10:09,140 --> 00:10:13,740
然后在每一类别内部，我们进一步
将他们分类到子类别

141
00:10:15,000 --> 00:10:16,728
所以，为什么文本分类这么重要呢？

142
00:10:16,728 --> 00:10:21,464
好吧，我已经向你们展示一些了应用实例

143
00:10:21,464 --> 00:10:23,244
有很多的原因

144
00:10:23,244 --> 00:10:28,891
其一，文本分类能够丰富文本呈现

145
00:10:28,891 --> 00:10:34,970
也就是实现对文本数据更深层次的理解
这对文本分析而言是很有帮助的

146
00:10:34,970 --> 00:10:38,738
所以，现在用分类文本可以在多个层次中显示

147
00:10:38,738 --> 00:10:47,310
关键词条件在大量文本处理任务中得以应用

148
00:10:47,310 --> 00:10:52,455
但我们现在也可以增加类别
并且它们可以提供两个过渡层次

149
00:10:55,485 --> 00:11:00,085
分配语义类别对应用而言

150
00:11:00,085 --> 00:11:01,145
是必要的。

151
00:11:01,145 --> 00:11:07,869
因此，比如语义类别已经非常有用了

152
00:11:07,869 --> 00:11:12,248
或者其他的归属类别也可能是直接有用的

153
00:11:12,248 --> 00:11:18,118
另一个例子是当语义类别可以

154
00:11:18,118 --> 00:11:24,660
方便文本内容的汇总，并且
这是文本分类应用的另一种情况

155
00:11:25,950 --> 00:11:30,940
比如，如果我们想知道某一产品的整体评价

156
00:11:32,010 --> 00:11:37,830
我们可以先对每个人的评价意见进行分类

157
00:11:37,830 --> 00:11:42,730
积极的或者消极的，然后这使得我们能够轻松地

158
00:11:42,730 --> 00:11:47,810
整合所有的情感意见，并且它会告诉我们

159
00:11:47,810 --> 00:11:52,680
其中70%的评价是积极的，30%的评价是消极的等等

160
00:11:53,810 --> 00:11:56,865
所以，没有分类的实现

161
00:11:56,865 --> 00:12:02,402
整合汇总这些意见来提供一种基于所有词汇的

162
00:12:02,402 --> 00:12:07,468
简洁的整合文本的方式是非常难的

163
00:12:07,468 --> 00:12:13,640
而且，有时你也会在一些应用中看到

164
00:12:13,640 --> 00:12:18,704
分类后的文本被称为编码文本
被一些控制词汇所编码

165
00:12:18,704 --> 00:12:22,316
第二个理由是

166
00:12:22,316 --> 00:12:27,024
使用文本分类来推断实体的属性

167
00:12:27,024 --> 00:12:31,950
并且文本分类允许我们推断

168
00:12:31,950 --> 00:12:36,950
与文本数据相关的实体的属性

169
00:12:36,950 --> 00:12:41,140
所以，这意味着我们可以使用文本分类

170
00:12:41,140 --> 00:12:44,090
来发现这个世界的知识

171
00:12:44,090 --> 00:12:48,370
通常来说，只要我们能够
将实体与文本数据相关联

172
00:12:48,370 --> 00:12:53,600
我们总能利用文本数据来对相应的实体进行分类

173
00:12:53,600 --> 00:12:54,502
所以，它是应用于单一信息网络

174
00:12:54,502 --> 00:12:59,380
使得其他实体与文本数据相连接

175
00:12:59,380 --> 00:13:03,750
作者明显是可以与文本数据直接相关的实体

176
00:13:03,750 --> 00:13:08,340
但是，你也可以假想
作者的隶属关系或者作者的年龄

177
00:13:08,340 --> 00:13:14,090
以及其他的东西实际上也可以与文本数据间接相关

178
00:13:14,090 --> 00:13:18,860
一旦我们建立了联系，
我们就可以对这些值作出预测

179
00:13:18,860 --> 00:13:23,520
所以，这也是允许我们通过文本分类

180
00:13:23,520 --> 00:13:26,890
使用文本挖掘来发现这个世界的知识的通常方法

181
00:13:26,890 --> 00:13:32,330
这非常有用，尤其是在大文本数据分析中

182
00:13:32,330 --> 00:13:38,150
我们通常使用文本数据作为
从人类中提取出来的额外数据集

183
00:13:38,150 --> 00:13:43,930
与非文本数据来一起推断特定的决定因子

184
00:13:43,930 --> 00:13:45,710
比如，对于文本具体而言

185
00:13:45,710 --> 00:13:49,220
我们可以想到一些推断实体属性的例子

186
00:13:49,220 --> 00:13:53,190
比如，发现某一语言的非母语说话者

187
00:13:53,190 --> 00:13:59,460
这可以通过对发言者的内容进行分类来实现

188
00:14:00,680 --> 00:14:05,566
另一个例子是基于政治演说

189
00:14:05,566 --> 00:14:07,314
对某一政治家的政党所属进行预测

190
00:14:07,314 --> 00:14:11,967
并且，这又是一个利用文本数据来推断

191
00:14:11,967 --> 00:14:15,146
真实世界知识的例子

192
00:14:15,146 --> 00:14:19,265
通常而言，这些问题都是相同的

193
00:14:19,265 --> 00:14:24,980
它们都是我们所定义的文本分类的问题

194
00:14:24,980 --> 00:14:34,980
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community