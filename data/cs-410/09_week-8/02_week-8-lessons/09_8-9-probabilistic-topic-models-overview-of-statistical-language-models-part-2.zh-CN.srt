1
00:00:00,000 --> 00:00:06,605
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community

2
00:00:06,605 --> 00:00:11,574
现在 让我们对这个问题 
--尤其是两中不同的参数估计方法

3
00:00:11,574 --> 00:00:15,670
进行详细讨论

4
00:00:15,670 --> 00:00:19,740
一种是我们已经介绍过的极大似然估计

5
00:00:19,740 --> 00:00:22,180
另一种是贝叶斯估计

6
00:00:22,180 --> 00:00:27,140
在极大似然估计中 我们将最优定义为

7
00:00:27,140 --> 00:00:31,550
数据似然值达到最大

8
00:00:31,550 --> 00:00:36,950
其正式的表述如ppt所示

9
00:00:36,950 --> 00:00:45,190
我们将估计定义为
给定Ɵ下的X的条件概率的arg max

10
00:00:46,280 --> 00:00:53,550
这里的arg max仅仅表示这个函数将以

11
00:00:53,550 --> 00:00:58,660
使这个函数取得最大值的参数的值最为返回值

12
00:00:58,660 --> 00:01:01,850
即arg max的值不是这个概率函数的值

13
00:01:01,850 --> 00:01:06,090
而是使得函数值达到最大时的参数值

14
00:01:06,090 --> 00:01:09,975
所以在这个公式中arg max返回值为Ɵ

15
00:01:09,975 --> 00:01:16,475
正是Ɵ决定了X的条件概率
--某个特定的Ɵ使其达到最大值

16
00:01:16,475 --> 00:01:22,122
因此这个估计方法符合我们的直觉
通常也很有用

17
00:01:22,122 --> 00:01:27,070
它寻求能够最好地解释数据的参数

18
00:01:27,070 --> 00:01:31,890
但是当数据太小时它也会产生问题

19
00:01:31,890 --> 00:01:35,120
-因为如果数据点太小 则我们只有很少的数据点

20
00:01:35,120 --> 00:01:39,050
在样本集合很小的情况下 
如果我们完全依赖于已有数据

21
00:01:39,050 --> 00:01:42,370
并且试图使估计拟合这些数据
则将导致偏差

22
00:01:42,370 --> 00:01:47,640
以文本数据为例，假设我们观察到100个单词

23
00:01:47,640 --> 00:01:52,950
其中并未包含另一个与文本挖掘有关的单词

24
00:01:52,950 --> 00:01:57,930
我们的极大似然估计将为
这个单词的概率赋值为0

25
00:01:57,930 --> 00:02:00,528
因为 如果赋予它非零值

26
00:02:00,528 --> 00:02:04,144
某些已观察到的单词的概率值将被减小

27
00:02:04,144 --> 00:02:08,629
这显然不是被观察数据

28
00:02:08,629 --> 00:02:09,910
由极大似然估计法得到的最优

29
00:02:11,300 --> 00:02:15,150
但是这种未观察到的单词的0概率

30
00:02:15,150 --> 00:02:20,180
有时候可能并不合理

31
00:02:20,180 --> 00:02:25,140
尤其当我们想要用这个分布来
描述文本挖掘主题的特征时

32
00:02:25,140 --> 00:02:29,770
解决这个问题的一种方式是使用贝叶斯（Bayesian）估计

33
00:02:29,770 --> 00:02:33,310
它能使我们兼顾数据

34
00:02:33,310 --> 00:02:36,760
与参数的先验知识

35
00:02:36,760 --> 00:02:42,180
我们假设我们对于参数有前置信念（prior belief）

36
00:02:42,180 --> 00:02:46,530
当然在这个例子中 我们不仅要关注数据

37
00:02:47,910 --> 00:02:52,460
还要考虑先验

38
00:02:54,150 --> 00:02:59,600
这里的先验由P(Ɵ)定义

39
00:02:59,600 --> 00:03:05,810
即 我们对某些Ɵ值施加倾向

40
00:03:06,860 --> 00:03:10,490
通过使用贝叶斯定理 如图所示

41
00:03:12,630 --> 00:03:18,130
我们可以组合出似然函数

42
00:03:18,130 --> 00:03:22,310
将先验考虑进去

43
00:03:23,730 --> 00:03:29,140
我们得到这样的参数后验概率

44
00:03:29,140 --> 00:03:34,090
完整的贝叶斯定理的解释及相关证明

45
00:03:34,090 --> 00:03:39,330
超出了课程的范围

46
00:03:39,330 --> 00:03:42,140
不过我要在这里做一个简单的介绍

47
00:03:42,140 --> 00:03:44,870
因为这是很有用的常识

48
00:03:44,870 --> 00:03:49,220
贝叶斯定理的基本定义如ppt所示

49
00:03:49,220 --> 00:03:54,320
它使我们能够用给定X条件下的Y的概率

50
00:03:54,320 --> 00:04:00,330
表述给定Y时X的条件概率

51
00:04:00,330 --> 00:04:03,060
你可以看到这2个概率

52
00:04:03,060 --> 00:04:08,480
在2个变量的顺序上是不同的

53
00:04:09,650 --> 00:04:14,936
但是这个定理通常用于推导变量

54
00:04:14,936 --> 00:04:23,070
让我们再来看看

55
00:04:23,070 --> 00:04:30,680
我们假设p(X)表述的是我们对于X的先验信念

56
00:04:30,680 --> 00:04:35,250
即在观察到任何其他数据之前
我们已经对X有了信念(belief)

57
00:04:35,250 --> 00:04:39,330
--我们相信X取某些值的概率比其他值更高

58
00:04:40,720 --> 00:04:45,580
然后 这里是给定Y条件下的X的概率

59
00:04:45,580 --> 00:04:50,910
这是一个条件概率
也是我们关于X的后验信念

60
00:04:50,910 --> 00:04:57,850
因为这是我们观察到Y之后对于X值分布的信念

61
00:04:57,850 --> 00:05:02,780
在已经观察到了Y之后
现在我们对X的信念是什么？

62
00:05:02,780 --> 00:05:08,450
我们仍然相信取某些值的概率比其他值率高么？

63
00:05:09,970 --> 00:05:14,720
现在这2个概率通过这个概率联系到一起

64
00:05:14,720 --> 00:05:18,860
这个概率可以看成

65
00:05:19,890 --> 00:05:26,685
对于特定的X 观察到的证据Y的概率

66
00:05:26,685 --> 00:05:30,845
你可以将X看成我们的假设

67
00:05:30,845 --> 00:05:35,155
对于选择哪个假设我们事先有一些想法

68
00:05:35,155 --> 00:05:40,470
观察到Y之后 我们将修正我们的信念

69
00:05:40,470 --> 00:05:46,300
修正的公式基于

70
00:05:48,390 --> 00:05:56,010
先验和X确实为真的条件下观察到的Y的可能性
的组合

71
00:05:57,200 --> 00:06:02,250
关于贝叶斯定理的解释先到这里

72
00:06:02,250 --> 00:06:07,550
本课程中 我们感兴趣的是推导Ɵ

73
00:06:07,550 --> 00:06:14,600
我们的先验在这里
它包括参数相关的先验知识

74
00:06:15,640 --> 00:06:18,970
然后我们还有数据似然值  这里

75
00:06:18,970 --> 00:06:23,740
它能告诉我们
怎样的参数值能恰当地解释数据

76
00:06:23,740 --> 00:06:28,590
而后验概率结合两者

77
00:06:30,220 --> 00:06:34,400
所以它体现了这两种倾向的折衷

78
00:06:34,400 --> 00:06:41,072
在这种情况下 我们可以将后验概率最大化

79
00:06:41,072 --> 00:06:47,800
以寻求将后验概率最大化的Ɵ

80
00:06:47,800 --> 00:06:54,380
这种估计方法叫做最大后验估计
简称MAP估计

81
00:06:55,470 --> 00:06:58,520
这种估计方法

82
00:06:58,520 --> 00:07:02,860
比极大似然估计更通用

83
00:07:02,860 --> 00:07:08,700
因为如果我们定义的先验不包含任何信息

84
00:07:08,700 --> 00:07:11,950
即意味着所有Ɵ值的均匀分布 没有偏向

85
00:07:11,950 --> 00:07:16,880
则我们实际上就回到了极大似然估计

86
00:07:16,880 --> 00:07:21,270
这种情况下 它将主要取决于似然值

87
00:07:21,270 --> 00:07:25,470
与这里一样

88
00:07:28,450 --> 00:07:33,960
但是如果我们有包含信息的先验

89
00:07:33,960 --> 00:07:39,660
有对于不同值的偏向
则MAP估计能使我们利用这些信息

90
00:07:39,660 --> 00:07:43,120
当然 这里的问题是如何定义先验

91
00:07:44,140 --> 00:07:49,460
没有免费的午餐
如果我们想要利用更多的知识来解决问题

92
00:07:49,460 --> 00:07:51,160
我们必须先有这些知识

93
00:07:51,160 --> 00:07:54,330
而且在理想情况下
这些知识应当是可靠的

94
00:07:54,330 --> 00:07:58,340
否则你的估计不一定

95
00:07:58,340 --> 00:07:59,499
比极大似然估计的结果更精确

96
00:08:01,160 --> 00:08:06,890
现在让我们来详细看看贝叶斯估计

97
00:08:08,070 --> 00:08:12,720
我将Ɵ值以一维数值来表示

98
00:08:12,720 --> 00:08:18,040
这当然经过了简化

99
00:08:18,040 --> 00:08:24,550
我们感兴趣的是哪个Ɵ值最优

100
00:08:24,550 --> 00:08:26,870
首先 我们有先验

101
00:08:26,870 --> 00:08:29,980
先验告诉我们 

102
00:08:29,980 --> 00:08:33,133
我们相信某些值比其他值具有更大可能性

103
00:08:33,133 --> 00:08:38,710
比如 这些值就比这里的值更有可能

104
00:08:38,710 --> 00:08:40,950
或者这里 或者其他地方

105
00:08:42,050 --> 00:08:45,907
这是我们的先验

106
00:08:45,907 --> 00:08:51,440
然后我们还有Ɵ分布概率

107
00:08:51,440 --> 00:08:56,800
这条曲线中的数据也会告诉我们
哪些Ɵ值可能性更大

108
00:08:56,800 --> 00:08:59,710
即那些能最好地解释我们的数据的Ɵ值

109
00:09:01,850 --> 00:09:05,100
那么当我们结合两者 就得到了后验分布

110
00:09:05,100 --> 00:09:07,810
这就是两者的某种折衷

111
00:09:07,810 --> 00:09:11,960
如图所示 它的值在两者之间

112
00:09:11,960 --> 00:09:16,540
现在让我们来看下一些有趣的Ɵ估计值点

113
00:09:16,540 --> 00:09:21,270
这个点表示先验众数
即在观察到任何数据之前

114
00:09:21,270 --> 00:09:24,160
根据我们的先验取得的最有可能的Ɵ值

115
00:09:25,180 --> 00:09:27,550
这个点表示极大似然估计值

116
00:09:27,550 --> 00:09:31,350
它表示获得最大概率时的Ɵ值

117
00:09:32,390 --> 00:09:36,400
现在 这个点很有趣 这是后验众数

118
00:09:38,960 --> 00:09:43,740
这是根据后验分布得到的最有可能的Ɵ取值

119
00:09:43,740 --> 00:09:48,470
它代表了先验众数和极大似然估计的

120
00:09:48,470 --> 00:09:49,820
一种好的折衷

121
00:09:51,480 --> 00:09:55,930
总的来说 在贝叶斯推断中 
我们感兴趣的是

122
00:09:55,930 --> 00:09:59,340
你见到的所有这些参数值的分布

123
00:09:59,340 --> 00:10:04,648
如果已经有了一个Ɵ值的分布

124
00:10:04,648 --> 00:10:07,880
这里  P(Ɵ|X)

125
00:10:09,120 --> 00:10:13,060
则贝叶斯推断的问题是

126
00:10:14,310 --> 00:10:18,970
推导这个后验分布 这个区间

127
00:10:18,970 --> 00:10:24,780
以及其他依赖于Ɵ的有趣的量

128
00:10:24,780 --> 00:10:27,990
所以 在这里我给出了f(Ɵ)

129
00:10:27,990 --> 00:10:30,780
作为我们想要计算的一个有趣的变量

130
00:10:30,780 --> 00:10:34,640
但是为了计算这些值 我们需要知道Ɵ的值

131
00:10:34,640 --> 00:10:39,620
在贝叶斯推断中  我们将Ɵ视为不确定变量

132
00:10:39,620 --> 00:10:42,870
所以我们要考虑Ɵ的所有可能取值

133
00:10:42,870 --> 00:10:50,060
因此我们把
根据给定观察证据X条件下 Ɵ的后验分布

134
00:10:50,060 --> 00:10:57,040
得到的 f的期望值作为 f的估计值

135
00:10:58,060 --> 00:11:04,620
作为一个特例 我们假设f(Ɵ) = Ɵ

136
00:11:04,620 --> 00:11:08,320
则我们得到的是Ɵ的期望值

137
00:11:08,320 --> 00:11:11,130
实际上就是Ɵ的后验均值

138
00:11:11,130 --> 00:11:15,530
这个值也对应一个Ɵ点

139
00:11:15,530 --> 00:11:19,890
这个点有时与后验众数（mode）一致 
但并非总是如此

140
00:11:19,890 --> 00:11:22,870
所以 它也给出了参数估计的另一种方法

141
00:11:24,450 --> 00:11:29,220
以上就是贝叶斯估计及其相关内容

142
00:11:29,220 --> 00:11:33,920
之后 你会看到它在

143
00:11:33,920 --> 00:11:39,500
主题挖掘当中的应用
因为我们想要在其中注入关于主题的先验知识

144
00:11:39,500 --> 00:11:43,560
总结： 我们使用了语言模型

145
00:11:43,560 --> 00:11:46,350
即文本中的概率分布

146
00:11:46,350 --> 00:11:48,670
又被称为文本数据的生成模型

147
00:11:48,670 --> 00:11:51,980
最简单的语言模型是一元语法模型

148
00:11:51,980 --> 00:11:53,390
即单词分布

149
00:11:54,740 --> 00:11:57,840
我们介绍了似然函数的概念

150
00:11:57,840 --> 00:12:00,809
即给定模型下的数据的概率

151
00:12:02,260 --> 00:12:03,880
这个函数非常重要

152
00:12:05,520 --> 00:12:09,860
给定特定参数值 这个函数能告诉我们哪个X值

153
00:12:09,860 --> 00:12:13,120
哪个数据点有更高的似然值 更高的概率

154
00:12:16,750 --> 00:12:22,700
给定X的样本 我们能用这个函数确定

155
00:12:22,700 --> 00:12:27,840
哪些参数值能使观察数据概率最大化

156
00:12:27,840 --> 00:12:29,640
这是极大似然估计的情形

157
00:12:31,050 --> 00:12:34,360
我们也讨论了贝叶斯估计或贝叶斯推断

158
00:12:34,360 --> 00:12:39,110
其中 我们必须定义P(Ɵ)参数的先验

159
00:12:39,110 --> 00:12:43,340
接着我们关注参数的后验分布的计算

160
00:12:43,340 --> 00:12:47,820
其结果与先验和似然值成正比

161
00:12:48,962 --> 00:12:56,867
这样的分布又能使我们推导任意从Ɵ导出的值

162
00:12:56,867 --> 00:13:06,867
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community