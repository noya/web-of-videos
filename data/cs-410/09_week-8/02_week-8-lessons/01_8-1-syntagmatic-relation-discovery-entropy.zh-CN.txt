[声音] 本节课是关于组合关系发现和熵。 这节课我们将继续讨论文字联想挖掘。 尤其我们将会讨论如何发现组合关系。 同时我们将开始介绍熵。 它是发现这些关系的基础 根据传统宗教等等的定义即我们控制了库存水平 存在于文字间的组合关系有着相互关系的共生。 那意味着，当我们在一段文字中看见一个词时， 我们往往能看见其他词的出现。 那么来看个更具体的例子。 我们可以问， 当出现“吃”的时候，哪些词可能也会出现？ 在左边的句子里我们可以看到这些词也可能出现 和“吃”一起的有猫，狗或鱼都是对的。 但如果把他们拿出来看右边的部分 只显示“吃”和其他词语，问题就变成 你能猜到左右会出现什么词吗？ 对所以这会迫使我们去思考 有哪些其他词语和吃相关。 如果它们可以和“吃”相联系，它们很可能也会出现在“吃”的上下文中。 更明确一点说，我们的预测问题就是去 搜寻关于文字的部分，它可以是一个句子，一个段落或者一篇文章。 然后提问 是否有一个特定的词在片段中 出现或不出现 现在我们提问的这个词为W W在片段中出现还是不出现 有趣的地方在于 某些词比别的词更容易预测 请看这里显示的三个词 '肉' '那个' '独角兽' 你认为哪一个词更容易预测 如果你稍微想一些可能有结论 '那个'(the)更容易预测因为它到处都是 所以我可以直接说那个词(the)会在句子里出现 独角兽也相对简单 因为独角兽少见 非常少见 所以我可以打赌它不在句子里出现 但肉在出现频率上就在两者之间了 这使得预测它在句子中是否出现变得难了 或者准确说 在片段中 但它也可能不在句子中出现 现在我们来正式地研究这个问题 问题可以被形式化定义为 预测一个二元随机变量的值 这里我们记为X(w) w代表一个词 所以这个随机变量精确地联系了一个词 当该随机变量值为1 意味着这个词出现 当它是0 意味着词不出现 自然地 0和1的概率求和应该为1 因为片段中一个词要么出现要么不出现 没有其他选择 所以前面这个直觉上的概念可以形式化表示如下 这个随机变量的随机程度越强 预测的难度越难 现在的问题是如何量化测量随机程度 对类似X(w)这样的随机变量 如何在一般意义上 量化一个变量的随机程度 因此我们需要一个叫熵的度量 这个度量从信息论引入 用于度量X的随机程度 这与信息论也有某种关联 但超出了本节课范围 出于我们的目的只把熵函数 看做定义在随机变量上的一个函数 在这个例子里 是一个二元随机变量 虽然定义可以容易推广多个值的随机变量 函数形式是这个样子的 对所有随机变量的取值求和 在求和函数内我们有概率的乘积 是对随机变量的值等于这个值的概率的对数 注意这里还有个负号 熵一般情况下是非负的 可以从数学上证明 如果我们把求和展开 我们会看到第二个公式的样子 这里我明确地写出了两个值 0 和 1 有时我们会遇到对0求对数 我们一般会把那个定义为0 因为0的对数值未定义 这就是熵函数 这个函数有不同的值 对应到这个随机变量的不同分布 它很明显依赖于 随机变量取0或1的概率值 如果我们画出这个函数 对照随机变量取1的概率 函数是这样子的 在两个末端 意味着X为1的概率 非常小或非常大 熵函数有很小的值 当(概率)为0.5时(熵)取到最大值 如果我们把函数对照上 X取0的情况 会有一摸一样的曲线 你可以想象出原因 因此 两个概率是对称的 完全对称 因此可以想到一个有趣的问题是 什么样子的X使得熵取最大或者最小值 我们可以考虑一些特殊情况 例如 考虑我们有一个随机变量 永远取值为1 概率值为1 或者有一个随机变量 以相同的概率等于0或1 这是X等于1的概率为0.5 哪种情况的熵更高 为了简化思考问题可以用一个简单的例子 抛硬币 所以考虑抛一个硬币的随机实验 这就给了我们一个可以代表结果的随机变量 可以是正(head)或者反(tail) 所以我们可以定义一个随机变量X(coin) 硬币正面朝上时为1 反面朝上时为0 现在我们可以计算这个随机变量的熵了 这个熵显示了预测抛硬币结果的 困难程度 可以考虑两种情况 一是均匀的硬币 完美的均匀 硬币正面和反面朝上的次数很可能相等 所以两个概率应该是对半 对不对 所以都等于0.5 另一个极端例子是完全偏斜的硬币 例如硬币永远正面朝上 这时它是完全偏斜的 考虑两种情况里的熵 把值代入后你可以看到熵值如下 均匀硬币可以看到熵达到最大值1 完全偏斜的硬币 可以看到为0 这个很符合直觉 因为完美硬币是最难预测的 对应完全偏斜的硬币是很容易预测的 我们总是可以说 这是正面 因为它所有时间都是正面 所以在曲线上显示如下 完美硬币对应到中间点 它是非常不确定的 完全偏斜的的硬币对应到末端 那里我们有概率为1.0并且熵为0 现在看我们如何利用熵来做词预测 我们的问题是预测W在片段中 出现或不出现 再一次用(前面的)三个词 考虑它们的熵 现在我们可以假设熵更高的词更难预测 因此我们现在有一个定量的方式来告诉我们哪个词更难预测 现在再看三个词 肉 那个 独角兽 我们显然会期望肉比独角兽有更高的熵 事实上 如果你看'那个'的熵 它接近于零 因为它到处都出现 它就像一个完全偏斜的硬币 因此熵为0 [背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community