1
00:00:00,401 --> 00:00:07,552
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community

2
00:00:07,552 --> 00:00:10,524
这个讲座是关于
背景文本挖掘中的一个特定技术

3
00:00:10,524 --> 00:00:16,097
叫做背景概率性隐性语义分析

4
00:00:19,162 --> 00:00:23,930
这节课我们继续讨论背景文本挖掘

5
00:00:23,930 --> 00:00:28,990
我们会介绍背景概率性隐性语义分析

6
00:00:28,990 --> 00:00:32,630
作为背景文本挖掘中词性分析的补充

7
00:00:34,390 --> 00:00:40,310
回想在背景文本挖掘中
我们希望在考虑背景的情况下

8
00:00:40,310 --> 00:00:42,285
分析文本中的话题

9
00:00:42,285 --> 00:00:46,950
这样我们能够将背景特征中有趣的内容联系起来

10
00:00:48,240 --> 00:00:54,033
那么在背景概率性隐性语义分析(CPLSA)这个方法当中

11
00:00:54,033 --> 00:00:58,487
核心就是
将这些背景特征

12
00:00:58,487 --> 00:01:01,890
作为变量加入到生成的模型当中

13
00:01:03,150 --> 00:01:06,860
想想之前我们生成文本的时候
我们假设

14
00:01:06,860 --> 00:01:10,730
我们会从一些话题开始
然后从这些话题中引申出合适的单词

15
00:01:10,730 --> 00:01:18,130
但是这里我们需要加入背景的变量
因此话题的覆盖面

16
00:01:18,130 --> 00:01:23,500
和话题的内容在背景中会联系在一起

17
00:01:23,500 --> 00:01:27,607
换句话说，背景可以影响话题的覆盖面

18
00:01:27,607 --> 00:01:28,900
和话题的内容

19
00:01:31,172 --> 00:01:37,370
这样做的结果就是
我们可以得到背景下的话题

20
00:01:37,370 --> 00:01:41,320
让话题变得更有趣
更有意义

21
00:01:41,320 --> 00:01:46,120
因为我们得到的话题
会是针对

22
00:01:46,120 --> 00:01:49,070
我们感兴趣的一个特定背景

23
00:01:49,070 --> 00:01:50,590
例如，一个特定的时间段

24
00:01:52,020 --> 00:01:55,639
作为概率性隐性语义分析(PLSA)的一个拓展

25
00:01:55,639 --> 00:02:01,330
背景概率性隐性语境分析(CPLSA)有如下不同

26
00:02:01,330 --> 00:02:05,770
首先模型会对
给定背景下的条件概率进行建模

27
00:02:07,110 --> 00:02:12,990
这表明文本的生成
会受到背景的影响

28
00:02:12,990 --> 00:02:16,520
我们就可以将背景
加入到生成模型当中

29
00:02:18,230 --> 00:02:22,300
其次，这种方法对话题和背景的相关性

30
00:02:22,300 --> 00:02:24,650
提出了两点假设

31
00:02:24,650 --> 00:02:28,420
第一个假设是
在不同的背景、不同的时间段

32
00:02:28,420 --> 00:02:33,630
或不同的地点
我们假设对于一个话题的观点

33
00:02:33,630 --> 00:02:37,370
或是描述话题使用的词汇会有不同

34
00:02:38,540 --> 00:02:42,260
这个假设允许
同一话题

35
00:02:42,260 --> 00:02:45,430
在不同语境下有不同的表述

36
00:02:46,500 --> 00:02:53,059
另一个假设是
我们假设话题的覆盖面与背景相关

37
00:02:55,150 --> 00:02:56,810
这意味着

38
00:02:56,810 --> 00:02:59,630
在不同时间或是地点
话题的范围可以有所不同

39
00:03:00,670 --> 00:03:03,890
也就是说，这种相关性
可以

40
00:03:03,890 --> 00:03:08,680
涵盖话题与特定背景的联系

41
00:03:08,680 --> 00:03:14,540
我们依然可以利用期望最大化（EM）
来进行参数求解

42
00:03:16,280 --> 00:03:22,520
这种情形下
估计参数自然会包含背景变量

43
00:03:22,520 --> 00:03:23,590
尤其是

44
00:03:23,590 --> 00:03:29,940
一系列话题的条件概率
可以刻画特定的语境

45
00:03:29,940 --> 00:03:33,090
也就可以进行背景文本挖掘了

46
00:03:33,090 --> 00:03:34,610
这就是基本思路

47
00:03:35,750 --> 00:03:41,470
现在我们没时间
细讲这个模型

48
00:03:41,470 --> 00:03:45,700
不过有不少参考材料
可以提供更多的细节

49
00:03:45,700 --> 00:03:52,120
这里我只想多讲一下
模型宏观上的想法

50
00:03:52,120 --> 00:03:55,610
尤其是生成过程

51
00:03:55,610 --> 00:04:00,330
利用具有相关背景的
文本数据建模的过程

52
00:04:01,550 --> 00:04:05,660
我们假设存在多个话题

53
00:04:05,660 --> 00:04:11,410
一些话题可能代表一个主题
比如政府回应

54
00:04:11,410 --> 00:04:14,270
捐赠或是新奥尔良

55
00:04:14,270 --> 00:04:18,803
现在这个例子
是在卡特里娜飓风的背景下

56
00:04:18,803 --> 00:04:20,570
飓风袭击了新奥尔良

57
00:04:22,915 --> 00:04:27,400
你能看到

58
00:04:27,400 --> 00:04:31,548
每个话题下有与之相关的不同观点

59
00:04:31,548 --> 00:04:36,530
这里显示为观点1、观点2、观点3

60
00:04:36,530 --> 00:04:41,475
每一个观点都有不同的单词分布

61
00:04:41,475 --> 00:04:44,715
这些观点与一些背景变量相联系

62
00:04:44,715 --> 00:04:50,125
比如跟德克萨斯这个位置
或是2005年7月

63
00:04:50,125 --> 00:04:54,475
再或是作者是个社会学家

64
00:04:56,205 --> 00:05:01,560
右边我们假设
文档有背景的相关信息

65
00:05:01,560 --> 00:05:04,370
时间是2005年7月

66
00:05:04,370 --> 00:05:06,710
地点是德克萨斯州等等

67
00:05:06,710 --> 00:05:11,410
这些背景信息
我们也希望加入模型当中

68
00:05:11,410 --> 00:05:13,300
这样我们就不只对文本建模

69
00:05:15,100 --> 00:05:20,980
这里我们的目标是
对热点内容和变化内容的差异进行建模

70
00:05:20,980 --> 00:05:21,920
和变化的内容进行建模

71
00:05:21,920 --> 00:05:25,970
这为我们提供了不同观点的单词分布

72
00:05:27,720 --> 00:05:32,360
现在在底端你可以看到
主题覆盖的主要内容

73
00:05:32,360 --> 00:05:39,310
也会根据背景发生变化
因为

74
00:05:39,310 --> 00:05:44,320
像例子中的德克萨斯州
人们可能更关注红色的话题

75
00:05:44,320 --> 00:05:46,130
这是新奥尔良

76
00:05:46,130 --> 00:05:47,690
这是可视化情况

77
00:05:47,690 --> 00:05:50,930
但在特定的时间段

78
00:05:50,930 --> 00:05:56,280
也许某一个话题
会被更多提及

79
00:05:56,280 --> 00:06:00,980
这种差异
在背景概率性隐性语义分析也有所考虑

80
00:06:00,980 --> 00:06:07,685
因此生成含有背景的搜索文档
需要选择一个观点

81
00:06:08,695 --> 00:06:14,055
这个观点可能来自
背景中的任何一个

82
00:06:14,055 --> 00:06:17,080
比如我们考虑时间带来的观点上的差异

83
00:06:17,080 --> 00:06:18,310
中间这里

84
00:06:18,310 --> 00:06:21,850
现在我们有了一个单词的特定分布

85
00:06:21,850 --> 00:06:25,030
现在你可以看到单词在各个话题中的概率

86
00:06:26,710 --> 00:06:28,830
一旦选择一个观点

87
00:06:28,830 --> 00:06:34,400
情况跟标准的概率性隐性语义分析(PLSA)模型很接近

88
00:06:34,400 --> 00:06:38,860
我们假设我们已经有了单词分布跟各个话题之间的联系，对吧？

89
00:06:39,870 --> 00:06:43,070
现在下一步是从底下选择一个范围

90
00:06:43,070 --> 00:06:47,988
我们选择一个特定范围

91
00:06:47,988 --> 00:06:55,305
这个在之前的概率性隐性语义分析(PLSA)模型里是固定的
针对一个特定的文档

92
00:06:55,305 --> 00:06:57,825
每个文档有自己
覆盖内容的分布

93
00:06:58,885 --> 00:07:03,925
现在这里我们考虑背景
因此话题的分布或者话题涵盖内容

94
00:07:03,925 --> 00:07:08,770
可以根据影响覆盖面的背景变化

95
00:07:10,020 --> 00:07:13,470
比如，我们可以选择
一个特定的范围

96
00:07:13,470 --> 00:07:19,090
这个例子里我们选了
一个针对文档的范围

97
00:07:20,590 --> 00:07:23,440
有了这个范围
以及单词分布

98
00:07:23,440 --> 00:07:26,590
我们可以向PLSA一样
生成一个文档

99
00:07:26,590 --> 00:07:32,450
这就意味着
我们可以利用范围去选择话题

100
00:07:32,450 --> 00:07:34,880
去选择三个话题中的一个

101
00:07:34,880 --> 00:07:38,230
比方说我们已经选择了黄色话题

102
00:07:38,230 --> 00:07:43,450
然后我们从这个话题顶端选择一个单词

103
00:07:44,760 --> 00:07:46,880
那么我们可以得到一个单词
比如政府(government)

104
00:07:46,880 --> 00:07:50,840
然后我们可以
选个不同话题

105
00:07:50,840 --> 00:07:53,640
比如得到捐赠(donate)这个词等等

106
00:07:53,640 --> 00:07:55,550
直到我们得到所有的单词

107
00:07:55,550 --> 00:07:58,550
这跟概率性隐性语义分析基本是一样的

108
00:08:00,200 --> 00:08:05,220
最主要的区别是
我们得到了覆盖面

109
00:08:05,220 --> 00:08:11,250
以及单词分布
我们允许背景影响我们的选择

110
00:08:11,250 --> 00:08:16,050
换句话说我们可以提供新的分支
这些分支

111
00:08:16,050 --> 00:08:20,950
控制着不同话题中观点的选择
以及覆盖内容的选择

112
00:08:22,010 --> 00:08:25,430
自然模型中
我们可以估计更多的参数

113
00:08:25,430 --> 00:08:29,010
当我们估计包含背景的参数之后

114
00:08:29,010 --> 00:08:33,080
我们就可以理解背景下话题中的观点

115
00:08:33,080 --> 00:08:36,020
或是背景下话题的覆盖范围

116
00:08:36,020 --> 00:08:38,850
这正是我们在背景文本挖掘中想要的

117
00:08:40,450 --> 00:08:42,950
这里是一些简单的结果

118
00:08:42,950 --> 00:08:44,340
使用这个模型

119
00:08:44,340 --> 00:08:48,240
不一定是一模一样的
但是类似的模型

120
00:08:48,240 --> 00:08:50,860
这一页上你可以看到
一些简单的结果

121
00:08:50,860 --> 00:08:54,950
比较了关于伊拉克战争和阿富汗战争的新闻

122
00:08:56,315 --> 00:09:02,855
我们有关于伊拉克战争的30篇文章
关于阿富汗战争的26篇文章

123
00:09:02,855 --> 00:09:08,852
这里
目标是寻找共同话题

124
00:09:08,852 --> 00:09:11,332
就是在两组文章中都涉及的内容

125
00:09:11,332 --> 00:09:17,352
比较两组文章中话题内容上变化的差异

126
00:09:18,622 --> 00:09:23,400
这里背景对应到
话题和文章集合层面

127
00:09:25,040 --> 00:09:30,420
我们从这里的结果看到
两组有一个共同的

128
00:09:30,420 --> 00:09:36,040
主题
对应这列里的聚类1

129
00:09:36,040 --> 00:09:42,260
另外一个共同的主题之处
两次战争都有联合国参与

130
00:09:42,260 --> 00:09:45,630
这是两组文章中都提到的一个话题

131
00:09:45,630 --> 00:09:48,970
体现在这里的高概率词
united

132
00:09:48,970 --> 00:09:49,860
和nations

133
00:09:51,160 --> 00:09:54,680
现在如果你了解了背景
这并不令人惊讶

134
00:09:54,680 --> 00:10:00,340
这个话题的确与两次战争非常相关

135
00:10:00,340 --> 00:10:04,900
如果你看接下来这列
有趣的是

136
00:10:04,900 --> 00:10:09,336
两个关于单词分布的单元格告诉我们

137
00:10:09,336 --> 00:10:14,790
在联合国这一话题上两组文章的差别

138
00:10:14,790 --> 00:10:16,660
数据表明伊拉克战争中

139
00:10:16,660 --> 00:10:21,060
联合国更多参与到武器内斗当中

140
00:10:21,060 --> 00:10:25,710
而在阿富汗战争中
则是对于北约的救助

141
00:10:25,710 --> 00:10:29,060
这就是联合国这一话题下的不同变化

142
00:10:30,100 --> 00:10:33,140
这就是加入背景的影响

143
00:10:33,140 --> 00:10:36,215
在这里就是指不同的战争
不同的集合

144
00:10:36,215 --> 00:10:40,034
我们可以将变化联系到背景当中

145
00:10:40,034 --> 00:10:45,250
评论联合国在两次战争中覆盖面上的差异

146
00:10:46,290 --> 00:10:50,200
现在你同样可以考虑第二个聚类2

147
00:10:50,200 --> 00:10:52,710
这跟贫民伤亡事件有关

148
00:10:52,710 --> 00:10:56,320
如果你了解战争背景同样不会意外

149
00:10:56,320 --> 00:10:59,660
两次战争都有死亡

150
00:10:59,660 --> 00:11:03,640
但是想象你对文本集并不了解

151
00:11:03,640 --> 00:11:05,120
我们有许多文章

152
00:11:05,120 --> 00:11:10,230
通过这个技术
我们可以看到两个集合中共同的话题

153
00:11:10,230 --> 00:11:14,715
这个方法也可以
分析多个文章集合之中的共同话题

154
00:11:14,715 --> 00:11:19,581
当然如果你看
聚类2这列

155
00:11:19,581 --> 00:11:26,143
你可以看到死亡信息
在不同背景中的变化

156
00:11:28,279 --> 00:11:31,582
这里是另一个例子的结果

157
00:11:31,582 --> 00:11:36,440
是来自有关卡特尼娜飓风的博客文章

158
00:11:37,470 --> 00:11:42,320
这里你可以看到

159
00:11:42,320 --> 00:11:46,090
话题的时间趋势的可视化结果

160
00:11:47,240 --> 00:11:52,980
最上面显示的是
有关两个话题的时间趋势

161
00:11:52,980 --> 00:11:58,980
一个是油价，还有一个是关于新奥尔良市的洪水。

162
00:12:00,060 --> 00:12:06,280
这些话题都是从有关卡特里娜飓风的博客中得到的

163
00:12:07,300 --> 00:12:09,395
人们谈论这些话题

164
00:12:09,395 --> 00:12:12,370
并最终传递给一些其他的话题

165
00:12:12,370 --> 00:12:15,000
不过从可视化结果来看
通过这个技术

166
00:12:15,000 --> 00:12:18,020
我们可以看到时间上的条件分布

167
00:12:18,020 --> 00:12:19,660
给定一个话题

168
00:12:19,660 --> 00:12:23,420
我们可以画出
这个条件概率

169
00:12:23,420 --> 00:12:26,000
曲线就是像你看到的这样

170
00:12:26,000 --> 00:12:31,560
我们可以看到
两条曲线同步状况很好

171
00:12:31,560 --> 00:12:40,010
不过在后段我们可以看到
新奥尔良又被提到而油价却没有

172
00:12:40,010 --> 00:12:44,060
这是在另一个时间段

173
00:12:44,060 --> 00:12:49,010
另一个飓风
飓风丽塔也袭击了这个区域

174
00:12:49,010 --> 00:12:52,470
而这显然引发了更多关于这个城市的洪水的讨论。

175
00:12:54,900 --> 00:13:00,010
底部的曲线显示
这个城市洪水的覆盖面

176
00:13:00,010 --> 00:13:05,320
这个分析来自不同地区的博客文章

177
00:13:05,320 --> 00:13:11,620
从这里也能看出
覆盖面的变化可能是由于

178
00:13:11,620 --> 00:13:19,150
人们从路易斯安那迁移到德克萨斯等原因

179
00:13:20,570 --> 00:13:25,650
这里我们可以看到时间
可以作为背景

180
00:13:25,650 --> 00:13:26,150
其中之一生成

181
00:13:27,780 --> 00:13:33,070
我们还可以得到额外的结果
是关于空间模式的

182
00:13:33,070 --> 00:13:37,850
这个例子里
是关于政府回应这一话题

183
00:13:37,850 --> 00:13:41,690
有一些关于卡特里娜飓风中

184
00:13:41,690 --> 00:13:42,649
政府反应慢的批评

185
00:13:44,020 --> 00:13:48,280
这个讨论
覆盖于不同的区域

186
00:13:48,280 --> 00:13:54,260
这些可视化结果说明了
时间过后不同星期的覆盖面情况

187
00:13:54,260 --> 00:13:59,610
最初这一话题
多出现南部受灾区域

188
00:13:59,610 --> 00:14:05,530
之后逐渐蔓延到其他地方

189
00:14:05,530 --> 00:14:09,760
不过第四周时
在左下方这里

190
00:14:09,760 --> 00:14:14,370
我们看到跟左上方第一周的情况类似的样式

191
00:14:14,370 --> 00:14:18,700
这正是
丽塔飓风再次侵袭该地区的时候

192
00:14:18,700 --> 00:14:22,540
所以说这个技术允许
我们将位置作为背景

193
00:14:22,540 --> 00:14:24,960
检验有关话题的相关问题

194
00:14:24,960 --> 00:14:27,280
当然这种模式在理论上是一般性的

195
00:14:27,280 --> 00:14:30,980
可以用于文本中的任何联系

196
00:14:30,980 --> 00:14:32,850
考察时间和空间的格局

197
00:14:34,460 --> 00:14:37,390
这也就引出了这类模型的另一个应用

198
00:14:37,390 --> 00:14:41,960
我们可以利用模型进行事件影响分析

199
00:14:43,290 --> 00:14:46,370
这里我们考虑有关信息检索的学术文章

200
00:14:46,370 --> 00:14:49,480
尤其是SIGIR(美国计算机协会情报检索专业组)的文章

201
00:14:49,480 --> 00:14:53,180
这里我们关注的是
检索模型

202
00:14:53,180 --> 00:14:58,440
你可以在左侧看到这一模型有关的高频词

203
00:14:59,580 --> 00:15:04,290
之后我们希望检验
两个事件的影响

204
00:15:04,290 --> 00:15:08,290
一个是TREC的开始,就是文本和检索会议

205
00:15:08,290 --> 00:15:11,459
这是一个美国政府赞助的评价项目

206
00:15:11,459 --> 00:15:16,722
1992年前后建立

207
00:15:16,722 --> 00:15:20,690
这一会议在

208
00:15:20,690 --> 00:15:22,790
学术信息检索领域有一定影响

209
00:15:23,870 --> 00:15:28,680
另一个开创性文章
是由Croft和Porte所做

210
00:15:28,680 --> 00:15:31,850
这是一个有关信息检索的语言模型

211
00:15:31,850 --> 00:15:36,440
文章对信息检索研究也有很大影响

212
00:15:36,440 --> 00:15:39,780
我们希望能够利用这类模型理解影响

213
00:15:39,780 --> 00:15:44,090
想法就是将时间作为背景

214
00:15:44,090 --> 00:15:48,585
然后利用这些事件区分
事件之前

215
00:15:48,585 --> 00:15:51,397
事件当中和
事件之后

216
00:15:51,397 --> 00:15:54,417
然后我们比较话题上的不同

217
00:15:54,417 --> 00:15:57,875
覆盖面和变化等等

218
00:15:57,875 --> 00:16:02,750
之前我们提到的检索模型

219
00:16:02,750 --> 00:16:07,120
大多是向量空间模型
布尔模型等等

220
00:16:07,120 --> 00:16:08,800
但是TREC之后

221
00:16:08,800 --> 00:16:13,975
检索模型加入了更多的字样

222
00:16:13,975 --> 00:16:18,440
这包括不同的检索任务

223
00:16:18,440 --> 00:16:22,980
比如企业内部邮件的检索

224
00:16:22,980 --> 00:16:26,550
另外TREC也引入了子话题检索

225
00:16:28,200 --> 00:16:32,461
在底部我们可以看到变化情况

226
00:16:32,461 --> 00:16:36,300
与语言模型论文的发展相关

227
00:16:36,300 --> 00:16:40,631
之前我们有那些古典概率风险模型

228
00:16:40,631 --> 00:16:44,600
逻辑模型、布尔模型等等
但是1998年之后

229
00:16:44,600 --> 00:16:50,430
我们看到概率模型成为了语言模型的主流

230
00:16:50,430 --> 00:16:54,580
我们看到了语言模型
参数估计这些词

231
00:16:54,580 --> 00:17:00,764
所以说这个技术主要利用事件
作为背景理解事件的影响

232
00:17:00,764 --> 00:17:03,403
这个技术是一般化的

233
00:17:03,403 --> 00:17:07,370
因此你可以用在任何事件影响的分析上

234
00:17:07,370 --> 00:17:10,240
这里是一些推荐阅读

235
00:17:11,940 --> 00:17:20,090
第一篇是关于交叉标记文章集比较

236
00:17:21,270 --> 00:17:24,610
是利用比较性文本挖掘

237
00:17:24,610 --> 00:17:27,410
提前多个文集中的共同话题

238
00:17:27,410 --> 00:17:29,930
在各个文集中有一定变化

239
00:17:31,010 --> 00:17:35,540
第二篇文章是CPLSA模型的主要文章

240
00:17:35,540 --> 00:17:38,830
讨论了模型的许多应用

241
00:17:38,830 --> 00:17:44,889
第三篇包含样例中时间空间样式的许多细节

242
00:17:44,889 --> 00:17:47,679
是关于卡特里娜飓风的

243
00:17:47,679 --> 00:17:57,679
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community