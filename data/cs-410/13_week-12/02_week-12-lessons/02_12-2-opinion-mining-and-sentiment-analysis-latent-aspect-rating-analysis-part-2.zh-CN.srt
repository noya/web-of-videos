1
00:00:00,025 --> 00:00:05,363
[背景音乐]本节课接上一节

2
00:00:05,363 --> 00:00:12,997
关于潜在方面评分分析(LARA)的讨论

3
00:00:12,997 --> 00:00:18,440
之前我们讲了如何用两步法解决LARA的问题

4
00:00:18,440 --> 00:00:22,440
但我们先要做不同方面的分离

5
00:00:22,440 --> 00:00:26,856
之后我们利用一个潜在回归模型学习方面评分

6
00:00:26,856 --> 00:00:28,334
然后是权重

7
00:00:28,334 --> 00:00:33,372
现在也可以通过建立一个统一的生成模型

8
00:00:33,372 --> 00:00:35,478
来解决这个问题

9
00:00:35,478 --> 00:00:41,360
也就是我们不仅对
文本评分的生成进行建模

10
00:00:41,360 --> 00:00:45,030
也对文本的生成进行建模

11
00:00:45,030 --> 00:00:47,410
那么一个自然的方案就是利用话题模型

12
00:00:47,410 --> 00:00:49,350
对于给定的实体

13
00:00:49,350 --> 00:00:54,700
我们可以假设其中存在
由词汇分布描述的方面

14
00:00:54,700 --> 00:00:55,830
比如说话题

15
00:00:55,830 --> 00:01:00,550
之后我们利用一个话题模型
对评论文本的生成进行建模

16
00:01:01,592 --> 00:01:07,045
我将假设评论文本中的词
是从这些分布中抽出的

17
00:01:08,475 --> 00:01:12,265
如我们做PLSA(概率潜在语义分析)模型生成的假设一样

18
00:01:13,605 --> 00:01:18,470
之后我们代入到
潜在回归模型当中

19
00:01:18,470 --> 00:01:23,710
利用文本来进一步预测评分

20
00:01:23,710 --> 00:01:26,220
也就是说我们先预测方面评分

21
00:01:26,220 --> 00:01:30,520
然后将其与方面的权重结合起来
预测整体的评分

22
00:01:30,520 --> 00:01:34,280
这就为我们带来了一个统一的生成模型

23
00:01:34,280 --> 00:01:39,870
其中我们对文本生成和
基于文本的整体评分分别进行了建模

24
00:01:40,910 --> 00:01:46,150
这里我们没有时间细说这个模型

25
00:01:46,150 --> 00:01:51,990
像这节课其他部分的许多时候
讨论到前沿的话题一样

26
00:01:51,990 --> 00:01:55,940
但是这里有一个参考的网站
你可以了解更多的细节

27
00:01:57,130 --> 00:02:00,070
现在我将给你看一些
你能得到的简单结果

28
00:02:00,070 --> 00:02:02,760
利用这种生成模型

29
00:02:02,760 --> 00:02:05,450
首先是评分的分解

30
00:02:05,450 --> 00:02:09,070
这里你看到的
就是分解后的评分

31
00:02:09,070 --> 00:02:13,100
关于三个有相同整体评分的旅馆

32
00:02:13,100 --> 00:02:15,570
所以如果你只看整体评分

33
00:02:15,570 --> 00:02:18,980
你从这些酒店中
看不出什么区别

34
00:02:18,980 --> 00:02:24,270
但是当我们将这些评分
分解到各个方面的评分

35
00:02:24,270 --> 00:02:28,559
我们可以看到其中一些酒店
在某些方面有更高的评分

36
00:02:28,559 --> 00:02:33,580
比如价值
但是其他酒店在位置等其他维度上会有更高的评分

37
00:02:33,580 --> 00:02:37,680
这就给你们在方面层次上细致的意见

38
00:02:38,750 --> 00:02:42,940
现在真实情况显示在括号当中

39
00:02:42,940 --> 00:02:46,530
让你来看预测是否准确

40
00:02:46,530 --> 00:02:52,490
它不总是准确
但是通常能反映出一些趋势

41
00:02:53,490 --> 00:02:58,880
第二个结果是你可以比较同一酒店的不同的评论者

42
00:02:58,880 --> 00:03:05,490
这个表格展现的是两位评论者
对同一酒店的分解评分

43
00:03:05,490 --> 00:03:08,470
同样他们的整体评分是一样的

44
00:03:08,470 --> 00:03:13,440
所以如果你看整体评分
你得不到太多信息

45
00:03:13,440 --> 00:03:15,730
区分两位评论者之间的差别

46
00:03:15,730 --> 00:03:17,360
但是你分解评分之后

47
00:03:17,360 --> 00:03:21,870
你可以清楚看见
他们在不同的维度有高分

48
00:03:21,870 --> 00:03:26,030
这就体现出模型可以区分
不同评论者不同意见的差异

49
00:03:26,030 --> 00:03:30,260
这样一个深入的理解能够帮助我们

50
00:03:30,260 --> 00:03:35,960
更好理解评论者
以及他们对酒店的评论

51
00:03:35,960 --> 00:03:38,420
这点很有趣

52
00:03:38,420 --> 00:03:40,800
因为这某种程度上是些副产品

53
00:03:40,800 --> 00:03:43,900
在我们问题当中
我们并没有要做这件事

54
00:03:43,900 --> 00:03:47,770
但是生成模型的设计中有这个成分

55
00:03:47,770 --> 00:03:52,930
不同方面的单词具有情感权重

56
00:03:52,930 --> 00:03:58,750
你可以看到权重为正的词和权重为负的词

57
00:03:58,750 --> 00:04:01,190
针对四个维度中的一个

58
00:04:01,190 --> 00:04:05,310
价值、房间、位置和清洁度

59
00:04:05,310 --> 00:04:08,990
顶部的词显然很有意义
底部的词也有意义

60
00:04:10,230 --> 00:04:12,540
这说明在这种方法中

61
00:04:12,540 --> 00:04:16,300
我们可以从数据中直接获得情感的信息

62
00:04:16,300 --> 00:04:21,410
现在这种词素十分有用
因为通常像long这样的词

63
00:04:21,410 --> 00:04:26,240
在不同语境可能具有不同的情感极性

64
00:04:26,240 --> 00:04:31,270
比如我说笔记本电脑的电池时间长
这是正面的信息

65
00:04:31,270 --> 00:04:36,440
但我如果说电脑重启的时间长
这就是负面的信息对吧?

66
00:04:36,440 --> 00:04:40,210
所以即便是对同一种产品
比如说笔记本电脑

67
00:04:40,210 --> 00:04:46,010
long这个词的情感是模糊的
可能是正面的也可能是负面的

68
00:04:46,010 --> 00:04:50,500
但是对于这种词我们可以利用
这类生成模型

69
00:04:50,500 --> 00:04:55,810
来判断一个词是正面的还是负面的

70
00:04:55,810 --> 00:05:01,590
这显然很有用
实际上一个词可以用于

71
00:05:01,590 --> 00:05:04,810
标记其他有关酒店的评论或是

72
00:05:04,810 --> 00:05:07,890
标记推特等社交媒体上的评论

73
00:05:08,910 --> 00:05:15,030
另一件很有趣的事就是
这一过程几乎是无监督的

74
00:05:15,030 --> 00:05:20,450
假设评论中的整体评分是可用的

75
00:05:20,450 --> 00:05:24,400
这就可以让我们可以从互联网
一个更大的数据量中学习

76
00:05:24,400 --> 00:05:27,070
来找到情感词

77
00:05:28,190 --> 00:05:31,530
这里有一些验证偏好词的结果

78
00:05:31,530 --> 00:05:36,165
记着这个模型可以推断评论对服务

79
00:05:36,165 --> 00:05:37,550
还是价格更关心

80
00:05:37,550 --> 00:05:41,380
现在我们怎么知道推断的权重是否正确呢?

81
00:05:41,380 --> 00:05:45,500
这为评价带来了一个很大的挑战

82
00:05:45,500 --> 00:05:49,480
现在我们来看一些评估的有趣方法

83
00:05:50,840 --> 00:05:55,030
你这里看到的是不同城市酒店的价格

84
00:05:55,030 --> 00:06:01,010
这些是受到不同群组评论者青睐的酒店的价格

85
00:06:01,010 --> 00:06:04,400
排名前十位的是

86
00:06:04,400 --> 00:06:08,460
有最高推断价值-其他方面比率的评论者

87
00:06:09,600 --> 00:06:13,840
比如比较价值与位置
价值与房间等等

88
00:06:13,840 --> 00:06:20,110
现在前十位的评论者在这个衡量方法下有最高的比率

89
00:06:20,110 --> 00:06:23,210
这就是说这些评论者

90
00:06:23,210 --> 00:06:26,120
相比其他维度
在价值上有很大的权重

91
00:06:26,120 --> 00:06:28,760
这说明他们相当重视价值

92
00:06:30,430 --> 00:06:32,950
底部的十位评论者

93
00:06:32,950 --> 00:06:34,610
具有最低的比率
这说明什么呢?

94
00:06:34,610 --> 00:06:39,420
这说明这些评论者在其他方面放置了更大的权重

95
00:06:39,420 --> 00:06:41,110
而不是价值

96
00:06:41,110 --> 00:06:46,740
也就是说这些是关注其他维度
而对价值某种意义上不太关心的人

97
00:06:46,740 --> 00:06:51,450
至少跟前十组来比

98
00:06:52,470 --> 00:06:56,610
现在这些比率是通过
模型中的推断权重来计算的

99
00:06:57,820 --> 00:07:02,020
所以你可以看到为前十位评论者所青睐的酒店的平均价格

100
00:07:02,020 --> 00:07:07,360
看起来的确是比后十位评论者
喜欢的那些
要便宜许多

101
00:07:07,360 --> 00:07:14,720
这为我们验证推断权重
提供了一些间接的方法

102
00:07:14,720 --> 00:07:16,950
这说明权重不是随机的

103
00:07:16,950 --> 00:07:19,430
它们在这里是有意义的

104
00:07:19,430 --> 00:07:22,570
与之相比
这三个城市的平均价格

105
00:07:22,570 --> 00:07:26,940
你可以看到前十位这组的价格要低于平均值

106
00:07:26,940 --> 00:07:30,780
而下半区更为关注服务或是房间条件的人

107
00:07:30,780 --> 00:07:36,870
则倾向于价格高于平均水平的酒店

108
00:07:36,870 --> 00:07:40,590
通过这些结果
我们可以有一些很有趣的应用

109
00:07:40,590 --> 00:07:45,098
比如一个直接的应用
就是得到各方面的评分和总结

110
00:07:45,098 --> 00:07:48,920
因为通过分解
我们已经生成了

111
00:07:48,920 --> 00:07:49,970
各个方面的总结

112
00:07:49,970 --> 00:07:54,050
每个方面中的正面和负面的词句

113
00:07:54,050 --> 00:07:57,750
这比原有评论中只有总体评分和评论文本

114
00:07:57,750 --> 00:07:58,280
有更多的信息量

115
00:07:58,280 --> 00:08:01,940
这里是其他的一些结果

116
00:08:01,940 --> 00:08:06,990
是来自无评分的评论的方面

117
00:08:06,990 --> 00:08:08,810
这些都是MP3评论

118
00:08:08,810 --> 00:08:13,910
这些结果可以看出
模型可以展示一些有趣的方面

119
00:08:13,910 --> 00:08:18,320
比较了综合评分低
和那些综合评分高的评论

120
00:08:18,320 --> 00:08:21,550
它们关注不同的方面

121
00:08:22,590 --> 00:08:25,790
或者说它们在不同的方面评论更多

122
00:08:25,790 --> 00:08:29,796
这可以帮助我们来看
比如

123
00:08:29,796 --> 00:08:34,460
消费者对不同特性产品的接受程度

124
00:08:34,460 --> 00:08:39,980
比如一个人可能发现
人们倾向于

125
00:08:39,980 --> 00:08:45,550
青睐大屏手机
或是更轻的笔记本电脑等等

126
00:08:45,550 --> 00:08:49,960
这些知识对制造商

127
00:08:49,960 --> 00:08:56,150
设计下一代产品很有用

128
00:08:56,150 --> 00:09:01,020
这里有一些有趣的结果
是关于用户评分行为的分析

129
00:09:01,020 --> 00:09:04,650
你看到的是不同维度的平均权重

130
00:09:04,650 --> 00:09:09,470
针对不同群体的评论者

131
00:09:09,470 --> 00:09:16,950
左侧你可以看到喜欢昂贵酒店的评论者的权重

132
00:09:16,950 --> 00:09:21,000
他们给了昂贵的酒店5颗星

133
00:09:21,000 --> 00:09:24,810
你可以看到他们在
一些服务上的平均分更高

134
00:09:24,810 --> 00:09:29,520
这表明人们喜欢昂贵的酒店
可能是因为好的服务

135
00:09:29,520 --> 00:09:30,990
这并不令人惊讶

136
00:09:30,990 --> 00:09:33,620
这也是另一种
验证推断权重的方法

137
00:09:34,800 --> 00:09:40,330
如果你看右边
看5星这一列

138
00:09:40,330 --> 00:09:43,460
这里有一些评论者喜欢便宜的酒店

139
00:09:43,460 --> 00:09:45,770
他们给了便宜的酒店5星

140
00:09:45,770 --> 00:09:48,600
正如我们所料
他们更加看重价值

141
00:09:48,600 --> 00:09:51,110
这就是他们为什么喜欢便宜的酒店的原因

142
00:09:52,570 --> 00:09:56,770
但如果你看他们为什么
不喜欢昂贵的酒店或是便宜的酒店

143
00:09:56,770 --> 00:10:00,600
你会看到他们在房间清洁度上

144
00:10:00,600 --> 00:10:03,070
给予了更多的权重

145
00:10:04,210 --> 00:10:08,840
这说明利用这个模型
我们可以推断出

146
00:10:08,840 --> 00:10:13,900
一些难于获得的信息
即使你看过了全部的评论

147
00:10:13,900 --> 00:10:18,740
即使你看了全部的评论
你也很难推断出这些偏好

148
00:10:18,740 --> 00:10:20,890
或是侧重点

149
00:10:20,890 --> 00:10:24,450
所以这就是一个
文本挖掘算法超越人类的例子

150
00:10:24,450 --> 00:10:27,440
可以发现数据中有趣的模式

151
00:10:27,440 --> 00:10:29,900
这当然很有用

152
00:10:29,900 --> 00:10:32,340
你可以比较不同的酒店

153
00:10:32,340 --> 00:10:37,550
比较来自不同消费者群体的意见
在不同的地点

154
00:10:37,550 --> 00:10:39,430
当然模型是一般化的

155
00:10:39,430 --> 00:10:43,270
它可以用在任何综合评分的评论当中

156
00:10:43,270 --> 00:10:45,870
所以说这是个十分有用的技术

157
00:10:45,870 --> 00:10:47,970
可以支持许多的文本挖掘应用情境

158
00:10:50,250 --> 00:10:54,830
最后是应用这一模型的结果

159
00:10:54,830 --> 00:10:56,090
可以制作个性化的排名
或是内容的推荐

160
00:10:57,790 --> 00:11:02,270
因为我们推断出
评论者对于不同的维度给予权重

161
00:11:02,270 --> 00:11:06,240
我们可以让用户自己来说
哪些事情你比较关心

162
00:11:06,240 --> 00:11:09,550
比如说
我这里有一个查询说是
将90%的权重放到价值上

163
00:11:09,550 --> 00:11:12,930
10%放到其他因素上

164
00:11:12,930 --> 00:11:15,180
这就是说我不需要关心其他方面

165
00:11:15,180 --> 00:11:17,620
我只要找到一个便宜的酒店

166
00:11:17,620 --> 00:11:21,450
我的重点就是在价值这一维度

167
00:11:21,450 --> 00:11:26,310
我们对这个查询所能做的
就是我们可以利用

168
00:11:26,310 --> 00:11:31,000
我们认为具有类似偏好的评论者
来推荐一个酒店给你

169
00:11:31,000 --> 00:11:31,860
我们怎么知道呢？

170
00:11:31,860 --> 00:11:36,525
我们可以推断出这些评论者
在不同方面上的权重

171
00:11:36,525 --> 00:11:40,325
我们找到那些权重更为精确

172
00:11:40,325 --> 00:11:43,795
那些推断权重跟你的权重
更为相似的评论者

173
00:11:43,795 --> 00:11:46,885
然后利用这些评论者
来为你推荐酒店

174
00:11:46,885 --> 00:11:51,212
这就是我们说的个性化
或是针对查询的推荐

175
00:11:51,212 --> 00:11:56,030
现在顶部显示的是非个性化的推荐

176
00:11:56,030 --> 00:12:01,870
你可以看到靠前的结果
相比之后的总的来讲要更贵

177
00:12:01,870 --> 00:12:06,250
这是因为评论者在查询中更关心价值

178
00:12:06,250 --> 00:12:12,760
所以他们更倾向于选择价格低的酒店

179
00:12:12,760 --> 00:12:16,860
这是这个技术的另一个应用

180
00:12:18,280 --> 00:12:22,220
它表明进行文本挖掘
可以帮助我们更好地了解用户

181
00:12:22,220 --> 00:12:25,570
当我们更好地了解了用户
我们也能更好地解决他们的问题

182
00:12:25,570 --> 00:12:28,790
那么对我们的意见挖掘部分做一个总结

183
00:12:28,790 --> 00:12:31,650
这是一个很重要的话题
有许多应用

184
00:12:33,220 --> 00:12:37,780
文本情感分析可以

185
00:12:37,780 --> 00:12:39,280
仅通过分本分类进行实现

186
00:12:39,280 --> 00:12:41,430
但是标准的技术可能并不够

187
00:12:41,430 --> 00:12:44,020
我们需要丰富功能实现过程

188
00:12:45,020 --> 00:12:48,410
我们还需要考虑这些类别的顺序

189
00:12:48,410 --> 00:12:52,630
我们在一些问题中讲了有序回归

190
00:12:52,630 --> 00:12:55,580
我们还假设生成模型

191
00:12:55,580 --> 00:12:57,110
在挖掘潜在用户偏好上
是十分有效的

192
00:12:57,110 --> 00:13:02,120
尤其是挖掘潜在回归的生成模型

193
00:13:02,120 --> 00:13:05,560
我们嵌入了一些有趣的偏好信息

194
00:13:05,560 --> 00:13:09,660
然后将词的权重放到模型当中

195
00:13:09,660 --> 00:13:13,820
作为利用数据拟合模型过程中
我们能学习的最有用的信息

196
00:13:13,820 --> 00:13:16,960
现在大部分方法已经提出并评估过了

197
00:13:16,960 --> 00:13:21,910
针对产品的评论
这是因为在这种背景下

198
00:13:21,910 --> 00:13:23,790
意见的持有方和目标是清晰的

199
00:13:23,790 --> 00:13:26,220
并且它们易于分析

200
00:13:26,220 --> 00:13:29,710
当然这里有许多实际的应用

201
00:13:29,710 --> 00:13:35,800
但是对新闻和社交媒体的意见挖掘也很重要

202
00:13:35,800 --> 00:13:40,980
因为它比分析评论数据更困难
主要是因为

203
00:13:40,980 --> 00:13:45,220
意见的持有者和目标是隐晦的

204
00:13:45,220 --> 00:13:46,610
那么

205
00:13:46,610 --> 00:13:49,790
这就需要自然语言处理技术来发现它们

206
00:13:50,990 --> 00:13:53,390
这里是一些推荐阅读

207
00:13:53,390 --> 00:13:59,790
前两个是小书
提到这个话题的一些应用

208
00:13:59,790 --> 00:14:04,370
你能从中发现许多关于这个问题
或是问题变种的讨论

209
00:14:04,370 --> 00:14:07,050
以及提出来解决问题的技术

210
00:14:08,280 --> 00:14:12,430
之后两篇论文是关于生成模型

211
00:14:12,430 --> 00:14:14,330
在方面评分分析当中的应用

212
00:14:14,330 --> 00:14:18,456
第一篇是利用两阶段解决问题

213
00:14:18,456 --> 00:14:23,194
第二篇是一个统一模型
其中话题模型

214
00:14:23,194 --> 00:14:27,726
是通过回归模型包含在其中的
通过这个统一模型来解决问题

215
00:14:30,977 --> 00:14:40,977
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community