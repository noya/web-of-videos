1
00:00:00,025 --> 00:00:05,203
 这节课是关于

2
00:00:05,203 --> 00:00:11,060
基于文本分析预测

3
00:00:11,060 --> 00:00:15,850
在这个章节
我们来说说挖掘

4
00:00:15,850 --> 00:00:21,420
一种不同知识
正如所看到的这个流程图

5
00:00:21,420 --> 00:00:27,980
也就是说我们根据文本数据
来推断出一些

6
00:00:27,980 --> 00:00:33,830
有价值的信息但在现实世界中
可能没有直接与文本有直接关联

7
00:00:33,830 --> 00:00:36,660
或仅仅有很弱联系的文本数据

8
00:00:36,660 --> 00:00:39,810
因此这与文本分析或者

9
00:00:39,810 --> 00:00:44,680
与我们能直接
在文本中得到信息的话题挖掘有很大的不同

10
00:00:44,680 --> 00:00:48,830
这也与思想或者情感分析有所不同

11
00:00:48,830 --> 00:00:54,090
这仍需要将文本描述出来

12
00:00:54,090 --> 00:00:59,330
只是我们更关注于文本主题

13
00:00:59,330 --> 00:01:03,020
从中反映了我们对意见持有者的了解

14
00:01:05,000 --> 00:01:08,630
但这仅仅只提供有限的可预测的评论

15
00:01:10,320 --> 00:01:15,000
在这课时以及接下来的课程中
我们着重讨论

16
00:01:15,000 --> 00:01:20,830
如何在文本中推测出更多信息

17
00:01:20,830 --> 00:01:26,930
如何使其他类型数据文本与复杂模式相结合

18
00:01:28,360 --> 00:01:32,590
先认识预测的宏观图会有所帮助

19
00:01:32,590 --> 00:01:36,450
即数据挖掘
或者我称之为数据挖掘循环

20
00:01:36,450 --> 00:01:41,375
在这张图片现在可以看到
多个传感器

21
00:01:41,375 --> 00:01:43,067
包括人体传感器

22
00:01:43,067 --> 00:01:46,982
用数据的方式来描述真实的世界

23
00:01:46,982 --> 00:01:50,840
当然数据有非文本数据与文本数据

24
00:01:51,960 --> 00:01:56,010
我们的目标是能够推测出有价值的信息

25
00:01:56,010 --> 00:01:59,480
在现实世界里与我们息息相关的

26
00:01:59,480 --> 00:02:05,850
比如，一些房屋情况或者天气等等

27
00:02:05,850 --> 00:02:11,020
以及这些变量会是十分重要的
因为我们有可能依此采取行动

28
00:02:11,020 --> 00:02:14,870
或者想要依此做出决定

29
00:02:14,870 --> 00:02:18,070
因此，我们如何从
数据中获取潜在价值

30
00:02:18,070 --> 00:02:22,650
那么，我们首先要做
数据挖掘和数据分析

31
00:02:23,760 --> 00:02:28,540
因为，在一般情况下
我们需要对所有收集到的数据进行处理

32
00:02:30,190 --> 00:02:32,820
在所设定的预测问题中

33
00:02:32,820 --> 00:02:37,150
我们非常关注
文本与非文本联合挖掘

34
00:02:37,150 --> 00:02:39,730
再次需要将所有类型文本统一整合

35
00:02:41,830 --> 00:02:45,850
然后通过分析

36
00:02:45,850 --> 00:02:50,850
大致上会有多种具有价值的推断

37
00:02:50,850 --> 00:02:52,910
我们称其为特值

38
00:02:52,910 --> 00:02:56,490
而这些特值能够用于预测模型

39
00:02:56,490 --> 00:03:01,240
来推测任何有价值的变量

40
00:03:02,610 --> 00:03:06,850
因此这使我们能够改变世界

41
00:03:06,850 --> 00:03:12,490
以及一般这流程用于

42
00:03:12,490 --> 00:03:15,810
基于数据做出推测
包括数据测试

43
00:03:17,010 --> 00:03:20,290
因此，强调人们在

44
00:03:20,290 --> 00:03:23,080
这个流程中扮演着十分重要的角色

45
00:03:24,460 --> 00:03:27,760
特别是在文本数据中

46
00:03:27,760 --> 00:03:32,010
所以人们首先涉足
数据挖掘

47
00:03:32,010 --> 00:03:36,030
它能够控制这些特值的产生

48
00:03:36,030 --> 00:03:39,200
同时能够帮助我们
来理解文本数据

49
00:03:39,200 --> 00:03:43,350
因为我们所创造的数据
最终就是为人类所用

50
00:03:43,350 --> 00:03:46,890
人是最佳的数据消费者或诠释者

51
00:03:48,280 --> 00:03:52,750
但是，当然，当有许多的数据
需要借助机器的帮助

52
00:03:52,750 --> 00:03:54,490
这也是为什么我们需要数据挖掘

53
00:03:55,670 --> 00:04:00,900
有时候机器能够在许多数据中
看到一些模式而人不行

54
00:04:00,900 --> 00:04:03,570
但是总体上人扮演着重要的角色

55
00:04:03,570 --> 00:04:07,010
在分析特定数据或者应用程序

56
00:04:07,010 --> 00:04:11,000
接下来人们通常必须
进行预测与模型建立

57
00:04:11,000 --> 00:04:13,250
以及调试

58
00:04:13,250 --> 00:04:17,530
尤其是我们掌握了
关于许多领域问题的知识

59
00:04:17,530 --> 00:04:22,170
用于预测且能够建立预测模型

60
00:04:22,170 --> 00:04:28,020
然后接下来，当然，当我们
从变量中分析出有价值的数据

61
00:04:28,020 --> 00:04:32,670
那么接下来人们将会
采取行动去改变世界

62
00:04:32,670 --> 00:04:35,100
或者基于这些特值做决定

63
00:04:36,730 --> 00:04:41,320
最后有趣的是
人们也涉及

64
00:04:41,320 --> 00:04:42,720
传感器的控制

65
00:04:43,910 --> 00:04:48,450
同时这是我们能够
调节传感器去收集

66
00:04:48,450 --> 00:04:50,850
尽可能多的有用可推测数据

67
00:04:52,490 --> 00:04:54,610
因此这也是为什么我称它为数据挖掘循环

68
00:04:54,610 --> 00:04:58,750
因为我们调整传感器
使得传感器能够收集新的数据

69
00:04:58,750 --> 00:05:03,063
同时更多有效数据
因而我们能够获取更多可预测数据

70
00:05:03,063 --> 00:05:07,020
这些数据大体上能够帮助我们
提高预测的准确性

71
00:05:07,020 --> 00:05:08,120
在这个循环中

72
00:05:08,120 --> 00:05:12,780
人们能够识别哪些
附加数据需要收集

73
00:05:12,780 --> 00:05:14,030
而机器，当然

74
00:05:14,030 --> 00:05:19,040
帮助人们去区别哪些数据
在下一步中需要收集

75
00:05:19,040 --> 00:05:23,640
总的来说，我们需要收集那些
最有利于我们研究的数据

76
00:05:23,640 --> 00:05:28,080
这也是机器学习底下的一块区域称为主动学习

77
00:05:28,080 --> 00:05:29,650
如何处理数据

78
00:05:29,650 --> 00:05:31,110
如何区分数据

79
00:05:32,590 --> 00:05:36,460
区别出在机械学习进程中哪些是最有效数据

80
00:05:36,460 --> 00:05:37,470
如果你能够区别出来

81
00:05:38,650 --> 00:05:39,310
因此，总体上

82
00:05:39,310 --> 00:05:43,690
我们可以看出这个循环从
数据的收集到数据的分析

83
00:05:43,690 --> 00:05:46,160
或者数据挖掘到数据价值预测

84
00:05:46,160 --> 00:05:50,520
接着采取行动来改变世界
然后观察接下来会发生什么

85
00:05:50,520 --> 00:05:54,780
接着你可以决定下一步

86
00:05:54,780 --> 00:05:58,280
哪些数据将要通过调整传感器去收集

87
00:05:58,280 --> 00:06:02,630
或者反过来
你同样可以标记出

88
00:06:02,630 --> 00:06:06,160
哪些数据需要收集
能提高预测的准确性

89
00:06:06,160 --> 00:06:09,410
这张大图总体上

90
00:06:09,410 --> 00:06:14,660
反应了主要在大数据中的主要流程

91
00:06:16,130 --> 00:06:19,930
因此，牢记它会十分有用
当我们看

92
00:06:19,930 --> 00:06:20,690
一些数据挖掘技术的时候

93
00:06:22,000 --> 00:06:26,280
从数据挖掘来说
我们关注更多基于文本的预测

94
00:06:26,280 --> 00:06:29,710
当然，有时数据可以单独进行推断

95
00:06:29,710 --> 00:06:31,625
同时这是最有用的

96
00:06:31,625 --> 00:06:36,820
用于推断人们行为或者
人们喜好或者观点

97
00:06:36,820 --> 00:06:40,480
但是在一般的文本中我们
会把非文本类数据放在一起

98
00:06:40,480 --> 00:06:43,100
那有趣的问题是首先

99
00:06:43,100 --> 00:06:47,030
我们如何设计有效推断程序

100
00:06:47,030 --> 00:06:52,190
以及我们如何从文本当中创造出
有效的推断程序

101
00:06:53,730 --> 00:06:57,730
这个问题已经在之前的
课程中做出了解释

102
00:06:57,730 --> 00:07:03,390
当我们讨论到哪一类
特值可以为文本数据设定

103
00:07:03,390 --> 00:07:06,860
以及也同样阐述了在

104
00:07:06,860 --> 00:07:10,430
谈论到我们可以从其他文本中挖掘到的知识

105
00:07:10,430 --> 00:07:15,950
所以，举例说明，主题挖掘用于模式或者主题是十分有效的

106
00:07:15,950 --> 00:07:22,340
基于指标或者数据
能够被进一步应用于下一步的推断模型

107
00:07:22,340 --> 00:07:26,370
因此主题可以是文本中间形式

108
00:07:26,370 --> 00:07:29,990
使我们能够去
设计高级特征或推测值

109
00:07:29,990 --> 00:07:35,780
有效用于推测
其他有价值的信息

110
00:07:35,780 --> 00:07:40,340
这些可能由原始文本数据中产生
它提供了一个更好的

111
00:07:40,340 --> 00:07:45,470
解决问题的措施以及
并将其作为更有效的预测

112
00:07:46,650 --> 00:07:50,650
同样类似的分析会
产生这样的预测结果

113
00:07:50,650 --> 00:07:52,650
所以，其他数据挖掘或者

114
00:07:52,650 --> 00:07:56,300
文本分析算法可以
用于产生新预测值

115
00:07:58,470 --> 00:08:03,020
另一个问题是，我们如何结合
文本和非文本挖掘

116
00:08:03,020 --> 00:08:06,680
现在我们还没对这个问题做出解答

117
00:08:06,680 --> 00:08:07,560
所以在这节课

118
00:08:07,560 --> 00:08:11,020
以及接下来的课程中
我们将解答这个问题

119
00:08:11,020 --> 00:08:16,570
因为在这个问题里我们可以
得出更多数据或推测值

120
00:08:16,570 --> 00:08:21,580
同时复习这个世界上许多有趣的知识

121
00:08:21,580 --> 00:08:23,738
这个模式源于文本以及

122
00:08:23,738 --> 00:08:30,520
非文本数据本身
有时候可以已用于推测

123
00:08:30,520 --> 00:08:34,900
但是，当我们将其与
其他预测数据放在一起时

124
00:08:34,900 --> 00:08:37,820
源文本数据对提高预测准确十分有帮助

125
00:08:39,150 --> 00:08:42,870
基本上，你可以看到基于文本的预测实际上是统一

126
00:08:42,870 --> 00:08:47,790
的框架结构来结合许多文本挖掘以及分析技术

127
00:08:47,790 --> 00:08:54,080
包括主题挖掘以及文本挖掘技术或分段分析

128
00:08:55,530 --> 00:09:01,120
目标在于产生在现实世界中有价值的数据

129
00:09:01,120 --> 00:09:07,030
为了实现这一目的
我们可以做一些不同的推测

130
00:09:07,030 --> 00:09:08,200
而这些子任务

131
00:09:08,200 --> 00:09:14,060
因此，一个子任务可以挖掘文本数据的内容
类似于主题挖掘

132
00:09:14,060 --> 00:09:18,360
而其他则可以用于探寻
检查者所记忆的知识

133
00:09:18,360 --> 00:09:20,040
因此情感分析、建议

134
00:09:21,320 --> 00:09:26,110
两者都能帮助提供推测数据
用于预测的问题

135
00:09:27,830 --> 00:09:31,883
当然我们同样直接添加
非文本数据在推断模型中

136
00:09:31,883 --> 00:09:36,960
之后非文本数据同样帮助
提供文本分析的语境

137
00:09:36,960 --> 00:09:42,520
而进一步提高主题分析与建议分析

138
00:09:42,520 --> 00:09:48,040
而这样的改进往往带领更多
有效的推断来解决我们的问题

139
00:09:48,040 --> 00:09:53,210
它能够扩大议题意见的模式空间

140
00:09:53,210 --> 00:09:58,400
从文本中挖掘中
我们接下来会讨论这一点

141
00:09:58,400 --> 00:10:00,395
因此统一文本

142
00:10:00,395 --> 00:10:04,480
与非文本可以从两个不同方面去了解

143
00:10:05,900 --> 00:10:10,300
一方面，非文本数据帮助证明

144
00:10:11,680 --> 00:10:15,310
因为非文本数据提供语境

145
00:10:15,310 --> 00:10:19,910
为文本数据发掘提供途径
去用不同方式区别文本

146
00:10:19,910 --> 00:10:24,950
而这带来了许多不同方法
用于上下文类型文本分析

147
00:10:24,950 --> 00:10:29,730
这就是通过非文本数据定义
上下文文本挖掘

148
00:10:29,730 --> 00:10:34,840
这些是参考，在大量的工作中
在这里

149
00:10:34,840 --> 00:10:37,730
我着重标记其中一些
在下一个课时中

150
00:10:39,370 --> 00:10:42,207
现在，而另一个方面

151
00:10:42,207 --> 00:10:46,315
文本同时也可以帮助非文本数据发掘

152
00:10:46,315 --> 00:10:49,875
应为文本数据可以帮助解释

153
00:10:49,875 --> 00:10:52,635
从非文本数据中发现规律

154
00:10:52,635 --> 00:10:56,525
比如说我们在非文本数据中发现一些常见规律

155
00:10:56,525 --> 00:11:01,465
现在我们可以使用与实例相关联的文本数据

156
00:11:01,465 --> 00:11:06,015
在一些规律中产生同时文本数据相关联的情形

157
00:11:06,015 --> 00:11:09,200
而实例中规律并没有产生

158
00:11:09,200 --> 00:11:11,610
这为我们提供了两种不同文本数据

159
00:11:11,610 --> 00:11:13,700
然后，我们可以看出有什么区别

160
00:11:13,700 --> 00:11:18,180
而这种不同因为文本语境在文本数据中
是可解释的

161
00:11:18,180 --> 00:11:19,780
因为文本内容容易被理解

162
00:11:19,780 --> 00:11:23,460
而这不同点可能意味着

163
00:11:23,460 --> 00:11:26,610
从非文本数据中发现的规律的某些意义

164
00:11:26,610 --> 00:11:29,390
因此帮助解释这种规律

165
00:11:29,390 --> 00:11:31,890
而这种方法称为规律解释法

166
00:11:32,920 --> 00:11:37,160
你可以看到这里更详细的参考资料

167
00:11:38,400 --> 00:11:40,590
这些参考资料
之前已经提到过的

168
00:11:40,590 --> 00:11:43,630
第一条参考是关于规律解释

169
00:11:43,630 --> 00:11:49,140
第二条是Qiaozhu Mei对上下文文本挖掘论文

170
00:11:49,140 --> 00:11:53,880
其中包含了许多关于
上下文文本分析方法

171
00:11:56,271 --> 00:12:06,271
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community