这节课是关于 文本分类的评估 我们已经讨论过很多不同的文本分类方法 但你到底如何知道哪种方法更好 针对一个特定的应用 到底如何知道哪种解决问题的方法最好 为了了解这些 我们必须 知道如何评估分类结果 首先介绍一些常见的评估的观点 通常 对于这种例如分类的试验任务的评估 我们会使用1960年代建立好的方法 由信息检索研究人员建立的 称为Cranfield评估法 基本观点就是我们自己去创造检验校正 正如已知 每个文档都标注了分类 或者说 从搜索的角度讲 哪个查询 哪个文档应该 已被检索 这就叫Ground Truth 现在用这个ground truth检验校正 可以重复检测许多不同的系统 然后比较它们 还可以关闭系统中的一些元件试试看将会发生什么 基本上它提供了一种方法来操控实验进行比较 所以这种方法实际上已经被用在 所有的任务上 那些实证问题 在我们的例子里 将会比较系统分类 的结果 使用由人类创造的ground truth 同时将会比较系统决策 就是哪个文档应该属于哪个分类 作者设定了哪些分类给文档 我们还想量化这些决定的相似度 或者 等价地 衡量系统输出和 需要的理想输出之间的不同 显然地 最相似的是最好的结果 相似度可以用不用方式衡量 用不同的度量 有时候也需要从不同的角度来配对相似度 只是为了更好的从细节角度来理解结果 比如说 可能同样想知道哪个类别表现 更好 而且哪个类别更容易实现分类 通常说 不同的分类错误 对于特定的应用有不同的消耗 所以某些领域可能比其他领域更严重 理想是 想要给这些不同建模 但是如果你读过 很多关于分类的论文 会发现其实他们通常不这么做 他们会用一种简化的度量 因为 在比较方法时 是可以不去考虑消耗差异 并且当我们想知道这些方法的相对不同时也不用考虑 所以允许误差存在 只要不是因为 一个特定的方法 然后应该预期更高效的方法 来好好表现 即使这种度量并不完美 所以将要介绍的第一个度量
称为分类正确率 它是衡量正确决定率的基础 所以会看到这些分类用c1 到ck指代 
有n个文档 用d1到dN指代 对每一对分类 和文档
接下来可以观察一下 看看系统是否对这一配对说 行 基本上就是把这个分类归于该文档 或者系统回答 否 用Y或N指代行或不行
那就是系统的决定了 类似地 也可以观察到人类的决定
如果人类规定了 一个文档的分类 会用+标注 意味着是人规定的 假设这个归属是对的
如果不对就用- 可以看到各种N的组合 是和否 -和+ 一共有四种组合 其中两个是正确的 所以当我们用y(+)或者n(-) 接下来就会出现两种错误 所以分类精度的衡量就是简单的去数 有多少决策是正确的 然后用决策总数来正态化 你看 已知决策总数是n 乘以k 同事正确决策的数目就是两种 一个是y(+) 另一个是n(-) 把数好的放在一起 这是个非常方便的测量
会给出一个数字 来特征化一种方法的表现 越高越好 当然了 但是这个方法也有很多问题 第一个就是它平均地审视每个决策 但事实上 很多决策错误比其他的更严重 比如说 对某些文档来说
可能得到正确决策更重要 相较其他而言相较其他而言 再或者 对某些类别来说 得到正确决策更重要 比起其他 这就需要 这个结果的一些细节评估来理解 不同方法 以及理解这些方法的表现 从每个类别的细节 或者 每个文档的细节 一个例子清楚显示了
由不同的原因导致的决策错误 是由垃圾邮件过滤问题引起的 问题上 缺少一个合法的邮件结果
是一类错误 但是让垃圾邮件进入你的文件夹就是另一种错误了 显而易见 两类错误非常不同 因为不缺失一个合法邮件非常重要 收件箱偶尔有垃圾邮件还能接受 所以第一类错误 缺少合法邮件 
是代价很高的错误 非常严重 同时分类错误 分类校准并不会解决这个问题 还会引起测速数据组的不平衡的问题 想象一下测试数据组有倾向
大部分实例是类别1 有98%在类别1 只有2%在类别2 这种例子里我们可以设置一个非常简单的基准线 基准线运行良好 类似地把所有实例归入主要类别 在这个例子里将会达到98%准确率 这将会很实用 但现实中显然不会是一个好结果 所以一般来说 在使用分类校准作为一个测量 要确保分类是平衡的 我们还需要相等数量的实例 比如说 每一个类里少数的分类或起因会被 在评估分类精度时被过分解读 所以 为了解决这些问题
我们当然也想要去 用不同方法从其他角度来评估结果 如我讲过的
从多重角度来研究是有益的 比如说 我们可以从每个文档入手 从每个文档入手 所以问题就是 这个文档的精度到底有多高 现在在所有决策中的常见例子里 我们可以想一下4个 可能性的组合 取决于系统是否说yes 取决于人类是否说这是对的或不对的
或者说yes或no 所以这四个组合是首先出现的
当人类和系统都说yes时 这就是正数 当系统说yes 这是在确认是正的以后 所以当系统说 yes 它就是正的 但是当人类确认它确实是正确的 就变成了真实正数 当系统说yes但人类说no 那就是不对的 是假正 叫FP 当系统说no但是人类说yes 就成了假负 漏了一个任务 当系统和 人类同时说no 那么假设是真负也是对的 好啦
所以我们可以有一些测量来 更好地特征化表现
用这四个数字和 两个常见的测量 精确度与查全率 这些早已经被1960的信息检索研究员提出 用于评估搜索结果 但是现在已经变成了标准测量 用于所有地方 所以当系统说yes 我们可以提出
有多少是对的 比例是多少 这就叫正确率 是正数除以所以系统说yes的结果 所有的正 另一个测量叫查全率 它是用来测量是否所有的文档都有该有的分类 所以这个例子里 它是正数除以正数和假负的和 因此这就是所有的例子了 这些例子里人类声称这个文档应该有此分类 所以这代表了两种应有的分类 并且查全率也告诉了我们系统是否真的 划分了所有该文档应有的分类 这给予了我们该文档的一个细节展示 然后就可以以后把它们合并在一起了 如果有兴趣某些文档 它会告知你在处理那些文档时表现如何 这可能就比其他的看起来有意思多了 比如 它会允许更加细节地检验分析错误 可以根据特定特征来分离文档 然后看看错误 可能可以看到模式A用于这类文档 这种长长的 它不会和shock文档一样好 同时交给你一些关于输入方法的内部观点 类似的 我们来看看每个类别的评估 在本例中 将会看到某特定类别的决策到底有多好 上个例子中我们可以定义正确率和查全率 只不过简单的回答了问题 从一个不同的角度 所以当系统说行 有多少是正确的呢 意味着 看看这个类别
是不是所有的文档 带有这个类别的文档
确实涵盖在该类别里了 对吧 然后查全率 将会了解到
该类别确实已经被 指定到所有文档 有时候是很有用的
在正确率与查全率组合成一个度量时 常用f度量来表示 这只是正确率的一个近义词 正确率和查全率在这页中被定义 也被参数Beta操控 来指代正确率是否更重要
还是查全率更重要 当Beta=1 
成为F1 这个例子里 我们采用了相等的权重对待查全率和程序 F1常被用来测量分类 现在所有的例子都说明
当合并结果 总是会想要 用最好的方法合并它们
所以这里我不知道你是否想到 我们可以用四则运算来合并它们 还是能得到同样的范围值 不过显然不这么做是有原因的
F1更受欢迎也是有原因的 考虑不同之处实际上很有用 思考一下就会发现
确实有很多不同 以及很多并非所求的计算属性 基本上 只要思考就很明显 当系统同意分类与文档配对 然后试图计算正确率与查全率 看看将会发生什么 这种测量 四则运算平均值 将不会 和F1-1一样有道理 
[被用来替换正确率和查全率] 使两个值相等 这是个极端的例子
用0指代一个字母 1指代另一个 F1会很低
但平均值会合理地高 [背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community