1
00:00:00,025 --> 00:00:04,845
 这节课是关于

2
00:00:04,845 --> 00:00:12,188
文本分类的评估

3
00:00:12,188 --> 00:00:15,930
我们已经讨论过很多不同的文本分类方法

4
00:00:15,930 --> 00:00:17,900
但你到底如何知道哪种方法更好

5
00:00:19,080 --> 00:00:20,610
针对一个特定的应用

6
00:00:20,610 --> 00:00:25,880
到底如何知道哪种解决问题的方法最好

7
00:00:25,880 --> 00:00:27,670
为了了解这些 我们必须

8
00:00:29,270 --> 00:00:34,870
知道如何评估分类结果

9
00:00:34,870 --> 00:00:37,320
首先介绍一些常见的评估的观点

10
00:00:38,650 --> 00:00:44,530
通常 对于这种例如分类的试验任务的评估

11
00:00:44,530 --> 00:00:49,380
我们会使用1960年代建立好的方法

12
00:00:49,380 --> 00:00:51,620
由信息检索研究人员建立的

13
00:00:51,620 --> 00:00:53,380
称为Cranfield评估法

14
00:00:53,380 --> 00:00:58,100
基本观点就是我们自己去创造检验校正

15
00:00:59,880 --> 00:01:04,550
正如已知 每个文档都标注了分类

16
00:01:04,550 --> 00:01:08,680
或者说 从搜索的角度讲 哪个查询 哪个文档应该

17
00:01:08,680 --> 00:01:12,080
已被检索 这就叫Ground Truth

18
00:01:12,080 --> 00:01:14,740
现在用这个ground truth检验校正

19
00:01:14,740 --> 00:01:19,950
可以重复检测许多不同的系统

20
00:01:19,950 --> 00:01:21,900
然后比较它们

21
00:01:21,900 --> 00:01:26,290
还可以关闭系统中的一些元件试试看将会发生什么

22
00:01:26,290 --> 00:01:34,690
基本上它提供了一种方法来操控实验进行比较

23
00:01:36,570 --> 00:01:39,910
所以这种方法实际上已经被用在

24
00:01:39,910 --> 00:01:44,450
所有的任务上 那些实证问题

25
00:01:45,950 --> 00:01:50,810
在我们的例子里 将会比较系统分类

26
00:01:50,810 --> 00:01:55,530
的结果 使用由人类创造的ground truth 

27
00:01:56,730 --> 00:01:59,569
同时将会比较系统决策

28
00:02:00,820 --> 00:02:04,540
就是哪个文档应该属于哪个分类

29
00:02:06,120 --> 00:02:09,620
作者设定了哪些分类给文档

30
00:02:09,620 --> 00:02:14,930
我们还想量化这些决定的相似度 或者

31
00:02:14,930 --> 00:02:19,200
等价地 衡量系统输出和

32
00:02:19,200 --> 00:02:23,670
需要的理想输出之间的不同

33
00:02:25,020 --> 00:02:29,040
显然地 最相似的是最好的结果

34
00:02:30,100 --> 00:02:33,800
相似度可以用不用方式衡量

35
00:02:33,800 --> 00:02:35,760
用不同的度量

36
00:02:35,760 --> 00:02:40,870
有时候也需要从不同的角度来配对相似度

37
00:02:40,870 --> 00:02:44,660
只是为了更好的从细节角度来理解结果

38
00:02:44,660 --> 00:02:49,370
比如说 可能同样想知道哪个类别表现

39
00:02:49,370 --> 00:02:52,850
更好 而且哪个类别更容易实现分类

40
00:02:52,850 --> 00:02:58,890
通常说 不同的分类错误

41
00:02:58,890 --> 00:03:03,570
对于特定的应用有不同的消耗

42
00:03:03,570 --> 00:03:06,710
所以某些领域可能比其他领域更严重

43
00:03:06,710 --> 00:03:12,080
理想是 想要给这些不同建模 但是如果你读过

44
00:03:12,080 --> 00:03:16,200
很多关于分类的论文 会发现其实他们通常不这么做

45
00:03:16,200 --> 00:03:22,027
他们会用一种简化的度量 因为

46
00:03:22,027 --> 00:03:28,144
在比较方法时 是可以不去考虑消耗差异

47
00:03:28,144 --> 00:03:34,478
并且当我们想知道这些方法的相对不同时也不用考虑

48
00:03:34,478 --> 00:03:39,616
所以允许误差存在 只要不是因为

49
00:03:39,616 --> 00:03:44,677
一个特定的方法 然后应该预期更高效的方法

50
00:03:44,677 --> 00:03:50,410
来好好表现 即使这种度量并不完美

51
00:03:53,110 --> 00:03:56,620
所以将要介绍的第一个度量
称为分类正确率

52
00:03:56,620 --> 00:04:00,370
它是衡量正确决定率的基础

53
00:04:00,370 --> 00:04:04,990
所以会看到这些分类用c1

54
00:04:04,990 --> 00:04:10,620
到ck指代 
有n个文档 用d1到dN指代

55
00:04:10,620 --> 00:04:12,470
对每一对分类

56
00:04:12,470 --> 00:04:14,920
和文档
接下来可以观察一下

57
00:04:16,710 --> 00:04:21,060
看看系统是否对这一配对说 行

58
00:04:21,060 --> 00:04:23,660
基本上就是把这个分类归于该文档

59
00:04:23,660 --> 00:04:29,060
或者系统回答 否 用Y或N指代行或不行
那就是系统的决定了

60
00:04:29,060 --> 00:04:34,290
类似地 也可以观察到人类的决定
如果人类规定了

61
00:04:34,290 --> 00:04:37,810
一个文档的分类 会用+标注

62
00:04:37,810 --> 00:04:40,660
意味着是人规定的

63
00:04:40,660 --> 00:04:46,360
假设这个归属是对的
如果不对就用-

64
00:04:46,360 --> 00:04:53,708
可以看到各种N的组合 是和否 -和+

65
00:04:53,708 --> 00:04:56,178
一共有四种组合

66
00:04:56,178 --> 00:05:01,041
其中两个是正确的 所以当我们用y(+)或者n(-)

67
00:05:01,041 --> 00:05:04,570
接下来就会出现两种错误

68
00:05:04,570 --> 00:05:07,640
所以分类精度的衡量就是简单的去数

69
00:05:07,640 --> 00:05:10,310
有多少决策是正确的

70
00:05:10,310 --> 00:05:14,050
然后用决策总数来正态化

71
00:05:14,050 --> 00:05:19,180
你看 已知决策总数是n 乘以k

72
00:05:20,310 --> 00:05:25,090
同事正确决策的数目就是两种

73
00:05:25,090 --> 00:05:26,580
一个是y(+)

74
00:05:26,580 --> 00:05:28,300
另一个是n(-)

75
00:05:28,300 --> 00:05:30,720
把数好的放在一起

76
00:05:30,720 --> 00:05:34,800
这是个非常方便的测量
会给出一个数字

77
00:05:34,800 --> 00:05:38,140
来特征化一种方法的表现

78
00:05:38,140 --> 00:05:39,670
越高越好 当然了

79
00:05:41,190 --> 00:05:44,530
但是这个方法也有很多问题

80
00:05:44,530 --> 00:05:48,800
第一个就是它平均地审视每个决策

81
00:05:48,800 --> 00:05:53,310
但事实上 很多决策错误比其他的更严重

82
00:05:53,310 --> 00:05:56,900
比如说 对某些文档来说
可能得到正确决策更重要

83
00:05:56,900 --> 00:05:57,490
相较其他而言相较其他而言

84
00:05:58,950 --> 00:06:02,200
再或者 对某些类别来说 得到正确决策更重要

85
00:06:02,200 --> 00:06:05,080
比起其他 这就需要

86
00:06:05,080 --> 00:06:10,978
这个结果的一些细节评估来理解

87
00:06:12,410 --> 00:06:18,440
不同方法 以及理解这些方法的表现

88
00:06:18,440 --> 00:06:22,897
从每个类别的细节 或者

89
00:06:22,897 --> 00:06:26,248
每个文档的细节

90
00:06:26,248 --> 00:06:30,545
一个例子清楚显示了
由不同的原因导致的决策错误

91
00:06:30,545 --> 00:06:35,337
是由垃圾邮件过滤问题引起的

92
00:06:35,337 --> 00:06:35,980
问题上

93
00:06:36,980 --> 00:06:42,360
缺少一个合法的邮件结果
是一类错误

94
00:06:42,360 --> 00:06:47,050
但是让垃圾邮件进入你的文件夹就是另一种错误了

95
00:06:47,050 --> 00:06:50,500
显而易见 两类错误非常不同

96
00:06:50,500 --> 00:06:54,930
因为不缺失一个合法邮件非常重要

97
00:06:54,930 --> 00:06:59,930
收件箱偶尔有垃圾邮件还能接受

98
00:06:59,930 --> 00:07:05,960
所以第一类错误 缺少合法邮件 
是代价很高的错误

99
00:07:05,960 --> 00:07:08,670
非常严重

100
00:07:08,670 --> 00:07:13,240
同时分类错误 分类校准并不会解决这个问题

101
00:07:14,340 --> 00:07:16,950
还会引起测速数据组的不平衡的问题

102
00:07:16,950 --> 00:07:22,883
想象一下测试数据组有倾向
大部分实例是类别1

103
00:07:22,883 --> 00:07:25,950
有98%在类别1

104
00:07:25,950 --> 00:07:26,900
只有2%在类别2

105
00:07:26,900 --> 00:07:31,400
这种例子里我们可以设置一个非常简单的基准线

106
00:07:31,400 --> 00:07:32,520
基准线运行良好

107
00:07:32,520 --> 00:07:35,370
类似地把所有实例归入主要类别

108
00:07:36,510 --> 00:07:39,450
在这个例子里将会达到98%准确率

109
00:07:39,450 --> 00:07:43,760
这将会很实用

110
00:07:43,760 --> 00:07:45,580
但现实中显然不会是一个好结果

111
00:07:47,180 --> 00:07:51,550
所以一般来说 在使用分类校准作为一个测量

112
00:07:51,550 --> 00:07:53,980
要确保分类是平衡的

113
00:07:54,980 --> 00:07:57,340
我们还需要相等数量的实例

114
00:07:57,340 --> 00:08:02,860
比如说 每一个类里少数的分类或起因会被

115
00:08:02,860 --> 00:08:07,290
在评估分类精度时被过分解读

116
00:08:07,290 --> 00:08:11,595
所以 为了解决这些问题
我们当然也想要去

117
00:08:11,595 --> 00:08:14,550
用不同方法从其他角度来评估结果

118
00:08:14,550 --> 00:08:18,670
如我讲过的
从多重角度来研究是有益的

119
00:08:18,670 --> 00:08:22,310
比如说 我们可以从每个文档入手

120
00:08:22,310 --> 00:08:25,350
从每个文档入手

121
00:08:25,350 --> 00:08:28,689
所以问题就是 这个文档的精度到底有多高

122
00:08:29,900 --> 00:08:35,670
现在在所有决策中的常见例子里 我们可以想一下4个

123
00:08:35,670 --> 00:08:40,786
可能性的组合 取决于系统是否说yes

124
00:08:40,786 --> 00:08:46,650
取决于人类是否说这是对的或不对的
或者说yes或no

125
00:08:46,650 --> 00:08:53,660
所以这四个组合是首先出现的
当人类和系统都说yes时

126
00:08:53,660 --> 00:08:59,200
这就是正数 当系统说yes 这是在确认是正的以后

127
00:08:59,200 --> 00:09:02,210
所以当系统说 yes 它就是正的

128
00:09:02,210 --> 00:09:05,420
但是当人类确认它确实是正确的

129
00:09:05,420 --> 00:09:06,870
就变成了真实正数

130
00:09:07,920 --> 00:09:10,710
当系统说yes但人类说no

131
00:09:10,710 --> 00:09:13,950
那就是不对的 是假正 叫FP

132
00:09:15,010 --> 00:09:20,000
当系统说no但是人类说yes 就成了假负

133
00:09:20,000 --> 00:09:22,240
漏了一个任务

134
00:09:22,240 --> 00:09:23,740
当系统和

135
00:09:23,740 --> 00:09:28,890
人类同时说no 那么假设是真负也是对的

136
00:09:28,890 --> 00:09:33,800
好啦
所以我们可以有一些测量来

137
00:09:33,800 --> 00:09:38,160
更好地特征化表现
用这四个数字和

138
00:09:38,160 --> 00:09:40,610
两个常见的测量 精确度与查全率

139
00:09:40,610 --> 00:09:45,480
这些早已经被1960的信息检索研究员提出

140
00:09:45,480 --> 00:09:47,360
用于评估搜索结果

141
00:09:47,360 --> 00:09:51,080
但是现在已经变成了标准测量 用于所有地方

142
00:09:51,080 --> 00:09:55,980
所以当系统说yes 我们可以提出
有多少是对的

143
00:09:55,980 --> 00:10:00,390
比例是多少

144
00:10:00,390 --> 00:10:02,320
这就叫正确率

145
00:10:02,320 --> 00:10:06,560
是正数除以所以系统说yes的结果

146
00:10:06,560 --> 00:10:09,690
所有的正

147
00:10:09,690 --> 00:10:13,029
另一个测量叫查全率

148
00:10:14,200 --> 00:10:18,810
它是用来测量是否所有的文档都有该有的分类

149
00:10:18,810 --> 00:10:23,980
所以这个例子里 

150
00:10:23,980 --> 00:10:25,870
它是正数除以正数和假负的和

151
00:10:25,870 --> 00:10:28,430
因此这就是所有的例子了

152
00:10:28,430 --> 00:10:32,960
这些例子里人类声称这个文档应该有此分类

153
00:10:32,960 --> 00:10:37,180
所以这代表了两种应有的分类

154
00:10:37,180 --> 00:10:40,480
并且查全率也告诉了我们系统是否真的

155
00:10:40,480 --> 00:10:44,500
划分了所有该文档应有的分类

156
00:10:46,000 --> 00:10:49,300
这给予了我们该文档的一个细节展示

157
00:10:49,300 --> 00:10:50,790
然后就可以以后把它们合并在一起了

158
00:10:52,060 --> 00:10:53,980
如果有兴趣某些文档 

159
00:10:53,980 --> 00:10:59,750
它会告知你在处理那些文档时表现如何

160
00:10:59,750 --> 00:11:02,260
这可能就比其他的看起来有意思多了

161
00:11:02,260 --> 00:11:05,580
比如 它会允许更加细节地检验分析错误

162
00:11:05,580 --> 00:11:09,680
可以根据特定特征来分离文档

163
00:11:09,680 --> 00:11:10,700
然后看看错误

164
00:11:10,700 --> 00:11:14,370
可能可以看到模式A用于这类文档 这种长长的

165
00:11:14,370 --> 00:11:17,350
它不会和shock文档一样好

166
00:11:18,900 --> 00:11:22,760
同时交给你一些关于输入方法的内部观点

167
00:11:22,760 --> 00:11:25,830
类似的 我们来看看每个类别的评估

168
00:11:25,830 --> 00:11:26,760
在本例中

169
00:11:26,760 --> 00:11:30,690
将会看到某特定类别的决策到底有多好

170
00:11:30,690 --> 00:11:34,580
上个例子中我们可以定义正确率和查全率

171
00:11:34,580 --> 00:11:38,740
只不过简单的回答了问题 从一个不同的角度

172
00:11:39,820 --> 00:11:43,430
所以当系统说行 有多少是正确的呢

173
00:11:43,430 --> 00:11:48,580
意味着 看看这个类别
是不是所有的文档

174
00:11:48,580 --> 00:11:53,520
带有这个类别的文档
确实涵盖在该类别里了 对吧

175
00:11:53,520 --> 00:11:56,630
然后查全率 将会了解到
该类别确实已经被

176
00:11:56,630 --> 00:11:58,750
指定到所有文档

177
00:12:00,730 --> 00:12:04,990
有时候是很有用的
在正确率与查全率组合成一个度量时

178
00:12:04,990 --> 00:12:08,230
常用f度量来表示

179
00:12:08,230 --> 00:12:10,410
这只是正确率的一个近义词

180
00:12:10,410 --> 00:12:13,410
正确率和查全率在这页中被定义

181
00:12:13,410 --> 00:12:18,640
也被参数Beta操控

182
00:12:20,200 --> 00:12:23,680
来指代正确率是否更重要
还是查全率更重要

183
00:12:23,680 --> 00:12:28,260
当Beta=1 
成为F1

184
00:12:28,260 --> 00:12:33,120
这个例子里 我们采用了相等的权重对待查全率和程序

185
00:12:34,710 --> 00:12:38,890
F1常被用来测量分类

186
00:12:39,960 --> 00:12:44,520
现在所有的例子都说明
当合并结果 总是会想要

187
00:12:44,520 --> 00:12:48,160
用最好的方法合并它们
所以这里我不知道你是否想到

188
00:12:48,160 --> 00:12:52,810
我们可以用四则运算来合并它们

189
00:12:52,810 --> 00:12:56,520
还是能得到同样的范围值

190
00:12:56,520 --> 00:13:00,460
不过显然不这么做是有原因的
F1更受欢迎也是有原因的

191
00:13:00,460 --> 00:13:04,070
考虑不同之处实际上很有用

192
00:13:04,070 --> 00:13:08,610
思考一下就会发现
确实有很多不同

193
00:13:08,610 --> 00:13:13,480
以及很多并非所求的计算属性

194
00:13:13,480 --> 00:13:17,640
基本上 只要思考就很明显

195
00:13:17,640 --> 00:13:21,932
当系统同意分类与文档配对

196
00:13:21,932 --> 00:13:26,350
然后试图计算正确率与查全率

197
00:13:26,350 --> 00:13:27,400
看看将会发生什么

198
00:13:28,410 --> 00:13:32,956
这种测量

199
00:13:32,956 --> 00:13:37,776
四则运算平均值 将不会

200
00:13:37,776 --> 00:13:43,563
和F1-1一样有道理 
[被用来替换正确率和查全率]

201
00:13:43,563 --> 00:13:47,443
使两个值相等

202
00:13:47,443 --> 00:13:53,443
这是个极端的例子
用0指代一个字母 1指代另一个

203
00:13:53,443 --> 00:13:58,883
F1会很低
但平均值会合理地高

204
00:14:01,123 --> 00:14:11,123
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community