1
00:00:00,012 --> 00:00:07,163
这一讲

2
00:00:07,163 --> 00:00:09,920
是讲
情感分类

3
00:00:11,080 --> 00:00:12,150
如果我们假设

4
00:00:13,330 --> 00:00:17,840
意见表述中的大部分元素
都是已知的

5
00:00:17,840 --> 00:00:23,250
那么我们唯一的任务就只是情感分类
也就是这章的内容

6
00:00:23,250 --> 00:00:28,920
假设我们知道谁是意见的持有人
意见针对的目标是什么

7
00:00:28,920 --> 00:00:33,440
并且还知道意见的内容和背景
那么我们主要需要

8
00:00:33,440 --> 00:00:38,750
决定评论中的情感

9
00:00:38,750 --> 00:00:45,540
这就是一个仅用情感分类
来理解意见的例子

10
00:00:46,570 --> 00:00:51,470
情感分类
具体来讲可以表述如下:

11
00:00:51,470 --> 00:00:57,664
输入内容是带有意见的文本对象
输出则一般是一个情感的标签

12
00:00:57,664 --> 00:01:02,590
或者是情感的标记
这在设计上可以从两种方式实现

13
00:01:02,590 --> 00:01:07,000
一个是极性分析
我们可以将其中的情感分为正面、负面、

14
00:01:07,000 --> 00:01:07,500
或中性

15
00:01:08,990 --> 00:01:14,336
另外一种是情绪分析
这种方法可以超越

16
00:01:14,336 --> 00:01:20,550
描述过程中意见持有者的感觉的极性特征

17
00:01:21,610 --> 00:01:24,610
在极性分析的情形下
我们有时

18
00:01:24,610 --> 00:01:29,450
也使用数值形式的评分
就像你在网络评论中常见的那样

19
00:01:30,540 --> 00:01:37,510
比如说5可以表示最正面的情绪
1可以表示最负面的

20
00:01:37,510 --> 00:01:42,360
一般情况下
你就通过盘架式的种类来表征情感

21
00:01:43,710 --> 00:01:46,820
在情绪分析中
当然你也有不同的方式

22
00:01:46,820 --> 00:01:48,030
设计情感的分类

23
00:01:49,120 --> 00:01:52,620
六种最常见的类别
包括快乐、

24
00:01:52,620 --> 00:01:57,150
悲伤、害怕、生气、
惊喜和恶心

25
00:01:59,280 --> 00:02:04,066
就像你看到的这个任务本质上就是
一个分类的任务

26
00:02:04,066 --> 00:02:08,660
或者说是类别化的任务
像我们之前看到的就是一个文本分类的特例

27
00:02:08,660 --> 00:02:13,034
这也意味着任何文本分类
方法也可以用在情感

28
00:02:13,034 --> 00:02:14,120
分类背景

29
00:02:15,320 --> 00:02:18,970
当然如果你只是这样做
准确性未必好

30
00:02:18,970 --> 00:02:24,040
因为情感分类
需要在

31
00:02:24,040 --> 00:02:29,740
常规的文本分类
或者是简单的文本分类上做一些改进

32
00:02:29,740 --> 00:02:33,220
特别是
需要两种改进

33
00:02:33,220 --> 00:02:37,324
一种是使用更复杂的功能
更合适用于

34
00:02:37,324 --> 00:02:40,050
情感标记
我会在稍后讨论

35
00:02:41,420 --> 00:02:45,878
另一种是考虑
这些类别的次序

36
00:02:45,878 --> 00:02:51,677
特别是在极性分析中
顺序是一定存在的

37
00:02:51,677 --> 00:02:56,115
因此这些类别
并不是完全独立的

38
00:02:56,115 --> 00:03:00,840
次序是存在的
所以考虑这个次序是有帮助的

39
00:03:00,840 --> 00:03:03,720
比如我们可以利用顺序回归

40
00:03:03,720 --> 00:03:06,760
这些内容我们会在后面谈到

41
00:03:06,760 --> 00:03:11,080
现在我们先讲一些特征
这些特征

42
00:03:11,080 --> 00:03:14,048
在文本分类中十分有用
在文本挖掘之中一般也有用

43
00:03:14,048 --> 00:03:17,449
不过其中的一些在情感分析中也很需要

44
00:03:18,660 --> 00:03:23,480
那么我们从最简单的一个开始
字串

45
00:03:23,480 --> 00:03:26,490
可以将一系列字符作为一个单元

46
00:03:26,490 --> 00:03:32,210
他们可以有不同的n
就是不同的长度

47
00:03:32,210 --> 00:03:35,260
好的
这是一种常规

48
00:03:35,260 --> 00:03:38,680
而且非常稳健的方式来表述文本数据

49
00:03:38,680 --> 00:03:41,180
而且你可以在任何语言中运用这些
可以频繁使用

50
00:03:42,260 --> 00:03:46,430
这个方法在出现拼写或是识别错误的时候
也是稳健的是吧？

51
00:03:46,430 --> 00:03:50,680
那么如果你在拼一个单词的时候一个字符拼错了
这种方式

52
00:03:50,680 --> 00:03:55,620
仍然可以在文本中正确匹配这个词

53
00:03:55,620 --> 00:04:00,700
对单词的错误拼写
与正确拼写依然可以匹配

54
00:04:00,700 --> 00:04:04,670
是因为它们有相同的字串

55
00:04:04,670 --> 00:04:08,901
但是这种方式
使用的字符的判别能力没有词汇高

56
00:04:10,080 --> 00:04:14,030
那么我们可以使用词串
一串单词

57
00:04:14,030 --> 00:04:17,920
同样地我们可以用不同的长度

58
00:04:17,920 --> 00:04:23,331
一个单词构成的词串实际上
在不少文字处理任务中通常十分有效

59
00:04:23,331 --> 00:04:29,177
这主要是因为
词本身就是人类为交流设计的

60
00:04:29,177 --> 00:04:34,097
因此本身效果就很不错

61
00:04:34,097 --> 00:04:38,710
但是在情感分析之中这种方法并不好
或者说还不足够

62
00:04:38,710 --> 00:04:42,250
比如我们看到一个句子

63
00:04:42,250 --> 00:04:47,420
它可能不够好
或是没有别的好对吧?

64
00:04:47,420 --> 00:04:49,810
在这种情况下
如果你只用了good这个词

65
00:04:49,810 --> 00:04:54,240
对于not good判断出的也是正面情绪
所以说这个方法不够准确

66
00:04:54,240 --> 00:04:59,586
但是如果你使用两个词的词串
那么就会更加准确了

67
00:04:59,586 --> 00:05:03,930
所以长一点的词串区分度更好
因为长词串的表述更具体

68
00:05:03,930 --> 00:05:07,860
如果你用这个词串匹配
涵盖的信息更多

69
00:05:07,860 --> 00:05:11,250
表述更准确，
不太可能出现似是而非的情形

70
00:05:11,250 --> 00:05:16,770
但是这种方法可能会过度拟合
因为词串中的独特特征

71
00:05:16,770 --> 00:05:21,884
会被程序准确从训练集中准确提取

72
00:05:21,884 --> 00:05:26,284
然后利用这些特征
分出不同的类别

73
00:05:26,284 --> 00:05:30,970
显然这种分类方式也会利用这些特征
归类未来输入的内容

74
00:05:30,970 --> 00:05:34,850
然而判别使用的标准
却可能不会出现

75
00:05:34,850 --> 00:05:39,090
这就是过度拟合
是我们不想看到的

76
00:05:39,090 --> 00:05:43,990
我们也可以考虑词性标记
我们可以使用词性标记构建词串

77
00:05:43,990 --> 00:05:49,310
比如利用形容词名词组成一对

78
00:05:49,310 --> 00:05:55,040
我们可以用单词组成的词串
混合词性标记的词串

79
00:05:55,040 --> 00:05:59,790
比如单词great可以伴随着一个名词
这可以作为

80
00:05:59,790 --> 00:06:05,140
一个特征一个混合性的特征
用来进行情感分析

81
00:06:06,820 --> 00:06:09,960
接下来我们还可以利用词类

82
00:06:09,960 --> 00:06:15,420
这些类可以是来自造句法
比如词性标记或者是来自语义

83
00:06:15,420 --> 00:06:20,731
它们可能代表词库或本体中的概念
像WordNet

84
00:06:20,731 --> 00:06:25,360
或者它们可以是能够被识别的名字实体
比如人或是地点

85
00:06:25,360 --> 00:06:31,240
这些类别可以用来
作为额外特征扩充呈现

86
00:06:31,240 --> 00:06:35,884
我们也可以学习词集群
比如

87
00:06:35,884 --> 00:06:40,260
我们谈到挖掘过程中词汇的联系

88
00:06:40,260 --> 00:06:43,325
我们可以得到范式中相关的词或集群

89
00:06:43,325 --> 00:06:45,090
也可以是语法上相关的词或集群

90
00:06:45,090 --> 00:06:50,910
这些集群都可以成为特征
补充词基表述

91
00:06:50,910 --> 00:06:54,100
另外我们可以得到频繁出现的语法特征

92
00:06:54,100 --> 00:06:57,030
这可以是频繁出现的词集
这些词

93
00:06:57,030 --> 00:07:01,940
不一定会一同出现
或是接连出现

94
00:07:01,940 --> 00:07:04,410
但是我们可以得到位置上的信息

95
00:07:04,410 --> 00:07:09,340
哪些位置上这些单词更有可能接连出现

96
00:07:09,340 --> 00:07:13,500
显然这种模式能够提供更好的判别依据

97
00:07:14,695 --> 00:07:18,092
而且这种方式更好推广
因为相比一般的字串

98
00:07:18,092 --> 00:07:18,815
因为它们出现的更频繁

99
00:07:18,815 --> 00:07:22,337
所以你会期望
这些特征在测试数据中也会出现

100
00:07:22,337 --> 00:07:27,244
这个方法有不少优点
但是也可能出现

101
00:07:27,244 --> 00:07:31,000
输入过度的问题
尤其是在特征更为复杂的情况下

102
00:07:31,000 --> 00:07:37,500
这是一个一般性问题
同样的问题在分析树特征中也会出现

103
00:07:37,500 --> 00:07:42,610
当你使用分析树得到特征的时候
比如频繁出现的子树

104
00:07:42,610 --> 00:07:46,405
或是路径
或是那些有更强判别能力的特征

105
00:07:46,405 --> 00:07:51,160
但它们也更有可能导致过度拟合

106
00:07:51,160 --> 00:07:55,510
一般来讲
模式发现算法

107
00:07:55,510 --> 00:07:59,330
在特征构建上十分有用
因为它们允许在很大的

108
00:07:59,330 --> 00:08:04,350
特征空间中选取
比单词更为复杂也更为有用

109
00:08:04,350 --> 00:08:08,900
一般来讲
自然语言处理十分重要

110
00:08:08,900 --> 00:08:14,030
因为过程中能够提供更为复杂的特征
以及丰富文本表述

111
00:08:14,030 --> 00:08:14,760
举例来说，

112
00:08:14,760 --> 00:08:21,160
这是一个简单句
我在很久之前的另一节课中展示过

113
00:08:21,160 --> 00:08:26,570
从这些单词中
我们只能得到简单的词串

114
00:08:26,570 --> 00:08:29,210
表述或是字串

115
00:08:29,210 --> 00:08:32,230
但是使用自然语言处理
我们可以

116
00:08:32,230 --> 00:08:37,196
利用许多其他信息
比如词性标注、分析树或是

117
00:08:37,196 --> 00:08:40,340
实体
或是言语行为

118
00:08:40,340 --> 00:08:45,392
现在利用这些信息
我们可以生成

119
00:08:45,392 --> 00:08:50,361
许多其他的特征、更为复杂的特征
就像一个混合性的词串、

120
00:08:50,361 --> 00:08:54,130
词性标注或是分析树的一部分

121
00:08:55,870 --> 00:09:00,890
一般来说
特征设计会显著影响分类的精度

122
00:09:00,890 --> 00:09:05,780
在其他的机器学习应用中也十分重要

123
00:09:05,780 --> 00:09:10,750
我认为最有效的方式
是组合

124
00:09:10,750 --> 00:09:15,750
组合机器学习、误差分析
和领域知识

125
00:09:15,750 --> 00:09:18,160
首先你要
利用领域知识

126
00:09:18,160 --> 00:09:22,820
你对于问题的理解
设计种子的特征

127
00:09:22,820 --> 00:09:27,920
然后你可以定义一个基本的特征空间
涵盖许多

128
00:09:27,920 --> 00:09:32,110
机器学习中可能的特征
计算机能够利用这些特征选择

129
00:09:32,110 --> 00:09:35,410
最有效的特征
或是构建新的特征

130
00:09:35,410 --> 00:09:37,570
这就是特征学习

131
00:09:37,570 --> 00:09:43,630
这些特征可以利用误差分析进一步分析

132
00:09:43,630 --> 00:09:46,386
如果你观察
分类中的误差

133
00:09:46,386 --> 00:09:50,488
可以进一步了解哪些特征
可以修正这些误差

134
00:09:50,488 --> 00:09:54,460
或者哪些特征引起了过度拟合
导致了这些误差

135
00:09:54,460 --> 00:09:58,177
这就进入了
特征检验过程

136
00:09:58,177 --> 00:10:01,823
调整特征集
不断重复这个过程

137
00:10:01,823 --> 00:10:05,140
我们可能要考虑
使用一个新的特征空间

138
00:10:07,520 --> 00:10:11,260
按之前所说
自然语言处理丰富了文本识别

139
00:10:11,260 --> 00:10:14,150
因为它改善了特征空间

140
00:10:14,150 --> 00:10:19,165
扩充了特征空间
还能提供

141
00:10:19,165 --> 00:10:23,514
更多更多的特征
应用于其他任务之中

142
00:10:23,514 --> 00:10:28,871
但是要注意
使用过多的类别特征

143
00:10:28,871 --> 00:10:33,464
会导致过度拟合
要不然

144
00:10:33,464 --> 00:10:38,401
只能在训练中小心一些
不要出现外溢

145
00:10:38,401 --> 00:10:41,375
所以在特征设计中的主要挑战

146
00:10:41,375 --> 00:10:46,534
共同的挑战就是权衡

147
00:10:46,534 --> 00:10:51,616
完备性与特异性
这个权衡过程十分困难

148
00:10:51,616 --> 00:10:56,485
完备性指我们需要
挑选合适的特征

149
00:10:56,485 --> 00:10:59,449
覆盖大量文本内容

150
00:10:59,449 --> 00:11:04,263
从这点上说
你需要这些特征频繁出现

151
00:11:04,263 --> 00:11:08,086
而特异性要求特征
的判别能力够强

152
00:11:08,086 --> 00:11:13,090
所以不常出现的特征
往往会有更强的判别能力

153
00:11:13,090 --> 00:11:17,652
所以就有了这样一个权衡

154
00:11:17,652 --> 00:11:22,360
用来在频繁和不频繁的特征之中进行挑选

155
00:11:22,360 --> 00:11:22,896
这就是特征
设计的独特之处

156
00:11:22,896 --> 00:11:27,693
也是机器学习中最重要
的内容

157
00:11:27,693 --> 00:11:32,076
尤其是在我们这里
对于文本分类来说或是

158
00:11:32,076 --> 00:11:35,723
具体来讲
对于情感分类来说

159
00:11:35,723 --> 00:11:45,723
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community