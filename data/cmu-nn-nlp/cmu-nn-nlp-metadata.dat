CMU-Neural-Nets-for-NLP-2017-(1):-Class-Introduction-&-Why-Neural-Nets?	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(1)---Class-Introduction-&-Why-Neural-Nets-Sss2EA4hhBQ.en.vtt	https://www.youtube.com/watch?v=Sss2EA4hhBQ	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Introduction to Neural Networks Example Tasks and Their Difficulties What Neural Nets can Do To Hel
CMU-Neural-Nets-for-NLP-2017-(10):-Structured-Prediction	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(10)---Structured-Prediction-e5sPNlgbZAE.en.vtt	https://www.youtube.com/watch?v=e5sPNlgbZAE	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Teacher Forcing and Exposure Bias Local vs. Global, Label Bias The Structured Perceptron Structu
CMU-Neural-Nets-for-NLP-2017-(11):-Structured-Prediction-w/-Local-Dependence	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(11)---Structured-Prediction-w_-Local-Dependence-p8K35mE66Ic.en.vtt	https://www.youtube.com/watch?v=p8K35mE66Ic	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Xuezhe Ma) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Why Local Independence Assumptions? Conditional Random Fields Considering Reward in TrainingSorry, t
CMU-Neural-Nets-for-NLP-2017-(12):-Transition-based-Dependency-Parsing	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(12)---Transition-based-Dependency-Parsing-7rp2c7JVymE.en.vtt	https://www.youtube.com/watch?v=7rp2c7JVymE	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: What is Transition-based Parsing? Shift-reduce Parsing w/ Feed-forward Nets Stack LSTM A Simple 
CMU-Neural-Nets-for-NLP-2017-(13):-Parsing-With-Dynamic-Programs	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(13)---Parsing-With-Dynamic-Programs-gRtEW6Q5XJE.en.vtt	https://www.youtube.com/watch?v=gRtEW6Q5XJE	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: What is Graph-based Parsing? Minimum Spanning Tree Parsing Structured Training and Other Improveme
CMU-Neural-Nets-for-NLP-2017-(14):-Neural-Semantic-Parsing	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(14)---Neural-Semantic-Parsing-7gS8pwRwHMc.en.vtt	https://www.youtube.com/watch?v=7gS8pwRwHMc	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: What is Graph-based Parsing? Minimum Spanning Tree Parsing Structured Training and Other Improveme
CMU-Neural-Nets-for-NLP-2017-(15):-Latent-Variable-Models	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(15)---Latent-Variable-Models-QKr8Ar86xSQ.en.vtt	https://www.youtube.com/watch?v=QKr8Ar86xSQ	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Generative vs. Discriminative, Deterministic vs. Random Variables Variational Autoencoders Handlin
CMU-Neural-Nets-for-NLP-2017-(16):-Reinforcement-Learning	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(16)---Reinforcement-Learning-F1hZfoh-wX4.en.vtt	https://www.youtube.com/watch?v=F1hZfoh-wX4	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: What is Reinforcement Learning? Policy Gradient and REINFORCE Stabilizing Reinforcement Learning
CMU-Neural-Nets-for-NLP-2017-(17):-Adversarial-Learning	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(17)---Adversarial-Learning-twjlGZzUM68.en.vtt	https://www.youtube.com/watch?v=twjlGZzUM68	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: (Generative) Adversarial Networks Where to use the Adversary?: Features vs. Outputs GANs on Discre
CMU-Neural-Nets-for-NLP-2017-(18):-Unsupervised-Learning-of-Structure	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(18)---Unsupervised-Learning-of-Structure-EKvkrv4K0qo.en.vtt	https://www.youtube.com/watch?v=EKvkrv4K0qo	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Learning Features vs. Learning Structure Unsupervised Learning Methods Design Decisions for Unsupe
CMU-Neural-Nets-for-NLP-2017-(19):-Document-Level-Models	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(19)---Document-Level-Models-cWDt6GTOpLE.en.vtt	https://www.youtube.com/watch?v=cWDt6GTOpLE	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Zhengzhong Liu) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Models of Coreference Discourse Parsing Document Level PredictionSlides: http://phontron.com/cl
CMU-Neural-Nets-for-NLP-2017-(2):-A-Simple-(?)-Exercise:-Predicting-the-Next-Word-in-a-Sentence	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(2)---A-Simple-()-Exercise---Predicting-the-Next-Word-in-a-Sentence-tNC9tpGqQb0.en.vtt	https://www.youtube.com/watch?v=tNC9tpGqQb0	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Describing a word by the company that it keeps Counting and predicting Skip-grams and CBOW Evalua
CMU-Neural-Nets-for-NLP-2017-(20):-Models-of-Dialog	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(20)---Models-of-Dialog-P58GOj91nnA.en.vtt	https://www.youtube.com/watch?v=P58GOj91nnA	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Chat-based Dialog Task-based DialogSlides: http://phontron.com/class/nn4nlp2017/assets/slides/nn4n
CMU-Neural-Nets-for-NLP-2017-(21):-Learning-From/For-Knowledge-Bases	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(21)---Learning-From_For-Knowledge-Bases-yq5YuZ_QCxU.en.vtt	https://www.youtube.com/watch?v=yq5YuZ_QCxU	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Relation Extraction w/ Neural Nets Learning Embeddings from Knowledge BasesSlides: http://phontron
CMU-Neural-Nets-for-NLP-2017-(22):-Machine-Reading-w/-Neural-Nets	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(22)---Machine-Reading-w_-Neural-Nets-rOiXjukeHSw.en.vtt	https://www.youtube.com/watch?v=rOiXjukeHSw	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Machine Reading Attention-based Machine Reading Models Multi-hop Reasoning ModelsSlides: http://
CMU-Neural-Nets-for-NLP-2017-(23):-Debugging-Neural-Nets-for-NLP	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(23)---Debugging-Neural-Nets-for-NLP-oMB24_ao05A.en.vtt	https://www.youtube.com/watch?v=oMB24_ao05A	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Diagnosing your Problem Debugging Training Time Problems Debugging Decoding Time Problems Combat
CMU-Neural-Nets-for-NLP-2017-(24):-Advanced-Search-Algorithms	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(24)---Advanced-Search-Algorithms-4AQbrT-GD2k.en.vtt	https://www.youtube.com/watch?v=4AQbrT-GD2k	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Daniel Clothiaux) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Beam Search A-type SearchSlides: http://phontron.com/class/nn4nlp2017/assets/slides/nn4nlp-24-
CMU-Neural-Nets-for-NLP-2017-(25):-Multilingual-and-Multitask-Learning	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(25)---Multilingual-and-Multitask-Learning-XnwB6jlHeR0.en.vtt	https://www.youtube.com/watch?v=XnwB6jlHeR0	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Multitask Learning Domain Adaptation Multilingual LearningSlides: http://phontron.com/class/nn4n
CMU-Neural-Nets-for-NLP-2017-(3):-Models-of-Words	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(3)---Models-of-Words-xCAtxcc0KIE.en.vtt	https://www.youtube.com/watch?v=xCAtxcc0KIE	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Describing a word by the company that it keeps Counting and predicting Skip-grams and CBOW Evalua
CMU-Neural-Nets-for-NLP-2017-(4):-Why-is-word2vec-so-fast?-Efficiency-Tricks.	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(4)---Why-is-word2vec-so-fast-Efficiency-Tricks.-9ERZsx__rBM.en.vtt	https://www.youtube.com/watch?v=9ERZsx__rBM	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Taylor Berg-Kirkpatrick) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Softmax Approximations: Negative Sampling, Hierarchical Softmax Parallel Training Tips fo
CMU-Neural-Nets-for-NLP-2017-(5):-Convolutional-Networks-for-Text	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(5)---Convolutional-Networks-for-Text-vnzKAhs7nds.en.vtt	https://www.youtube.com/watch?v=vnzKAhs7nds	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Bag of Words, Bag of n-grams, and Convolution Applications of Convolution: Context Windows and Sente
CMU-Neural-Nets-for-NLP-2017-(6):-Recurrent-Neural-Networks	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(6)---Recurrent-Neural-Networks-TVp_75uJkPw.en.vtt	https://www.youtube.com/watch?v=TVp_75uJkPw	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Recurrent Networks Vanishing Gradient and LSTMs Strengths and Weaknesses of Recurrence in Sentence
CMU-Neural-Nets-for-NLP-2017-(7):-Using/Evaluating-Sentence-Representations	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(7)---Using_Evaluating-Sentence-Representations-7j20MC6J_QU.en.vtt	https://www.youtube.com/watch?v=7j20MC6J_QU	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Sentence Similarity Textual Entailment Paraphrase Identification RetrievalSlides: http://phont
CMU-Neural-Nets-for-NLP-2017-(8):-Conditioned-Generation	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(8)---Conditioned-Generation-6DSg-AA-Ur0.en.vtt	https://www.youtube.com/watch?v=6DSg-AA-Ur0	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Encoder-Decoder Models Conditional Generation and Search Ensembling Evaluation Types of Data t
CMU-Neural-Nets-for-NLP-2017-(9):-Attention	cmu-nn-nlp\CMU-Neural-Nets-for-NLP-2017-(9)---Attention-MhTMgFvoaD8.en.vtt	https://www.youtube.com/watch?v=MhTMgFvoaD8	PL8PYTP1V4I8ABXzdqtOpB_eqBlVAz_xPT	This lecture (by Graham Neubig) for CMU CS 11-747, Neural Networks for NLP (Fall 2017) covers: Attention What do We Attend To? Improvements to Attention Specialized Attention Varieties A Ca
