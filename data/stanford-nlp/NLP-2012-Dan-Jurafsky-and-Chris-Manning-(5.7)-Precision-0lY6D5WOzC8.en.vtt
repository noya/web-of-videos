WEBVTT
Kind: captions
Language: en

00:00:00.928 --> 00:00:05.158
Okay, let me now talk about how
we evaluate text categorization.

00:00:05.158 --> 00:00:08.863
And in doing this, I'm going to come
back to the concepts of precision and

00:00:08.863 --> 00:00:11.360
recall that we introduced
informally before.

00:00:11.360 --> 00:00:13.030
But define them formally, and

00:00:13.030 --> 00:00:15.570
show how they get put together
into combined measure.

00:00:15.570 --> 00:00:19.360
The F measure,
that gets applied to Text Classification.

00:00:19.360 --> 00:00:22.280
But it isn't only applied
to Text Classification.

00:00:22.280 --> 00:00:24.907
You'll see these concepts
coming back again and

00:00:24.907 --> 00:00:29.730
again as ways of evaluation of the tasks
in natural language processing.

00:00:29.730 --> 00:00:32.460
The starting point from
understanding these measures

00:00:32.460 --> 00:00:35.770
is the following 2-by-2 contingency table.

00:00:35.770 --> 00:00:40.020
And so, for any particular piece
of data that we're evaluating,

00:00:40.020 --> 00:00:42.820
there are essentially four states.

00:00:42.820 --> 00:00:47.060
On one axis we're choosing whether

00:00:47.060 --> 00:00:51.409
this piece of data correctly
belongs to a class.

00:00:52.610 --> 00:00:56.870
Or whether it doesn't
correctly belong to a class.

00:00:56.870 --> 00:01:03.385
So for example, if we're wanting to
decide whether a piece of email is spam,

00:01:03.385 --> 00:01:09.050
where it either is spam
which is the correct class,

00:01:09.050 --> 00:01:12.370
or it's not which is
the not correct class.

00:01:12.370 --> 00:01:19.120
And so,
on this axis we're describing the truth.

00:01:19.120 --> 00:01:25.330
Now, what we've done is built a system
that tries to detect the truth,

00:01:25.330 --> 00:01:29.685
and so secondly, we're going to
look at the status of our system.

00:01:29.685 --> 00:01:35.275
So our system could be saying
that this piece of data is spam,

00:01:35.275 --> 00:01:38.215
or it could be saying that it's not spam.

00:01:40.585 --> 00:01:44.571
And so, we're then going to
take these four things and

00:01:44.571 --> 00:01:47.788
look at the four possibilities that occur.

00:01:47.788 --> 00:01:48.730
And here they are.

00:01:48.730 --> 00:01:53.210
So, if we're looking for
spam, one possibility

00:01:53.210 --> 00:01:58.128
is the truth that it is spam and
that we said it was spam.

00:01:58.128 --> 00:02:01.320
And so, that's then referred
to as a true positive.

00:02:03.950 --> 00:02:09.170
Another possibility is that our system

00:02:09.170 --> 00:02:14.055
thought it wasn't spam even though,
actually, it was.

00:02:14.055 --> 00:02:17.075
And so, that's then a false negative.

00:02:17.075 --> 00:02:19.605
It was treated as negative falsely.

00:02:20.975 --> 00:02:22.755
On the other side of the dial,

00:02:22.755 --> 00:02:27.835
it's possible that the piece
of email actually wasn't spam.

00:02:27.835 --> 00:02:31.375
In that case, there are,
again, two possibilities.

00:02:31.375 --> 00:02:36.341
Our system mistakenly thought it was spam,
so that's then a false positive,

00:02:36.341 --> 00:02:39.814
where classifying something positively,
wrongly.

00:02:39.814 --> 00:02:44.775
But the other possibility is it wasn't
a piece of spam, and our system said

00:02:44.775 --> 00:02:49.688
it wasn't a piece of spam, and
then we're dealing with a true negative.

00:02:49.688 --> 00:02:55.440
Okay, so if we're doing this kind of
classification with two classes that

00:02:55.440 --> 00:03:00.870
are perhaps about equally common
in your email, spam and non-spam.

00:03:00.870 --> 00:03:04.850
It seems the reasonable thing to
do is just to look at accuracy.

00:03:06.970 --> 00:03:08.061
So for accuracy,

00:03:08.061 --> 00:03:12.298
the ones that count as you getting
the answer correct are these ones.

00:03:12.298 --> 00:03:17.434
So, if you want to work out the accuracy,
the accuracy equals

00:03:17.434 --> 00:03:23.075
the true positives plus the true
negatives over all four classes,

00:03:23.075 --> 00:03:30.550
the true positives + the false positives +
the false negatives + the true negatives.

00:03:33.040 --> 00:03:37.680
In many applications accuracy
is a useful measure for systems.

00:03:37.680 --> 00:03:42.080
But there is a particular scenario
in which it's not a useful measure.

00:03:42.080 --> 00:03:46.768
And that scenario is when you are dealing
with things that are uncommon.

00:03:46.768 --> 00:03:51.408
So for example, suppose that we're wanting

00:03:51.408 --> 00:03:56.460
to detect mentions of
shoe brands in web pages.

00:03:56.460 --> 00:04:01.879
So, the correct class is that
something is a shoe brand.

00:04:03.720 --> 00:04:09.278
And the not class is anything else.

00:04:13.978 --> 00:04:18.618
Well, If you're just looking through
random webpages, or Tweets, or

00:04:18.618 --> 00:04:21.905
something, looking for
mentions of shoe brands.

00:04:21.905 --> 00:04:27.461
Probably, I don't know,
99.99% of the words

00:04:27.461 --> 00:04:33.310
you encounter are not going to
be the name shoe brands.

00:04:33.310 --> 00:04:35.130
And so, what does that mean?

00:04:35.130 --> 00:04:41.255
What that is likely to mean is, that
perhaps in total, let's say, there are,

00:04:45.875 --> 00:04:52.781
10 mentions of a shoe brand
in a 100,000 word sample,

00:04:52.781 --> 00:04:58.850
and 99,990 words that are not shoe brands.

00:04:58.850 --> 00:05:03.750
Well, if we build a classifier,
presumably, even if it's a mediocre

00:05:03.750 --> 00:05:08.840
classifier, we're going to say
most words are not a shoe brand.

00:05:08.840 --> 00:05:12.510
And if we go straight to the limit case,

00:05:12.510 --> 00:05:17.890
one possibility of our classifier is it
could say that no word is a shoe brand.

00:05:17.890 --> 00:05:21.230
So, it doesn't select any
words as shoe brands.

00:05:21.230 --> 00:05:26.450
And it says that all 100,000
words are not shoe brands.

00:05:26.450 --> 00:05:32.336
And so that means,
the number of true negatives are 99,990,

00:05:32.336 --> 00:05:35.537
but there are a few false negatives,

00:05:35.537 --> 00:05:40.610
words that were shoe brands,
but the number them is 10.

00:05:40.610 --> 00:05:45.170
So, if we then actually work out
the accuracy of this system,

00:05:45.170 --> 00:05:48.518
you'll see that
the accuracy of the system,

00:05:53.518 --> 00:05:58.558
Is 99.99%.

00:05:58.558 --> 00:06:03.317
So, we have a 99.99% accurate system,

00:06:03.317 --> 00:06:07.838
but the system has done precisely nothing.

00:06:07.838 --> 00:06:13.548
This is very easy system to write,
you just write one line of code that says,

00:06:13.548 --> 00:06:20.090
return false for any token, and you're
done, and yet its accuracy is amazing.

00:06:20.090 --> 00:06:23.810
So, what's clearly missing here
is that we're just not dealing

00:06:23.810 --> 00:06:25.680
with what we wanted to do.

00:06:25.680 --> 00:06:29.790
So, what we wanted to do
was detect shoe brands.

00:06:29.790 --> 00:06:36.250
So what's all-important to us is the 10
tokens which are instances of shoe brands.

00:06:36.250 --> 00:06:40.825
And so, what we want to do is
come up with an evaluation

00:06:40.825 --> 00:06:43.977
metric that is much more focused on,

00:06:43.977 --> 00:06:50.098
are we detecting these very few words
that are the names of shoe brands?

00:06:50.098 --> 00:06:54.030
And so, that's what the measures
of precision and recall do.

00:06:54.030 --> 00:06:56.910
So, precision tells you,

00:06:56.910 --> 00:07:01.290
of the things that you're selecting,
are they the correct things?

00:07:01.290 --> 00:07:06.420
So, precision is saying,
of the things that you are selecting,

00:07:06.420 --> 00:07:12.340
which is that row, what percentage of
them are correct things, this column?

00:07:12.340 --> 00:07:17.815
So, precision is the number of true
positives out of all the things that

00:07:17.815 --> 00:07:23.820
you selected,
the true positives + the false positives.

00:07:23.820 --> 00:07:26.900
And then recall is the opposite measure.

00:07:26.900 --> 00:07:32.880
So, for recall you're saying,

00:07:32.880 --> 00:07:37.880
of the things that are correct,

00:07:37.880 --> 00:07:40.640
what percentage of them did you find?

00:07:41.640 --> 00:07:46.890
So for recall, the numerator is,
again, the true positives,

00:07:46.890 --> 00:07:52.005
but this time,
the denominator is the true positives

00:07:52.005 --> 00:07:56.050
+ the not selected, false negatives.

00:07:59.090 --> 00:08:02.210
And so, note how looking at these measures

00:08:02.210 --> 00:08:07.210
solves the problem that we had
last time with the shoe brands.

00:08:07.210 --> 00:08:12.322
Because, the fact that
there is 99,990 tokens

00:08:12.322 --> 00:08:20.220
that are true negatives is now having
no effect on these measures at all.

00:08:20.220 --> 00:08:24.022
And so,
what will happen in our previous case,

00:08:24.022 --> 00:08:28.206
where they're 10 tokens here and
0 tokens here,

00:08:28.206 --> 00:08:32.962
since our classifier said every
word wasn't a shoe brand,

00:08:32.962 --> 00:08:38.885
that what we'd find is that we'd say
that the recall of that system is 0.

00:08:38.885 --> 00:08:43.338
It's finding none of what we
wanted to find, and, basically,

00:08:43.338 --> 00:08:47.135
we can say a system with 0
recall isn't interesting.

00:08:49.505 --> 00:08:57.418
And so, this suggests we'd actually want
to do better by returning some stuff.

00:08:57.418 --> 00:09:02.560
So, what we'd like to do is label
some things as shoe brands.

00:09:02.560 --> 00:09:04.120
So we could revise the system.

00:09:04.120 --> 00:09:09.190
And when we revise the system,
maybe what we'll do is

00:09:09.190 --> 00:09:13.690
we'll have it return 40
things as the name of shoes.

00:09:13.690 --> 00:09:18.390
And so, it'll perhaps find
eight of the shoe brands, but

00:09:18.390 --> 00:09:22.270
it'll make some mistakes and claim some
things as shoe brands that aren't.

00:09:22.270 --> 00:09:27.560
So there will be 32 tokens over here and
then there'll be 2 tokens down here.

00:09:27.560 --> 00:09:34.610
And then, the remainder of the tokens,
960, will be down here.

00:09:34.610 --> 00:09:40.780
So then, at that point we can say, well,
the recall of our system is pretty good.

00:09:40.780 --> 00:09:46.610
So it's now finding 8 out of
the 10 instances of shoe brands.

00:09:46.610 --> 00:09:49.097
So its recall is 80%.

00:09:49.097 --> 00:09:53.080
But the problem is that,
that recall came at a cost,

00:09:53.080 --> 00:09:57.960
because it's now also claiming lots of
other things as shoe brands that aren't.

00:09:57.960 --> 00:10:03.153
So, the precision of the system is now

00:10:03.153 --> 00:10:09.981
8 over 8 + 32 = 8 out of 40 which = 20%.

00:10:09.981 --> 00:10:13.440
1 in 5 things it returns as correct.

00:10:13.440 --> 00:10:13.970
And so, for

00:10:13.970 --> 00:10:19.140
a lot of practical applications, this
kind of precision is going to be too low.

00:10:19.140 --> 00:10:22.816
It depends whether you're really
interested in finding references

00:10:22.816 --> 00:10:23.980
to shoe brands.

00:10:23.980 --> 00:10:28.110
And have prepared to have a human being go
through and check them all individually.

00:10:28.110 --> 00:10:34.260
But if you want to do something more
automatic, 20% is too low of a precision.

00:10:34.260 --> 00:10:35.290
But in this,

00:10:35.290 --> 00:10:41.365
we see the secret of the trade-off that
balances between recall and precision.

00:10:41.365 --> 00:10:45.570
because, almost inevitably, if you
are going to increase your recall and

00:10:45.570 --> 00:10:49.535
find instances of something,
you are going to make some mistakes.

00:10:49.535 --> 00:10:52.400
And so,
your precision is going to go down.

00:10:52.400 --> 00:10:53.520
And the more you try and

00:10:53.520 --> 00:10:58.240
boost recall, the more your precision
is going to be starting to drop.

00:10:58.240 --> 00:11:01.680
And so, people are trading
off precision and recall.

00:11:01.680 --> 00:11:05.397
So that's a good thing about
having these two measures,

00:11:05.397 --> 00:11:08.571
because you can discuss the trade-off and
say,

00:11:08.571 --> 00:11:13.063
how important to someone is
the precision of what's returned versus

00:11:13.063 --> 00:11:17.344
how important is it to find all of
the stuff, to have high recall?

00:11:17.344 --> 00:11:22.018
And that's a trade-off that is played out
differently in different applications.

00:11:22.018 --> 00:11:27.153
So, in various applications such as for
things like legal applications where

00:11:27.153 --> 00:11:32.703
you want to find all of the appropriate
evidence, such as in discovery procedures.

00:11:32.703 --> 00:11:36.995
But what you really, really want to
be doing is having a system that is

00:11:36.995 --> 00:11:41.790
high recall, that finds as much of
the relevant stuff as possible.

00:11:41.790 --> 00:11:43.670
Where, in other contexts,

00:11:43.670 --> 00:11:49.540
where what you're going to do is just
show a sampling of stuff to the user,

00:11:49.540 --> 00:11:54.800
you might be more interested in
the stuff that's shown to the user,

00:11:54.800 --> 00:11:59.190
being stuff that is correct that looks
good, that your precision is high.

00:11:59.190 --> 00:12:03.523
And it doesn't really matter that you're
only showing to the user one-tenth or

00:12:03.523 --> 00:12:07.210
one-twentieth of the things
that do satisfy their query.

00:12:08.820 --> 00:12:12.423
So sometimes that explicit
trade-off is really useful, and

00:12:12.423 --> 00:12:16.868
it's a really good concept to remember
when you're building NLP systems.

00:12:16.868 --> 00:12:20.402
because in practice, whenever you're
building one of these systems,

00:12:20.402 --> 00:12:24.990
you're choosing some trade-off point as to
how much you're emphasizing precisional

00:12:24.990 --> 00:12:30.140
recall, and different trade-off points
are appropriate in different applications.

00:12:30.140 --> 00:12:33.678
But sometimes that's a slightly annoying
thing, having these these two measures.

00:12:33.678 --> 00:12:38.190
Because when people are wanting to compare
systems and say which one is better,

00:12:38.190 --> 00:12:41.390
then you need some way to
combine these measures.

00:12:41.390 --> 00:12:43.210
And so, that's been thought about as well.

00:12:45.970 --> 00:12:50.190
And so, the standard way that's been
proposed to combine these measures

00:12:50.190 --> 00:12:55.060
is something that's called the F
measure in disciplines like

00:12:55.060 --> 00:12:58.500
information retrieval and
named entity recognition.

00:12:58.500 --> 00:13:00.330
So, what is the F measure?

00:13:00.330 --> 00:13:03.550
What the F measure is,
is it's neither more nor

00:13:03.550 --> 00:13:05.930
less than a weighted harmonic mean.

00:13:06.930 --> 00:13:11.490
So at this point, we have to kind of
revise a little bit of math on means.

00:13:11.490 --> 00:13:14.655
So, you doubtless remember
the arithmetic mean,

00:13:14.655 --> 00:13:17.163
which is just the average of two things.

00:13:17.163 --> 00:13:20.935
And you, perhaps,
also remember a geometric mean.

00:13:20.935 --> 00:13:24.775
But in addition to both of those,
there's the harmonic mean.

00:13:24.775 --> 00:13:30.059
And in the harmonic mean,
what you do is you take the reciprocal

00:13:30.059 --> 00:13:36.160
of two quantities and then add them and
then take the reciprocal of that.

00:13:36.160 --> 00:13:40.018
And if you work through in
more detail what that does,

00:13:40.018 --> 00:13:44.239
the harmonic mean ends up as
a very conservative average.

00:13:44.239 --> 00:13:47.311
So, if you put in two
numbers into a harmonic mean,

00:13:47.311 --> 00:13:50.531
it's fairly close to
the minimum of the two numbers.

00:13:50.531 --> 00:13:52.591
Not completely at the minimum, but

00:13:52.591 --> 00:13:57.301
it's nearer to the minimum than either
the arithmetic or geometric means.

00:13:58.691 --> 00:14:00.950
Then in particular, for

00:14:00.950 --> 00:14:05.810
this F measure, we're allowed to
put weights on these two terms.

00:14:05.810 --> 00:14:07.800
And so, this is this alpha factor.

00:14:07.800 --> 00:14:13.830
So, the weighting is how much to pay
more attention to the precision or

00:14:13.830 --> 00:14:16.740
how much to pay more
attention to the recall.

00:14:16.740 --> 00:14:21.220
So, if you are in an application and
you know that precision is much more

00:14:21.220 --> 00:14:26.060
important to you, you can actually
express that utility trade-off

00:14:26.060 --> 00:14:30.779
by putting a particular value
of alpha in that expresses it.

00:14:33.620 --> 00:14:35.195
So this formulation here,

00:14:35.195 --> 00:14:39.370
very clearly shows that the F measure
is the weighted harmonic mean, but

00:14:39.370 --> 00:14:43.418
actually that's not the formulation
that you normally see in books.

00:14:43.418 --> 00:14:47.492
The formulation that you normally
see in books is actually this one,

00:14:47.492 --> 00:14:50.383
which is I guess,
just a little tidier to write.

00:14:50.383 --> 00:14:52.603
And these two formulations are related,
and

00:14:52.603 --> 00:14:55.356
maybe we'll work through that
in one of the exercises.

00:14:55.356 --> 00:14:59.176
You can work out the relationship
between alpha and beta.

00:14:59.176 --> 00:15:04.897
But effectively, this formula also
expresses a weighted harmonic mean,

00:15:04.897 --> 00:15:08.073
and it also has a control perimeter beta,

00:15:08.073 --> 00:15:12.998
as to how much emphasis is being
put on precision versus recall.

00:15:14.658 --> 00:15:20.919
So while the control parameter is useful,
in the absence of other evidence,

00:15:20.919 --> 00:15:25.280
the most commonly used thing
is a balanced F measure.

00:15:25.280 --> 00:15:29.690
And so, the balanced F measure gets
referred to as the F1 measure.

00:15:29.690 --> 00:15:34.372
And what that’s meaning is,
that your setting beta=1.

00:15:34.372 --> 00:15:37.978
That then, gives you equal balance
between precision and recall,

00:15:37.978 --> 00:15:40.585
which corresponds in turn
to alpha being a half.

00:15:40.585 --> 00:15:43.719
And if you do the balanced F measure,

00:15:43.719 --> 00:15:48.630
this formula here simplifies
to just this formula.

00:15:48.630 --> 00:15:51.118
And so, this is really the thing
that you'll see most common.

00:15:51.118 --> 00:15:56.525
So, if you don't remember any
of the rest of this stuff,

00:15:56.525 --> 00:16:01.596
what you should do is remember
this little formula for

00:16:01.596 --> 00:16:05.664
the F measure, 2PR divided by (P+R).

00:16:05.664 --> 00:16:09.857
So, that should give you a good sense of
what these measures of precision recall

00:16:09.857 --> 00:16:13.551
are, how they are combined into
the F measure, why they're useful,

00:16:13.551 --> 00:16:16.390
and how we use them to
evaluate text classification.

