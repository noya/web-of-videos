WEBVTT
Kind: captions
Language: en

00:00:00.470 --> 00:00:05.370
Okay, let me tell you a little bit
more about how tf-idf scores and

00:00:05.370 --> 00:00:10.788
the cosine similarity measure get used
together in a ranked IR retrieval system.

00:00:10.788 --> 00:00:15.010
I'm not going to get a lot into the
details of making these systems practical

00:00:15.010 --> 00:00:17.939
and efficient, at least give you
a little bit more of a sense.

00:00:19.360 --> 00:00:23.946
So the first thing that you might have
already started to notice is that tf-idf

00:00:23.946 --> 00:00:26.550
weighting isn't really one thing.

00:00:26.550 --> 00:00:28.310
It's really a family of measures.

00:00:28.310 --> 00:00:31.740
Let's just look at that in
a little bit more detail.

00:00:31.740 --> 00:00:35.760
So first of all you have
the term frequency, and

00:00:35.760 --> 00:00:38.000
what you do with the term frequency.

00:00:38.000 --> 00:00:41.310
And you could just have
the natural term frequency, but

00:00:41.310 --> 00:00:45.660
we suggested that that is usually
muted by something like log weighting.

00:00:45.660 --> 00:00:47.670
And that's indeed the most
common thing to do,

00:00:47.670 --> 00:00:50.330
but it's not the only
method that's been used.

00:00:50.330 --> 00:00:53.390
There have been a bunch of other
methods that have been suggested for

00:00:53.390 --> 00:00:55.640
normalizing term frequency.

00:00:55.640 --> 00:00:58.170
Then if we move on to
the document frequency,

00:00:58.170 --> 00:01:01.900
we cannot use document
frequency weighting at all.

00:01:01.900 --> 00:01:05.270
We can use this kind of log inverse
document frequency weighting,

00:01:05.270 --> 00:01:07.120
which is again extremely common.

00:01:07.120 --> 00:01:10.850
But again there are other things
that people have tried out doing.

00:01:10.850 --> 00:01:15.440
So if we put these two things together we
have tf-idf weighting giving us a vector.

00:01:15.440 --> 00:01:20.500
But what we may want to normalize
those vectors in some way to have,

00:01:20.500 --> 00:01:22.890
and have better similarity computations.

00:01:22.890 --> 00:01:29.120
And so, we discussed using
the cosine length normalization,

00:01:29.120 --> 00:01:32.810
and it turns out that it has some
advantages and some disadvantages.

00:01:32.810 --> 00:01:37.480
So again there are other things people
have tried including both of these and

00:01:37.480 --> 00:01:40.800
other ones that have come up more
recently sort of things like pivoted

00:01:40.800 --> 00:01:42.020
length normalization.

00:01:43.460 --> 00:01:48.620
So in general we have kind
of a broad menu of choices.

00:01:48.620 --> 00:01:52.120
And so
at the beginning here of each column

00:01:52.120 --> 00:01:56.560
I've given some letter
names to these choices.

00:01:56.560 --> 00:01:59.830
These were choices that were
developed in the context

00:01:59.830 --> 00:02:04.420
of the SMART Information Retrieval System,
which is a very famous pioneering

00:02:04.420 --> 00:02:09.160
information retrieval system that was
developed at Cornell by Jerry Sultan,

00:02:09.160 --> 00:02:13.300
who was really the father of a lot
of modern information retrieval.

00:02:13.300 --> 00:02:18.160
So these choices could be given
names by giving letters from these.

00:02:18.160 --> 00:02:22.950
So if you were using the system that we've
mainly been talking about That will be

00:02:22.950 --> 00:02:30.680
coming out as ltc, for logarithm,
logarithmic idf, and cosine waiting.

00:02:30.680 --> 00:02:36.840
And so this kind of waiting it then
turns out can be used both for

00:02:36.840 --> 00:02:39.230
queries and documents differently.

00:02:39.230 --> 00:02:42.720
And so let's go through a little
bit How that all comes out,

00:02:42.720 --> 00:02:48.000
so we can have different weightings for
queries vs documents.

00:02:48.000 --> 00:02:52.940
And if we follow this smart notation,
the standard way that they represented

00:02:52.940 --> 00:02:56.070
things is these six letters
with a dot in the middle.

00:02:56.070 --> 00:02:58.800
Where there's the document
weighting scheme,

00:02:58.800 --> 00:03:01.270
followed by the query weighting scheme.

00:03:01.270 --> 00:03:03.170
There are various variants, but

00:03:03.170 --> 00:03:09.050
one that was quite standard coming out of
the SMART work in the 1990s was this one.

00:03:09.050 --> 00:03:12.710
We will just mention this one
in a little bit more detail.

00:03:12.710 --> 00:03:19.220
If we do the query part of it first
what we find out is that there is log

00:03:19.220 --> 00:03:24.350
query normalisation,
now this is actually only makes

00:03:24.350 --> 00:03:29.240
a difference if you have long queries,
it might mention words multiple times.

00:03:29.240 --> 00:03:33.320
If really you have short queries and
no word is mentioned more than once.

00:03:33.320 --> 00:03:37.260
That you're just going to be getting
a weight of 1 for words that appear and

00:03:37.260 --> 00:03:39.860
0 for words that don't appear.

00:03:39.860 --> 00:03:45.500
There's then idf weighting of the query
terms and cosign normalization.

00:03:45.500 --> 00:03:48.850
The treatment for
the documents is the same,

00:03:48.850 --> 00:03:52.750
except there's actually no idf
normalization of the documents.

00:03:52.750 --> 00:03:56.080
And that's something that you might
want to think about for a moment.

00:03:56.080 --> 00:03:58.710
Is that a bad idea?

00:03:58.710 --> 00:04:02.420
There is some reasons to want to do that.

00:04:02.420 --> 00:04:07.640
One of them is, well you have
already put in an idf vector for

00:04:07.640 --> 00:04:10.370
the same words in the query.

00:04:10.370 --> 00:04:13.950
Because remember that you are only
going to get non zero scores for

00:04:13.950 --> 00:04:17.610
words that occur in both the query and
the document.

00:04:17.610 --> 00:04:21.520
And that there are some advantages
in terms of efficiency of

00:04:21.520 --> 00:04:24.700
compressing indices if you
are not putting idf in there.

00:04:26.390 --> 00:04:31.430
Let's take this waiting scheme and
again go through a concrete example,

00:04:31.430 --> 00:04:36.300
so we're just going to be
working out the score for

00:04:36.300 --> 00:04:40.895
precisely one document against It's
one query using this waiting scheme.

00:04:40.895 --> 00:04:44.245
But we'll do it in great depth.

00:04:44.245 --> 00:04:47.855
Okay, so our document is car
insurance auto insurance.

00:04:47.855 --> 00:04:51.335
That's a bit of a fake document but
we wanted something short.

00:04:51.335 --> 00:04:54.845
And then the query is best car insurance.

00:04:54.845 --> 00:05:02.065
So if we go to the query first, best car
insurance, these are its raw weights.

00:05:04.370 --> 00:05:08.540
And so then, we're going to scale
those with logarithmic scaling, but

00:05:08.540 --> 00:05:10.990
since each word only occurred once,
it stays one.

00:05:10.990 --> 00:05:15.008
We then get the document
frequency of each of those words,

00:05:15.008 --> 00:05:18.788
which we map onto an inverse
document frequency, so.

00:05:21.923 --> 00:05:26.477
The rarer words like insurance
are getting the highest

00:05:26.477 --> 00:05:31.427
waiting there we then multiply
this column by this column,

00:05:31.427 --> 00:05:37.367
which ends up looking just like
the document frequency score except for

00:05:37.367 --> 00:05:39.860
the word that didn't occur.

00:05:39.860 --> 00:05:44.720
And then we turn that into a unit
vector with cosine normalization.

00:05:44.720 --> 00:05:49.850
And so this is our final
representation of the query vector.

00:05:49.850 --> 00:05:53.940
We then move to the document.

00:05:54.970 --> 00:06:01.210
So the document has some term
frequencies that aren't just zero one,

00:06:01.210 --> 00:06:06.050
so we reduce those with term frequency
ratings that look like that.

00:06:06.050 --> 00:06:12.040
In this case there is no idf
component on the document,

00:06:12.040 --> 00:06:17.340
so the weights go to being exactly
the same just coming from tome frequency.

00:06:17.340 --> 00:06:20.840
And then we can do co-sign normalization

00:06:20.840 --> 00:06:23.475
which gives this as our
final document vector.

00:06:23.475 --> 00:06:27.280
Okay, then to work out the score for

00:06:27.280 --> 00:06:31.840
this document for this query then
working out the co-sign similarity.

00:06:31.840 --> 00:06:38.520
It's just simply the dot product of these
two length normalized vectors, and so

00:06:38.520 --> 00:06:44.980
that's then this vector here where only
the bottom two components are non zero.

00:06:44.980 --> 00:06:50.174
So we add those up and
the overall score is 0.8.

00:06:52.460 --> 00:06:55.720
So the document is a good match for
the query.

00:06:55.720 --> 00:06:59.550
Though I mean do remember when you
look at co-signs similarities.

00:06:59.550 --> 00:07:04.620
Because of the fact that the co-sign
kind of is sort of flat at the top here

00:07:05.790 --> 00:07:09.750
flat for
sending it means that you tend to get for

00:07:09.750 --> 00:07:15.400
fairly similar documents the cosine
scores are sort of biased fairly high.

00:07:15.400 --> 00:07:19.350
So it's more important to remember
the ordering than the precise values.

00:07:19.350 --> 00:07:24.530
Okay, but that shows you how

00:07:24.530 --> 00:07:28.910
we evaluated that document and then we'd
evaluate a bunch of other documents, and

00:07:28.910 --> 00:07:32.450
then we'd want to rank according
to their cosine similarity scores.

00:07:35.320 --> 00:07:41.020
A little exercise that you might like
to do based on this example is well,

00:07:41.020 --> 00:07:46.600
if you know what the IDF scores
are here and the document frequencies.

00:07:46.600 --> 00:07:51.950
You should actually be able to not work
out what is the number of documents

00:07:51.950 --> 00:07:56.780
as being used as the basis
of this example.

00:07:56.780 --> 00:08:00.270
Okay now, let's go through how we
can work out cosine scores and

00:08:00.270 --> 00:08:04.200
a vector space retrieval system for
a document collection.

00:08:04.200 --> 00:08:07.400
This is the rough kind of algorithm
that we're going to want to use.

00:08:07.400 --> 00:08:12.610
So what we're going to assume
here Is that the query is

00:08:12.610 --> 00:08:15.160
a typical short web-like query.

00:08:15.160 --> 00:08:19.490
So, we're only going to be thinking
of the words as either occurring or

00:08:19.490 --> 00:08:22.260
not occurring in the query.

00:08:22.260 --> 00:08:24.820
And, also,
we're going to skip one other step, then.

00:08:24.820 --> 00:08:28.900
We're not actually going to do any
length normalization of the query.

00:08:28.900 --> 00:08:30.390
And part of the reason for

00:08:30.390 --> 00:08:35.300
that is when you have a situation
like this late normalization of

00:08:35.300 --> 00:08:40.450
the query is actually unnecessary because
the query vector has some length.

00:08:40.450 --> 00:08:45.035
And for whatever it is, the effective
length normalization would just be

00:08:45.035 --> 00:08:49.435
a rescaling that applies to all
query document calculations and

00:08:49.435 --> 00:08:50.945
wouldn't change the final result.

00:08:52.225 --> 00:08:54.405
Okay, so
given that background what do we do?

00:08:54.405 --> 00:09:01.250
So we start off by having the scores array
for all documents which we st to zero.

00:09:01.250 --> 00:09:05.660
And so, we're going to accumulate
in here the score of a document for

00:09:05.660 --> 00:09:08.010
different query terms.

00:09:08.010 --> 00:09:11.420
And so, these scores are often
referred to as accumulators.

00:09:14.390 --> 00:09:17.840
Okay, and then we're also going
to have another array for

00:09:17.840 --> 00:09:20.280
the length of the different documents.

00:09:20.280 --> 00:09:26.650
Ans so then what we do is go through
each term in the query and we say.

00:09:26.650 --> 00:09:31.410
Well, the query term is
actually just going to be one,

00:09:32.670 --> 00:09:36.360
and then we fetch the postings list for
that query.

00:09:36.360 --> 00:09:40.750
So then, for
each document in the postings list.

00:09:42.000 --> 00:09:45.690
The term has a frequency in that document.

00:09:45.690 --> 00:09:50.770
And, we may then want to scale that,
by doing something like log weighting or

00:09:50.770 --> 00:09:52.090
something like that.

00:09:52.090 --> 00:09:54.860
But, and to give us our
document weight for the term.

00:09:54.860 --> 00:09:58.520
And then we're doing the components for
the dot product here, and

00:09:58.520 --> 00:10:01.000
summing them into the Scores array.

00:10:01.000 --> 00:10:05.810
So in essence, where kind of
the outer iteration here is for

00:10:05.810 --> 00:10:11.310
each query term, and we're working out
the components of the cosine score.

00:10:11.310 --> 00:10:15.800
For each query term and
accumulating it in this scores array.

00:10:17.680 --> 00:10:21.440
We haven't actually done any length
normalization of the documents either yet,

00:10:21.440 --> 00:10:28.095
so then the next step is to work
out the length of each document.

00:10:28.095 --> 00:10:32.285
And then divide these scores
by the length of the document.

00:10:32.285 --> 00:10:36.685
So this then does the length normalization
for different document sizes.

00:10:36.685 --> 00:10:39.715
So given the assumptions I
mentioned at the beginning,

00:10:39.715 --> 00:10:44.185
that the query vector is 1 / 0 and
we don't need to length normalize it.

00:10:44.185 --> 00:10:48.190
We have something that
is now ordered the same.

00:10:48.190 --> 00:10:52.280
As a length, and [INAUDIBLE] cosine
similarity score for the documents.

00:10:52.280 --> 00:10:57.180
And so then for our ranking,
what we just want to return is

00:10:57.180 --> 00:11:02.025
the sum number K, of documents, their ids.

00:11:02.025 --> 00:11:05.975
These are the representation of them
that has the highest value for scores.

00:11:05.975 --> 00:11:12.715
Now, if you think about the little this
isn't quite yet a practical algorithm.

00:11:12.715 --> 00:11:16.370
So if our document collection is huge.

00:11:16.370 --> 00:11:20.070
We actually want tot build
an array which has save

00:11:20.070 --> 00:11:23.730
every document say tat we might
have 20 billion document.

00:11:23.730 --> 00:11:28.400
So something like that and
say system used methods to work out

00:11:28.400 --> 00:11:32.770
are likely documents, and
only accumulators for those documents.

00:11:32.770 --> 00:11:38.840
And similarly at the end,
it's not a good way to find the most

00:11:38.840 --> 00:11:43.750
relevant documents by simply doing
a linear scan of this scores array, and so

00:11:43.750 --> 00:11:46.460
there are more efficient
data structures to do that.

00:11:46.460 --> 00:11:50.700
But I hope that that's given you
a general idea of how we can build

00:11:50.700 --> 00:11:53.880
cosine similarity scoring into
a ranked retrieval engine.

00:11:55.130 --> 00:11:58.700
So to summarize,
the essence of what we've covered for

00:11:58.700 --> 00:12:02.750
vector space retrieval
is the following steps.

00:12:02.750 --> 00:12:06.530
That the query represented
as a t f i d f vector.

00:12:06.530 --> 00:12:12.090
The document is also represented
as a t f i d f vector.

00:12:12.090 --> 00:12:19.340
And then, to score a pair of a query and
a document Command.

00:12:19.340 --> 00:12:22.240
We're working out cosine
similarity scores,

00:12:22.240 --> 00:12:25.810
which we straightforwardly use
to rank the documents with.

00:12:25.810 --> 00:12:30.620
And then what we'll do in the first
instance is return some top Ks, for

00:12:30.620 --> 00:12:34.670
example the top ten documents
according to this score to the user

00:12:34.670 --> 00:12:36.200
as their initial results.

00:12:36.200 --> 00:12:38.330
And if they ask for more,
we can then show them more.

00:12:39.680 --> 00:12:44.712
Okay, so that's the general idea of
how we can start to build a tf-idf

00:12:46.007 --> 00:12:47.761
retrieval system.

