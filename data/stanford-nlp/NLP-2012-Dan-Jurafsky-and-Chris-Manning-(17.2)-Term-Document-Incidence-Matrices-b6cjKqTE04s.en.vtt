WEBVTT
Kind: captions
Language: en

00:00:01.070 --> 00:00:04.402
Hello, in this section I'm going
to introduce the important idea

00:00:04.402 --> 00:00:07.555
of a term-document matrix, but
also I'm going to explain why it

00:00:07.555 --> 00:00:11.856
isn't actually a practical data structure
for an informational retrieval system.

00:00:15.501 --> 00:00:19.621
We'll take as our example doing
information retrieval over the works of

00:00:19.621 --> 00:00:21.510
William Shakespeare.

00:00:21.510 --> 00:00:24.190
So let's suppose we have
this concrete question.

00:00:24.190 --> 00:00:27.490
Which plays of Shakespeare
contain the words Brutus and

00:00:27.490 --> 00:00:29.590
Caesar, but not Calpurnia.

00:00:30.630 --> 00:00:35.680
Well, if you're starting from a very
basic level of text searching commands

00:00:35.680 --> 00:00:39.430
the first think that you'd think
about to solve this problem is by

00:00:39.430 --> 00:00:43.650
using searching through the text
of the documented source and

00:00:43.650 --> 00:00:46.369
play, what's known in
the Unix world as grepping.

00:00:47.370 --> 00:00:51.890
And so, we could first of all grep for
plays that contain Brutus and

00:00:51.890 --> 00:00:56.280
Caesar and then if you know your grep
command well you can give a flag for

00:00:56.280 --> 00:01:00.860
files that do not match, and you could get
out the ones that don't contain Calpurnia.

00:01:02.210 --> 00:01:07.340
Now these days for works of
the size of William Shakespeare for

00:01:07.340 --> 00:01:11.740
this kind of query, grepping is
a perfectly satisfactory solution.

00:01:11.740 --> 00:01:14.240
Now destrives and
computers are sufficiently

00:01:14.240 --> 00:01:19.020
fast that you could use this method and it
takes no time at all to find the answer.

00:01:19.020 --> 00:01:21.680
But nevertheless,
that isn't a good answer for

00:01:21.680 --> 00:01:24.460
the full information retrieval problem.

00:01:24.460 --> 00:01:27.400
It falls flat in a number of ways.

00:01:27.400 --> 00:01:31.470
Once your corpus becomes large,
hence that means something

00:01:31.470 --> 00:01:35.870
like everything on your hard disk or
even more so, the world wide web, we can't

00:01:35.870 --> 00:01:41.040
afford to do a linear scan through all
that documents every time we have a query.

00:01:41.040 --> 00:01:43.980
Then some parts for like the not part

00:01:43.980 --> 00:01:48.890
become less trivial to implement
than just finding things.

00:01:48.890 --> 00:01:53.960
But even more so than the not part, we'll
have more complex queries, like finding

00:01:53.960 --> 00:01:59.520
uses of the word Romans near countrymen,
and we can't do that with a grep command.

00:01:59.520 --> 00:02:04.150
But, even more than that, the big thing
that's happened in information retrieval

00:02:04.150 --> 00:02:07.900
is the idea of making,
finding the best documents to return for

00:02:07.900 --> 00:02:10.970
a query, and
that's something that we just can't get

00:02:10.970 --> 00:02:14.790
out of the linear scan model
while finding things that match.

00:02:14.790 --> 00:02:17.920
And we'll talk about all of these issues
and the way they're handled in modern

00:02:17.920 --> 00:02:21.100
information retrieval
systems in later lectures.

00:02:22.310 --> 00:02:26.950
But let's first go to this idea
of a term-document matrix.

00:02:26.950 --> 00:02:31.330
So what we do in a term-document
matrix is that we have

00:02:31.330 --> 00:02:37.530
the rows of the matrix are our words,

00:02:37.530 --> 00:02:41.510
or often they're also called
an information retrieval of the terms.

00:02:41.510 --> 00:02:45.960
And then the columns of
the matrix are our documents.

00:02:49.780 --> 00:02:52.900
And we're doing here is
a very simple thing.

00:02:52.900 --> 00:02:58.810
We're simply saying, let's fill in
every cell in this boolean matrix,

00:02:58.810 --> 00:03:01.890
like whether the word
appears in the play or not.

00:03:01.890 --> 00:03:05.980
So Anthony, appears in Anthony and
Cleopatra, but

00:03:05.980 --> 00:03:09.060
Calpurnia does not appear in Anthony and
Cleopatra.

00:03:10.640 --> 00:03:14.940
So this matrix represents
the appearance of words in documents.

00:03:14.940 --> 00:03:20.750
And if we have this matrix, it's straight
forward to then answer boolean queries,

00:03:20.750 --> 00:03:21.940
such as our example before.

00:03:21.940 --> 00:03:28.620
Before queries for documents that contain
Brutus and Caesar, but not Calpurnia.

00:03:28.620 --> 00:03:31.290
Let's just go through
concretely how we do that.

00:03:31.290 --> 00:03:35.750
So, what we're going to do is we're
going to take the vectors for the term

00:03:35.750 --> 00:03:40.490
in the query, and then we're going to put
them together with boolean operations.

00:03:40.490 --> 00:03:46.459
So first of all, we can take out
the row that is referring to Brutus.

00:03:48.270 --> 00:03:49.180
It goes up here.

00:03:50.850 --> 00:03:57.290
Then, we can take the row for
Caesar and it there.

00:03:59.220 --> 00:04:02.570
And then finally, we can take the row for

00:04:02.570 --> 00:04:07.060
Calpurnia, complement it and
then stick it down here.

00:04:07.060 --> 00:04:12.000
So Calpurnia only appears in
Julius Caesar and so, we complemented

00:04:12.000 --> 00:04:16.470
it to a vector where everything is one and
apart from Julius Caesar.

00:04:16.470 --> 00:04:22.528
And at that point we can just and those
three vectors together and the answer is.

00:04:22.528 --> 00:04:26.185
This 1 of 100100.

00:04:26.185 --> 00:04:31.914
And so we've been able to do information
retrieval successfully, and can tell that

00:04:31.914 --> 00:04:37.850
this query is satisfied by the documents,
Antony and Cleopatra and Hamlet.

00:04:37.850 --> 00:04:41.370
And indeed, we can then go off
to the document collection and

00:04:41.370 --> 00:04:44.050
confirm that that is the case.

00:04:44.050 --> 00:04:49.115
So here we are, so in Antony and
Cleopatra, when Antony found Julius Caesar

00:04:49.115 --> 00:04:54.204
dead, he cried almost roaring and
he wept when at Philippi Brutus is slain.

00:04:54.204 --> 00:04:58.050
And similarly we find both
words occurring in Hamlet.

00:04:59.830 --> 00:05:04.430
Okay, so that's the suggests that
we could do information retrieval

00:05:04.430 --> 00:05:08.150
simply by working with
this term document matrix.

00:05:08.150 --> 00:05:11.750
So an important thing to realize
is that doesn't really work

00:05:11.750 --> 00:05:14.430
once we go to sensible size collections.

00:05:14.430 --> 00:05:17.040
And so let's just go through that for
a minute.

00:05:17.040 --> 00:05:21.020
Let's go through a sensible sized,
but still small collection.

00:05:21.020 --> 00:05:26.130
So, suppose that we have 1 million
documents, and we'll often use N to refer

00:05:26.130 --> 00:05:31.550
to the number of documents, each of
which is on average 1,000 words long.

00:05:31.550 --> 00:05:36.680
Okay, so what does that mean
in terms of the size of our

00:05:36.680 --> 00:05:39.490
document collection and
in terms of the size of our matrix.

00:05:40.620 --> 00:05:45.330
So, if we have an average of six
bytes per word including spaces and

00:05:45.330 --> 00:05:49.450
punctuation the amount of data we're
talking about here is six gigabytes.

00:05:49.450 --> 00:05:54.100
So that a tiny fraction of one,
one hard disk in your laptop.

00:05:54.100 --> 00:05:58.560
But, let us then suppose,
we try and work out how many

00:05:58.560 --> 00:06:03.320
distinct terms there are in
our document collection.

00:06:03.320 --> 00:06:05.790
And we need to know
the number of distinct terms,

00:06:05.790 --> 00:06:08.990
because that corresponds to
the number of columns now matrix.

00:06:08.990 --> 00:06:13.130
And let's suppose they're about 500k,
that'll be a typical number for

00:06:13.130 --> 00:06:14.580
a million documents.

00:06:14.580 --> 00:06:17.800
So often refer to this number
of different terms as M.

00:06:17.800 --> 00:06:19.970
Well what does that mean?

00:06:19.970 --> 00:06:25.640
Well what it means is that even with that
size document collection we can't build

00:06:25.640 --> 00:06:32.050
this term document matrix because we'll
have 500,000 rows and a million columns.

00:06:32.050 --> 00:06:35.040
And that's half a trillion 0's and 1's.

00:06:35.040 --> 00:06:39.760
It's already huge, and probably
bigger than we have space to store.

00:06:39.760 --> 00:06:43.120
And as the document collection gets
bigger than a million documents,

00:06:43.120 --> 00:06:44.770
things are just going to get worse.

00:06:46.130 --> 00:06:51.130
But there's this really important
observation, which is although

00:06:51.130 --> 00:06:56.420
the matrix here had half
a trillion 0's and 1's are that,

00:06:56.420 --> 00:07:01.670
that actually almost all
of the entries are 0.

00:07:01.670 --> 00:07:07.050
But the document has at
most one billion 1's.

00:07:07.050 --> 00:07:10.410
And it'd be good for
you guys just stop and think for

00:07:10.410 --> 00:07:15.880
a fraction of a second why is it that
there's at most one billion ones.

00:07:17.790 --> 00:07:24.740
And the answer to that is well,
if we have 1M documents,

00:07:24.740 --> 00:07:29.750
and the average document Is 1,000
words long, as we said last time,

00:07:29.750 --> 00:07:34.660
then the actual number of word
tokens is only one billion.

00:07:34.660 --> 00:07:39.330
So even if we assume that every word
in every document were different,

00:07:39.330 --> 00:07:43.140
we could only have, at most,
one billion 1 entries.

00:07:43.140 --> 00:07:47.080
And most likely, we have far less than
that because we'll have common words like

00:07:47.080 --> 00:07:52.380
there, are, of and to occurring many many
times in each document and so, therefore

00:07:52.380 --> 00:07:58.920
the key observation is the matrix we are
dealing with is very, very, very sparse.

00:07:58.920 --> 00:08:04.311
So the central question in
the design of information retrieval

00:08:04.311 --> 00:08:09.194
data structures is taking
advantage of that sparsity and

00:08:09.194 --> 00:08:13.175
coming up with a better
data representation.

00:08:13.175 --> 00:08:18.949
And the secret of doing that and having an
efficient storage mechanism is we want to

00:08:18.949 --> 00:08:24.570
only record the positions that hold a one
and not the positions that hold a zero.

00:08:26.970 --> 00:08:32.660
Okay, so I have given you an understanding
of the term document matrix.

00:08:32.660 --> 00:08:35.340
It is an important
conceptual data structure

00:08:35.340 --> 00:08:38.030
that we keep on coming back to again and
again.

00:08:38.030 --> 00:08:43.140
When we talk about various types of
algorithms, we think about them in terms

00:08:43.140 --> 00:08:47.940
of that matrix as you will see, but
when we actually come to doing storage in

00:08:47.940 --> 00:08:53.360
computer systems we can also see
that we never actually want to store

00:08:53.360 --> 00:08:57.540
documents and the information
retrieval representation in that form.

