WEBVTT
Kind: captions
Language: en

00:00:00.500 --> 00:00:04.320
In this segment i'm going to introduce
the idea of lexicalizing PCFGs.

00:00:05.760 --> 00:00:08.580
So let's look at a basic PCFG here and

00:00:08.580 --> 00:00:11.990
see how the probabilities
of rules actually work.

00:00:11.990 --> 00:00:17.878
So what we have in the PCFG
is local trees corresponding

00:00:17.878 --> 00:00:22.742
to rules such as verb
phrase rewrites as VBD,

00:00:22.742 --> 00:00:27.993
PP and
that has some probability attached to it.

00:00:27.993 --> 00:00:32.413
Like maybe that probability
be 0.03 about 3% of verb

00:00:32.413 --> 00:00:37.650
phrases expand as a past tense
verb in a prepositional phrase.

00:00:37.650 --> 00:00:41.120
While similarly we have other
rules that we have up here.

00:00:41.120 --> 00:00:44.072
A sentence goes to NP VP rule.

00:00:46.708 --> 00:00:48.920
And that would have a much
higher probability.

00:00:48.920 --> 00:00:52.260
Maybe its probability is 0.4 or
something like that.

00:00:52.260 --> 00:00:57.030
But the really important
thing to notice is that

00:00:57.030 --> 00:01:01.760
these rules make no reference
whatsoever to actual words.

00:01:01.760 --> 00:01:04.410
So this is saying that overall,

00:01:06.370 --> 00:01:11.570
about 3% of verb phrases consist of a past
tense verb and a prepositional phrase.

00:01:11.570 --> 00:01:12.700
But whether that's likely or

00:01:12.700 --> 00:01:16.660
not depends an awful lot on
which verb we're dealing with.

00:01:16.660 --> 00:01:21.910
So in this example here, we have the word
verb walked and walked is the kind of

00:01:21.910 --> 00:01:27.840
motion verb that is really, really
likely to have a PP following after it.

00:01:27.840 --> 00:01:33.920
Whereas if we had another verb for
example if we had the verb saw.

00:01:33.920 --> 00:01:36.020
Then that'd be a past tense verb but

00:01:36.020 --> 00:01:40.010
it'd be really unlikely to have
a prepositional phrase coming after it.

00:01:40.010 --> 00:01:45.930
Something like, he saw in the mirror,
or something like that.

00:01:45.930 --> 00:01:50.700
You'd normally get a noun-phrase
object after saw first.

00:01:50.700 --> 00:01:54.910
So, it seems like we can only really
come up with good probability estimates

00:01:54.910 --> 00:01:57.130
if we know more about
the words in the sentence.

00:01:57.130 --> 00:02:01.850
And so that's precisely what
the idea of lexicalization is.

00:02:01.850 --> 00:02:05.390
The idea of lexicalization is,
let's define for

00:02:05.390 --> 00:02:09.010
each category a way of finding its head.

00:02:09.010 --> 00:02:12.902
For a noun phrase we'll say
that the last noun in it,

00:02:12.902 --> 00:02:18.450
whether a proper noun or a common noun,
will be declared its head.

00:02:18.450 --> 00:02:24.410
And so, this noun phrase we'll
say that its head is Sue.

00:02:24.410 --> 00:02:29.230
And for this noun phrase here we'll
say that its head is the word store.

00:02:30.530 --> 00:02:34.190
Because this is the last
noun in the noun phrase and

00:02:34.190 --> 00:02:35.820
we'll apply that to other ideas.

00:02:35.820 --> 00:02:40.320
So for verb phrase the head of a verb
phrase will be the verb inside it.

00:02:40.320 --> 00:02:43.830
So the head of verb phrase is walked.

00:02:43.830 --> 00:02:47.990
And for a prepositional phrase the head
will be the preposition inside it into.

00:02:49.980 --> 00:02:54.150
And we'll say that the head of
a sentence is the head of a verb phrase.

00:02:54.150 --> 00:02:58.080
So we put in this way lexical items

00:02:58.080 --> 00:03:02.850
that represent the head of each phrase
next to each non-terminal in the grammar.

00:03:02.850 --> 00:03:07.380
Let me give my more neatly
printed version of that here.

00:03:07.380 --> 00:03:09.770
Okay well what happens if we do that?

00:03:09.770 --> 00:03:14.990
Well what we then find is that
we've now got these categories.

00:03:14.990 --> 00:03:18.340
Like S walked which
are a combination of our

00:03:18.340 --> 00:03:22.240
old nonterminals plus some lexical item.

00:03:22.240 --> 00:03:27.190
And so if we do that we've enormously,

00:03:27.190 --> 00:03:30.980
enormously expanded our
affected space of nonterminals.

00:03:30.980 --> 00:03:35.050
Because if we had something
like 20 nonterminals before but

00:03:35.050 --> 00:03:39.060
we had something like 30,000
words in our vocabulary.

00:03:39.060 --> 00:03:43.000
Well, now we've got 600,000
nonterminals in our grammar.

00:03:43.000 --> 00:03:47.240
And so that suggests we need to start
doing some more special engineering to be

00:03:47.240 --> 00:03:48.470
able to do that.

00:03:48.470 --> 00:03:50.420
Let's not worry about that for
the moment and

00:03:50.420 --> 00:03:54.450
let's just think in terms of probabilities
what this will allow us to do.

00:03:54.450 --> 00:03:58.000
Well the neat thing this
will allow us to do is

00:03:58.000 --> 00:04:02.710
now if we're looking at what's
the probability of this sub tree.

00:04:02.710 --> 00:04:06.260
We won't just be saying what's
the probability of a verb.

00:04:07.450 --> 00:04:11.600
Expanding to a past tense verb phrase,
expanding into a past tense verb and a PP.

00:04:11.600 --> 00:04:16.585
We'll be saying what's the probability of
a verb phrase headed by walk making a PP,

00:04:16.585 --> 00:04:22.070
in particular a PP that's headed by into.

00:04:22.070 --> 00:04:26.670
And so we're now going to be
capturing inside the wall two things.

00:04:27.750 --> 00:04:31.564
We'll be capturing both that a VP walk

00:04:34.943 --> 00:04:41.080
Is likely to take a PP after it.

00:04:41.080 --> 00:04:45.930
And we will be capturing
the relationship between the heads here.

00:04:45.930 --> 00:04:48.950
So we'll be capturing the relationship

00:04:48.950 --> 00:04:53.410
that is reasonable to have
someone walk into something.

00:04:55.230 --> 00:04:59.210
And so we have a lot of much richer
probabilistic conditioning being captured

00:04:59.210 --> 00:04:59.860
by our grammar.

00:05:02.070 --> 00:05:04.250
This extra information will be really,

00:05:04.250 --> 00:05:07.870
really useful for
resolving various kinds of ambiguities.

00:05:07.870 --> 00:05:12.490
So a classic example of that is
prepositional phrase attachment.

00:05:12.490 --> 00:05:17.740
So if we want to work out for
a prepositional phrase, whether,

00:05:17.740 --> 00:05:25.010
it is modifying a noun that precedes,
or modifying a verb that precedes.

00:05:25.010 --> 00:05:31.174
Well, we can capture quite a lot of that
inside a PCFG, once we lexicalize it.

00:05:31.174 --> 00:05:35.360
because now,
we'll have a role where an NP rates

00:05:35.360 --> 00:05:38.820
is taking on its right hand side,
a PP for.

00:05:38.820 --> 00:05:42.620
And we can ask whether that is
a likely thing to happen or not.

00:05:42.620 --> 00:05:46.727
Or we can say we have
a VP announce is taking,

00:05:46.727 --> 00:05:50.750
expanding on its right
hand side to a PP in.

00:05:50.750 --> 00:05:52.750
Is that a reasonable thing to happen or
not?

00:05:53.790 --> 00:05:57.426
And so
we can use this information to better

00:05:57.426 --> 00:06:01.976
model PP attachments than
we could in a vanilla PCFG.

00:06:01.976 --> 00:06:05.154
That doesn't mean we can capture
everything about PP attachments in this

00:06:05.154 --> 00:06:06.250
model though.

00:06:06.250 --> 00:06:08.010
And actually if you want to,

00:06:08.010 --> 00:06:11.670
you could think a little, about what other
things that you'd like to know about

00:06:11.670 --> 00:06:16.320
attaching a prepositional phrase,
which aren't yet captured in this model.

00:06:16.320 --> 00:06:21.430
Where we have a head word pinned
onto every phrase like this.

00:06:21.430 --> 00:06:22.170
But nonetheless,

00:06:22.170 --> 00:06:26.740
this kind of head lexicalization captures
most of the additional things that you'd

00:06:26.740 --> 00:06:30.520
like to know to make the various
passing decisions of a sentence.

00:06:30.520 --> 00:06:34.540
So it's also useful for
things like coordination scope,

00:06:34.540 --> 00:06:38.530
knowing about the complementation
patterns of verbs and so on.

00:06:38.530 --> 00:06:44.060
Indeed there was the case that
doing this lexicalization

00:06:44.060 --> 00:06:49.480
of PCFGs was seen as the parsing
breakthrough of the late 1990s.

00:06:49.480 --> 00:06:52.920
So that's a really useful
notion to know about.

00:06:52.920 --> 00:06:57.900
Is this idea of lexicalizing PCFGs
to capture more of the necessary

00:06:57.900 --> 00:07:01.530
probabilistic conditioning information
to make parsing decisions.

