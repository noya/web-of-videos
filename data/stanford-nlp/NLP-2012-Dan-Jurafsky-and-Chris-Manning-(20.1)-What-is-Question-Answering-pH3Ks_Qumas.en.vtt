WEBVTT
Kind: captions
Language: en

00:00:02.070 --> 00:00:03.350
Welcome back.

00:00:03.350 --> 00:00:04.890
Today we're going to look
at question answering,

00:00:04.890 --> 00:00:07.830
one of the oldest applications
in natural language processing.

00:00:09.020 --> 00:00:13.244
Some of the first NLP tasks, built on
punched card systems in the early 60s,

00:00:13.244 --> 00:00:16.330
include the Simmons,
that old system, from 1964.

00:00:16.330 --> 00:00:18.980
Let's look at that.

00:00:18.980 --> 00:00:22.530
So, that answered questions,
like, what do worms eat?

00:00:22.530 --> 00:00:26.050
By taking the question,
parsing it into its dependency format so

00:00:26.050 --> 00:00:30.402
we have a relationship between eat and
worms, and eat and what, and then looking

00:00:30.402 --> 00:00:35.100
for a matching dependency sentence
somewhere in a large database of answers.

00:00:35.100 --> 00:00:38.360
So they had sentences like worms
eat grass, and birds eat worms,

00:00:38.360 --> 00:00:41.600
and horses with worms eat grass,
and so on.

00:00:41.600 --> 00:00:46.700
And the idea is that this
dependency Treelet worms eat what

00:00:46.700 --> 00:00:52.120
match worms eat grass and
even grass is eaten by worms but

00:00:52.120 --> 00:00:56.070
not horses eat grass or birds eat worms.

00:00:56.070 --> 00:00:59.510
So the idea of answering the question
by finding a sentence that

00:00:59.510 --> 00:01:01.860
looks like the question but answers it,

00:01:01.860 --> 00:01:05.640
is an old intuition that we're going to
see underlies many modern systems as well.

00:01:07.260 --> 00:01:08.810
You may know that last year,

00:01:08.810 --> 00:01:14.670
IBM's Watson won the Jeopardy challenge
answering questions about, for example,

00:01:14.670 --> 00:01:19.930
this Bram Stoker novel that was
inspired by William Wilkinson's book so

00:01:19.930 --> 00:01:23.250
the novel of course was Dracula,
and the author was Bram Stoker.

00:01:25.130 --> 00:01:29.440
And you may also know about Apple's Siri,
another question answering application.

00:01:29.440 --> 00:01:32.530
So you can ask questions like, do I need
an umbrella tomorrow in San Francisco, and

00:01:32.530 --> 00:01:35.240
it will check the weather for you and
tell you which days it's going to rain.

00:01:38.260 --> 00:01:41.980
Another question answering application,
Wolfram Alpha, you can ask questions like

00:01:41.980 --> 00:01:45.100
how many calories are in two
slices of banana cream pie?

00:01:45.100 --> 00:01:47.630
And not only will it give the answer, but

00:01:47.630 --> 00:01:49.670
it'll give you little
variables that it lets you.

00:01:49.670 --> 00:01:51.750
It'll tell you the semantics
of the answer.

00:01:51.750 --> 00:01:56.150
So, we're looking for an amount of pie
that's two slices of banana cream type,

00:01:56.150 --> 00:01:59.230
and we're asking about the total calories,
and there's the answer.

00:02:00.310 --> 00:02:01.250
702 calories.

00:02:04.530 --> 00:02:08.380
So these kind of questions
are factoid questions.

00:02:08.380 --> 00:02:11.960
So questions like, how many calories
are there in two slices of apple pie?

00:02:11.960 --> 00:02:14.500
Or who wrote The Universal Declaration
of Human Rights?

00:02:14.500 --> 00:02:17.300
Or what is the average age
of the onset of autism?

00:02:17.300 --> 00:02:21.490
These kind of questions, pretty simple
questions can be answered by a simple fact

00:02:21.490 --> 00:02:24.620
off an identity.

00:02:24.620 --> 00:02:27.810
Modern systems also deal with complex or
narrative questions.

00:02:27.810 --> 00:02:30.700
So in children with
an acute febrile illness,

00:02:30.700 --> 00:02:33.420
what is the efficacy of
acetaminophen in reducing fever?

00:02:33.420 --> 00:02:36.050
Or, what do scholars think
about Jefferson's position on

00:02:36.050 --> 00:02:37.520
dealing with pirates?

00:02:37.520 --> 00:02:43.459
So these complex questions
are generally answered more in research

00:02:43.459 --> 00:02:51.180
systems whereas factoid question answering
is a widely used commercial application.

00:02:51.180 --> 00:02:53.620
What are these kind of factoid questions?

00:02:53.620 --> 00:02:56.290
So they can be questions about locations.

00:02:56.290 --> 00:03:00.700
So the Louvre being located in Paris,
France, or what an abbreviation means,

00:03:00.700 --> 00:03:04.930
or the names of the ravens of Odin,

00:03:05.930 --> 00:03:11.360
names of a currency or an ingredient,
or an instrument or a phone number.

00:03:11.360 --> 00:03:14.812
So, they're all simple answers often
with a single phrase or name entity.

00:03:17.608 --> 00:03:21.290
There are two main paradigms for
question answering.

00:03:21.290 --> 00:03:26.374
The IR based approach which will spend a
lot of time on today and that's pioneered

00:03:26.374 --> 00:03:31.161
in the annual track evaluations and
used in commercial systems like IBMs and

00:03:31.161 --> 00:03:36.500
Googles, and the IR-based approaches go
find the answer in some string on the web.

00:03:37.770 --> 00:03:42.643
The knowledge-based approach is build
an answer from understanding parts of

00:03:42.643 --> 00:03:47.808
the question, and the hybrid approach is
take a combination of these approaches,

00:03:47.808 --> 00:03:52.161
so we might use some online databases and
we might use some information

00:03:52.161 --> 00:03:56.390
retrieval approaches to find sentences and
build answers.

00:03:56.390 --> 00:04:01.159
And most modern systems, I would say,
are some kind of hybrid of knowledge and

00:04:01.159 --> 00:04:02.760
information retrieval.

00:04:02.760 --> 00:04:05.958
A few of them like perhaps Wolfram Alpha
are purely knowledge based, but

00:04:05.958 --> 00:04:07.645
most systems use a little bit of both.

00:04:11.260 --> 00:04:15.030
So, simple web search actually
answers a lot of questions already.

00:04:15.030 --> 00:04:17.870
And that's really the intuition
underlying the IR based approach

00:04:17.870 --> 00:04:19.560
to question answering that
we'll talk about the most.

00:04:20.640 --> 00:04:25.120
So, if I asked into Google,
what are the names of Odin's ravens?

00:04:25.120 --> 00:04:27.070
The first page I get has the answer.

00:04:27.070 --> 00:04:30.290
And in this snippet that Google returns,
there's the answer.

00:04:30.290 --> 00:04:33.650
So it's in the title of this page and
talks about the names of the ravens.

00:04:38.270 --> 00:04:43.070
Other kinds of simple questions,
like where is the Louvre Museum located,

00:04:43.070 --> 00:04:45.920
are also answerable by
methods like Google.

00:04:45.920 --> 00:04:50.572
And here, in fact,
Google applies modern question answering

00:04:50.572 --> 00:04:55.749
techniques to give you its best guess for
the location by pulling it out

00:04:55.749 --> 00:05:00.710
of semi-structured resources
like Wikipedia or Answers.com.

00:05:00.710 --> 00:05:03.790
So, let's see how this factoid
question answering algorithm works.

00:05:04.820 --> 00:05:10.030
The general algorithm for IR-based factoid
question answering starts with a question

00:05:10.030 --> 00:05:13.658
and begins by extracting information
from the question itself.

00:05:13.658 --> 00:05:17.530
And the two most important and
common things to extract from the question

00:05:17.530 --> 00:05:20.440
are a query that's going to
be sent to an IR engine, and

00:05:20.440 --> 00:05:23.630
the type of the answer that tells us what
kind of name entity we're looking for.

00:05:25.280 --> 00:05:28.910
In advance, we take a whole lot
of documents, we index them, so

00:05:28.910 --> 00:05:32.720
that when we have a query,
we can return a whole lot of documents.

00:05:32.720 --> 00:05:37.210
From those documents, we extract
passages or parts of those documents and

00:05:37.210 --> 00:05:42.580
then those passages are then processed
in Answer Processing looking for

00:05:42.580 --> 00:05:44.860
the type of the answer
that we are looking for.

00:05:44.860 --> 00:05:46.940
And then we are turning
in an actual answer.

00:05:46.940 --> 00:05:48.100
So that's the general process.

00:05:48.100 --> 00:05:49.700
And we'll walk through the pieces today.

00:05:52.120 --> 00:05:54.360
So, another way of looking at
the same set of processes.

00:05:54.360 --> 00:05:58.290
Three big parts of the algorithm,
question processing, so

00:05:58.290 --> 00:06:01.440
we're detecting the question type,
formulating the queries.

00:06:01.440 --> 00:06:04.590
Passage retrieval,
given these queries retrieve documents,

00:06:04.590 --> 00:06:06.060
break them into pieces.

00:06:06.060 --> 00:06:10.191
And then answer processing,
extract answers from the text snippets and

00:06:10.191 --> 00:06:15.010
rank those candidates using evidence from
the text and from other kinds of sources.

00:06:15.010 --> 00:06:18.961
So by contrast, the knowledge-based
approach which we will talk about less

00:06:18.961 --> 00:06:22.668
today, builds a pure semantic
representation of the query as if you have

00:06:22.668 --> 00:06:26.011
Siri or Wolfram Alpha where they're
going to come up with a semantic

00:06:26.011 --> 00:06:29.330
representation language for
questions that they understand.

00:06:29.330 --> 00:06:33.191
And you might pick some sub domain that
you're able to build a perfect semantic

00:06:33.191 --> 00:06:34.596
representation for times,

00:06:34.596 --> 00:06:38.700
dates, locations, scientific questions,
mathematical questions.

00:06:38.700 --> 00:06:42.845
And from these semantics,
we can then map to structure databases or

00:06:42.845 --> 00:06:44.380
structured resources.

00:06:44.380 --> 00:06:48.100
Geospatial databases or ontologies or
restaurant review systems.

00:06:48.100 --> 00:06:51.170
These things where we can build
up your semantic of the approach.

00:06:54.108 --> 00:06:57.557
Hybrid approaches, and IBM Watson is
a good example of this, but lots of others

00:06:57.557 --> 00:07:00.710
do this now, build some shallow
semantic representation of the query.

00:07:00.710 --> 00:07:03.195
So, they do some processing of the query,

00:07:03.195 --> 00:07:06.450
use IR methods to generate
many candidate answers.

00:07:06.450 --> 00:07:10.517
But then use these more knowledge-based
approaches to use spatial databases or

00:07:10.517 --> 00:07:12.860
temporal reasoning to
score the candidates.

00:07:12.860 --> 00:07:16.712
So, IR methods to find
possible candidates,

00:07:16.712 --> 00:07:20.280
knowledge-based methods to score them.

00:07:20.280 --> 00:07:23.547
So question answering is both one of
the oldest topics in natural language

00:07:23.547 --> 00:07:25.339
processing and also one of the newest and

00:07:25.339 --> 00:07:27.990
most exciting research areas
with commercial potential.

