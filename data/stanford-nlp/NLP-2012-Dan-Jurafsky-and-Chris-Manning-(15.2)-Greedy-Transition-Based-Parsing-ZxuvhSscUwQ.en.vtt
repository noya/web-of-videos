WEBVTT
Kind: captions
Language: en

00:00:00.920 --> 00:00:04.880
In this segment I'm going to look
at the greedy transition based

00:00:04.880 --> 00:00:07.110
pausing approach to dependency pausing.

00:00:07.110 --> 00:00:11.050
And in particular I'm going to describe
the model that's used by MaltParser,

00:00:11.050 --> 00:00:13.470
the best known example of this framework.

00:00:14.830 --> 00:00:23.260
So the idea of MaltParser is that maybe
we can do parsing by just making simple

00:00:23.260 --> 00:00:29.300
greedy decisions as to how to
attach each word as it comes along.

00:00:29.300 --> 00:00:32.020
And in particular,
to make those decisions or

00:00:32.020 --> 00:00:35.590
use a discriminative machine
learning classifier.

00:00:35.590 --> 00:00:39.770
So the parser does a sequence of actions,
working bottom-up,

00:00:39.770 --> 00:00:41.680
kind of like a shift reduce parser,

00:00:41.680 --> 00:00:47.640
if you've seen that in either CFG parsing
or in the programming language literature.

00:00:47.640 --> 00:00:52.250
The parser has a stack which will be
written with the top to the right, and

00:00:52.250 --> 00:00:55.750
which will start off with a ROOT symbol
on it as I introduced last time.

00:00:55.750 --> 00:00:56.970
And then a buffer,

00:00:56.970 --> 00:01:01.490
which is the stuff we get to look at
with the top written to the left.

00:01:01.490 --> 00:01:03.910
And so,
that will have the input sentence on it.

00:01:03.910 --> 00:01:04.890
And as we go along,

00:01:04.890 --> 00:01:08.500
we'll build up a set of dependency arcs,
which starts off empty.

00:01:08.500 --> 00:01:11.350
And we'll do this by
doing a set of actions.

00:01:13.050 --> 00:01:18.560
This is the natural way to think of
a transition-based dependency parser.

00:01:18.560 --> 00:01:23.690
So this is our start configuration
with our Stack the buffer and

00:01:23.690 --> 00:01:26.800
the empty set of dependency arcs.

00:01:26.800 --> 00:01:31.750
And so essentially our moves
are that we can shift a word

00:01:31.750 --> 00:01:36.490
across from the buffer
onto the stack which

00:01:36.490 --> 00:01:42.080
is like the shift operation for CFG
parsing, or we can do a reduce operation.

00:01:42.080 --> 00:01:47.250
Now, in dependency parsing framework,
we end up with two reducer operations

00:01:47.250 --> 00:01:50.470
depending on whether we're
taking the word on the left or

00:01:50.470 --> 00:01:52.510
the word on the right as the head.

00:01:53.880 --> 00:01:57.580
So, here we have word i and word j.

00:01:57.580 --> 00:02:04.040
And if we take a word on the right
as the head, we get a left arc.

00:02:04.040 --> 00:02:07.900
That means we're kind of creating
an arc that points like this,

00:02:07.900 --> 00:02:11.950
which is being added to
our set of arcs here.

00:02:11.950 --> 00:02:17.920
Or, if we do a right arc operation, we are
having a dependency that goes this way.

00:02:17.920 --> 00:02:23.570
So on the word on the buffer is being
a dependent of the word on the stack.

00:02:23.570 --> 00:02:28.350
Now if it's untyped dependency parsing,
there are just these two operations.

00:02:28.350 --> 00:02:33.080
If you want to do typed dependency parsing
you also when you do this reduction

00:02:33.080 --> 00:02:37.850
have to say what label you're
using to connect the two words.

00:02:37.850 --> 00:02:42.890
And so that means if you have 20 labels,
you actually end up with 20

00:02:42.890 --> 00:02:48.710
times two plus one, 41 different
actions in your dependency parse.

00:02:48.710 --> 00:02:51.460
And you finish when you've
exhausted the buffer.

00:02:53.020 --> 00:02:58.820
Now something to note here is
that if you have seen parsing.

00:02:58.820 --> 00:03:03.200
This something that's slightly
unusual with this presentation here.

00:03:03.200 --> 00:03:07.780
So normally in shift-reduced parsing,
CFGs, you first of all

00:03:07.780 --> 00:03:11.740
put things on the stack and
the reduction is done fully on the stack.

00:03:11.740 --> 00:03:13.920
But for the model that's being shown here,

00:03:13.920 --> 00:03:19.160
when you are doing the reductions in
either direction, you're actually doing

00:03:19.160 --> 00:03:24.340
a reduction with one thing that's on the
stack and one thing that's on the buffer.

00:03:24.340 --> 00:03:27.050
That's just a convention that's

00:03:27.050 --> 00:03:30.830
standard in what you see in
the dependency parser in literature.

00:03:30.830 --> 00:03:35.710
The claim is that is makes it a little
bit cleaner to formulate things that way.

00:03:35.710 --> 00:03:38.120
Though I'm not actually sure
it makes a big difference, but

00:03:38.120 --> 00:03:41.210
I've gone with it because it's
just standardly what you see.

00:03:43.150 --> 00:03:47.000
This is a simple way to do things,
and you can do that, but

00:03:47.000 --> 00:03:50.270
it's not the standard thing
that people actually do.

00:03:50.270 --> 00:03:54.615
And so I'm going to move on next to
the most common method that you see for

00:03:54.615 --> 00:03:57.050
transition-based dependency parsers.

00:03:57.050 --> 00:04:01.900
And let me just explain why this simple
way is a little bit problematic.

00:04:01.900 --> 00:04:06.084
So that if you had a sentence of the sort,

00:04:06.084 --> 00:04:10.776
Sue tried to

00:04:10.776 --> 00:04:17.135
open the door in the cellar.

00:04:17.135 --> 00:04:21.500
Well,what you're going to have

00:04:21.500 --> 00:04:26.800
is that you have a dependency
from tried to open.

00:04:26.800 --> 00:04:31.390
And as soon as you've gone
up to hear in the Import.

00:04:31.390 --> 00:04:35.350
At least by then it's obvious that
you're going to have a dependency

00:04:35.350 --> 00:04:37.410
between tried to open.

00:04:37.410 --> 00:04:42.890
But if you're using the kind of three
action model of dependency parsing

00:04:42.890 --> 00:04:48.600
I'm showing here,
you can't construct this arc immediately.

00:04:48.600 --> 00:04:57.000
Instead because of the fact that
the door is a dependent of open and

00:04:57.000 --> 00:05:02.310
in the cellar is a dependent of door,
that you have to construct

00:05:02.310 --> 00:05:07.850
all of this material Before
you construct this arc here.

00:05:07.850 --> 00:05:12.040
So the closer of
the dependencies of a dependent

00:05:12.040 --> 00:05:17.100
have to be constructed before you
then hook it up to a higher head.

00:05:17.100 --> 00:05:21.160
So all of these dependencies
have to be constructed first.

00:05:21.160 --> 00:05:25.760
Well what that means is that you have
to have shifted on all of the words in

00:05:25.760 --> 00:05:30.360
the import before you can decide
anything about this dependency.

00:05:31.490 --> 00:05:35.940
And it's been found that having
to do that amount of look ahead,

00:05:35.940 --> 00:05:37.700
actually makes it harder.

00:05:37.700 --> 00:05:42.690
From machine learning as three
classifies the work well so

00:05:42.690 --> 00:05:48.990
instead what people wanted to
do is move to be able in greedy

00:05:48.990 --> 00:05:54.950
session Hook up local things on the right
even before you know their dependence.

00:05:54.950 --> 00:05:59.930
And so that's what's being done in
a different way of formulating the actions

00:05:59.930 --> 00:06:03.980
that's referred to as
arc-eager dependency parser.

00:06:03.980 --> 00:06:06.250
For the eager dependency parser,

00:06:06.250 --> 00:06:11.110
we have exactly the same start and
finish configurations.

00:06:11.110 --> 00:06:15.450
And the operations are sort of
similar there's a shift operation and

00:06:15.450 --> 00:06:18.550
there's these left arc and
right arc steps.

00:06:18.550 --> 00:06:22.590
Though we add in one new
operation a reduce operation but

00:06:22.590 --> 00:06:26.860
there are a number of differences
in the Subtleties of what works.

00:06:26.860 --> 00:06:29.450
Let's look at them for a moment.

00:06:30.600 --> 00:06:34.310
When you have the left arc operation,

00:06:34.310 --> 00:06:40.300
it's doing the same thing of
constructing a left dependency between

00:06:40.300 --> 00:06:45.260
the head that's in the and
the top word on the stack.

00:06:45.260 --> 00:06:50.464
And the result is the same that we
are constructing this new dependency but

00:06:50.464 --> 00:06:53.490
we have to add on to
it some preconditions.

00:06:53.490 --> 00:06:59.510
So, we need to have on a precondition
that W I isn't already

00:06:59.510 --> 00:07:04.650
a dependent of some other word because
if we allow that arc to be put in

00:07:04.650 --> 00:07:10.390
then we get an analysis where two arrows
would be pointing to the same word.

00:07:10.390 --> 00:07:15.910
And Precisely because of the arc-eager
character, words can already

00:07:15.910 --> 00:07:19.740
be on the stack even though they've been
made the dependent of some other word.

00:07:21.410 --> 00:07:24.900
The right arc operation
is a bit more different.

00:07:26.110 --> 00:07:30.700
So for the right arc operation
our starting point is exactly

00:07:30.700 --> 00:07:36.170
the same that we've now going to
Want to make an arrow like this.

00:07:36.170 --> 00:07:38.970
We have the head on the stack and

00:07:38.970 --> 00:07:43.320
the dependent at the beginning of
the buffer and we add this dependency.

00:07:43.320 --> 00:07:48.309
But the difference is,
we then Rather than getting

00:07:48.309 --> 00:07:52.146
rid of wj that we push it on to the stack.

00:07:52.146 --> 00:07:56.102
So that means that we are keeping
the word on the right so

00:07:56.102 --> 00:07:59.206
it can take it's own dependence later on.

00:07:59.206 --> 00:08:03.414
And so that's precisely how we get
a word on the stack which has already

00:08:03.414 --> 00:08:06.350
been declared the dependent
of some other word.

00:08:07.780 --> 00:08:14.000
Okay, then it's the fact that we do that
necessitates this extra reduce operation.

00:08:14.000 --> 00:08:19.110
Plus, once we've then found all
the dependents of that word, we have

00:08:19.110 --> 00:08:25.390
to eventually get rid, of that so we can
go back to finding the pins of other words

00:08:25.390 --> 00:08:29.940
that are higher up the syntax tree and
that's what this reduce operation does.

00:08:29.940 --> 00:08:32.930
And the reduce operation
also has a precondition and

00:08:32.930 --> 00:08:36.370
its precondition is,
you can only get rid of a word

00:08:36.370 --> 00:08:40.290
from the stack if it has been made
the dependent of some other word.

00:08:40.290 --> 00:08:45.690
So in other words, if it was
introduced in this way as the dependent

00:08:45.690 --> 00:08:51.180
of some other word, then at some later
point you can reduce it once it's closed.

00:08:52.350 --> 00:08:56.160
That's all a bit confusing,
let's go through a concrete example and

00:08:56.160 --> 00:08:57.870
I think it'll make a lot more sense.

00:08:58.980 --> 00:09:01.700
Okay, so
the sentence I'm going to work with is,

00:09:01.700 --> 00:09:04.720
happy children like to
play with their friends.

00:09:04.720 --> 00:09:09.080
And here's the cheat sheet of
the operations that we're going to

00:09:09.080 --> 00:09:10.690
be able to perform.

00:09:10.690 --> 00:09:17.060
So starting off, we start off with here
is the stack with just this root symbol.

00:09:17.060 --> 00:09:21.450
The buffer has our sentence and
we found no dependencies.

00:09:21.450 --> 00:09:28.220
So in this situation, we have these
four operations we could apply.

00:09:28.220 --> 00:09:32.645
So, if we thought that happy was
the head of the whole sentence we could

00:09:32.645 --> 00:09:37.370
immediately do a right-arc operation but
that doesn't seem right here.

00:09:37.370 --> 00:09:41.390
What we do is we shift it onto the stack.

00:09:41.390 --> 00:09:43.410
And then we're in this situation.

00:09:43.410 --> 00:09:47.080
Okay, well in this situation, we do have,

00:09:47.080 --> 00:09:52.360
the children is going to have
as it's dependent, happy.

00:09:52.360 --> 00:09:57.725
So, the next thing we want to do is
construct a dependency of that sort.

00:09:57.725 --> 00:10:01.928
And so, that means we're doing a left
arc operation, and in particular,

00:10:01.928 --> 00:10:05.805
we're introducing it as
an adjectival modifier dependant.

00:10:05.805 --> 00:10:08.685
So, when we do a left arc operation,

00:10:08.685 --> 00:10:12.085
we add to the set of
dependencies that we found.

00:10:12.085 --> 00:10:16.005
And then we get rid of the dependent
off our vowel stack, so

00:10:16.005 --> 00:10:17.535
it disappears right here.

00:10:19.170 --> 00:10:24.620
Ok, at this point, children isn't
the head of the sentence either so

00:10:24.620 --> 00:10:26.410
we do another shift operation.

00:10:26.410 --> 00:10:30.390
Well at this point, we're already
to do another left arch operation

00:10:30.390 --> 00:10:35.280
because children is the subject
of like and so we introduce

00:10:35.280 --> 00:10:39.830
this noun subject dependency and
add that to our set of dependencies.

00:10:39.830 --> 00:10:43.890
So, A2 is now a set of two
dependencies that we've already built.

00:10:45.690 --> 00:10:50.780
Okay, well at this point we've actually
found the head of the whole sentence.

00:10:50.780 --> 00:10:53.310
So, like is the head
of the whole sentence.

00:10:53.310 --> 00:10:59.350
So, that means we can connect it to
the root by doing a brighter cooperation.

00:10:59.350 --> 00:11:03.290
So, we now add the root dependency for
the whole sentence.

00:11:05.560 --> 00:11:09.830
And remember then for
the right arc operation, we haven't yet

00:11:09.830 --> 00:11:12.720
found the dependence of like on the right.

00:11:12.720 --> 00:11:15.620
And so therefore,
we're adding it into the stack

00:11:15.620 --> 00:11:19.730
as something that still has to find
its own dependence on the right.

00:11:19.730 --> 00:11:23.485
And indeed at this point we're going
to be able to start to do that.

00:11:23.485 --> 00:11:28.120
because play is going to
be a dependent of like.

00:11:28.120 --> 00:11:30.190
First of all, we have to get past to.

00:11:31.342 --> 00:11:35.640
So, for to,
we shift to onto the stack and then to,

00:11:35.640 --> 00:11:40.670
the infinitive marker, is going to
be a dependent of the verb play.

00:11:40.670 --> 00:11:44.730
That's going to be another left
attach as an auxiliary modifier.

00:11:46.230 --> 00:11:51.580
Okay, this point, we can say that like and

00:11:51.580 --> 00:11:55.950
take it's first right
dependant like to play and so

00:11:55.950 --> 00:12:01.240
that's done as a right attachment and so
it's getting that right attach x column.

00:12:01.240 --> 00:12:04.570
Which is again adding in
to our set of dependencies.

00:12:07.110 --> 00:12:07.730
Okay.

00:12:07.730 --> 00:12:12.090
So at that point then, we're making
progress, but we've still got more to do.

00:12:12.090 --> 00:12:15.670
So, this is what we're up to so far.

00:12:15.670 --> 00:12:21.810
Play, and while play is also going
to take as its argument, play with.

00:12:22.840 --> 00:12:27.825
We can do another right attach of play and
with.

00:12:27.825 --> 00:12:32.840
And so that means,
again that with now moves onto

00:12:32.840 --> 00:12:38.380
the step that we've attached,
we've made this dependency of play with.

00:12:38.380 --> 00:12:42.810
But with hasn't found its arguments on
the right, so it's placed on the stack and

00:12:42.810 --> 00:12:46.040
then we're going to be able
to find its arguments.

00:12:46.040 --> 00:12:49.750
So, with argument is
going to be to friends.

00:12:49.750 --> 00:12:53.973
So, before we can get to that,
we have to shift on their and

00:12:53.973 --> 00:12:58.730
then we can introduce their as
a left arc of friends and attach it.

00:12:58.730 --> 00:13:03.665
And remember formally that to apply
this left arc rule each time we

00:13:03.665 --> 00:13:08.602
have to check the precondition and
the precondition is that their

00:13:08.602 --> 00:13:12.475
hasn't been made the dependent
of any other word.

00:13:12.475 --> 00:13:16.270
And it hadn't been so
that precondition is satisfied.

00:13:17.930 --> 00:13:23.400
Okay, now we can do another right arc
operation where we can hook together with

00:13:23.400 --> 00:13:25.920
and friends as the object
of the preposition.

00:13:27.360 --> 00:13:29.720
Okay, so we're making good progress.

00:13:29.720 --> 00:13:35.450
So, at this point we've now got
things that we've finished with.

00:13:35.450 --> 00:13:40.300
Friends never had any, right,
doesn't have any right dependents at all.

00:13:40.300 --> 00:13:43.900
With, we found that's only right
dependent that was friends.

00:13:43.900 --> 00:13:48.070
Play, we found it's only right
dependent with their friends.

00:13:48.070 --> 00:13:51.710
And at this point, we have to
start using the reduce operation.

00:13:51.710 --> 00:13:54.680
So, we reduce off friends.

00:13:54.680 --> 00:13:58.460
And again, remember that had
a precondition, and the precondition was

00:13:58.460 --> 00:14:04.040
checking that friends is hooked in as a
dependent of something, and indeed it is.

00:14:04.040 --> 00:14:06.570
We can reduce again, to get rid of with.

00:14:06.570 --> 00:14:10.040
And we can reduce again,
to get rid of play.

00:14:10.040 --> 00:14:12.590
Okay.
At this point, we've now got just

00:14:12.590 --> 00:14:17.100
the period to deal with which we
say is dependent of the main verb.

00:14:17.100 --> 00:14:21.980
So, we can introduce that also
as a right attached operation.

00:14:21.980 --> 00:14:24.670
And so now, at this point,
the buffer is empty.

00:14:24.670 --> 00:14:29.490
And the way we define our finish state is,
as soon as the buffer is empty,

00:14:29.490 --> 00:14:30.780
we can stop.

00:14:30.780 --> 00:14:34.479
You could if you want to save,
jeez, can't we just sort of reduce,

00:14:34.479 --> 00:14:36.970
reduce to pop these things
of back to the root.

00:14:36.970 --> 00:14:40.135
Anyway, you could have define things
like that, it wouldn't do any harm.

00:14:40.135 --> 00:14:45.402
And actually it's unnecessary
because once your offer is empty,

00:14:45.402 --> 00:14:49.082
you can't construct anymore dependencies.

00:14:49.082 --> 00:14:52.662
Because each operation,
introduces a dependency,

00:14:52.662 --> 00:14:57.033
is taking one thing from the stack and
one thing from the buffer and

00:14:57.033 --> 00:14:59.974
that there's no way in
this formulation for

00:14:59.974 --> 00:15:04.766
things to reappear in the buffer once
they've been moved to the stack.

00:15:04.766 --> 00:15:09.350
So, we know that we'd done and
we found a complete set of dependencies

00:15:09.350 --> 00:15:13.233
which is you have to hear a kind
of work back up to my list, but

00:15:13.233 --> 00:15:16.829
you make a settable
dependencies we've introduced.

00:15:16.829 --> 00:15:21.430
Okay so that's the model
of how the parser operates

00:15:21.430 --> 00:15:25.520
as doing these operations step by step.

00:15:25.520 --> 00:15:29.270
But at each step there, there were
multiple things that could have been done.

00:15:29.270 --> 00:15:34.010
It could have chosen to shift what could
have chosen to make it left arc or

00:15:34.010 --> 00:15:35.010
a right arc.

00:15:35.010 --> 00:15:39.360
And if it chooses to make a left arc or a
right arc, it has to label the dependency

00:15:39.360 --> 00:15:43.010
that introduce us with one
of many dependency labels.

00:15:43.010 --> 00:15:44.420
So, how do you do that?

00:15:44.420 --> 00:15:48.590
Well the way that stands is by using
some form of discriminative classifier.

00:15:48.590 --> 00:15:52.752
Support vector machines, SVM's have
been most commonly used in practice, but

00:15:52.752 --> 00:15:56.793
it could equally be another kind of
discriminatory classifier such as a maxent

00:15:56.793 --> 00:15:57.542
classifier.

00:15:57.542 --> 00:16:01.768
And so these classifiers
are choosing from a set of moves.

00:16:01.768 --> 00:16:07.551
So, if it's an untyped dependency parser
Four moves that [INAUDIBLE] configuration,

00:16:07.551 --> 00:16:11.905
but if it's typed, then there
are twice the number of dependency

00:16:11.905 --> 00:16:14.460
types plus 2 parsers to choose from.

00:16:14.460 --> 00:16:17.910
It's a finite set of parsers
you're choosing from.

00:16:17.910 --> 00:16:20.690
So what are the features that you
use in the dependency parser?

00:16:20.690 --> 00:16:23.890
Well, you definitely use What's
the word on top of the stack?

00:16:23.890 --> 00:16:25.180
What's its part of speech?

00:16:25.180 --> 00:16:26.820
What's the first word int he buffer?

00:16:26.820 --> 00:16:28.550
What's its part of speech?

00:16:28.550 --> 00:16:31.570
That will let you choose
operations like shifting or

00:16:31.570 --> 00:16:34.110
the kind of dependency label to choose.

00:16:34.110 --> 00:16:37.200
But those aren't the only operations
in good dependency pauses,

00:16:37.200 --> 00:16:40.460
because remember we had
other things that we

00:16:40.460 --> 00:16:44.020
knew could be important like
the length of the dependency arc.

00:16:44.020 --> 00:16:49.150
That's being proposed or
knowing what's intervening between them.

00:16:49.150 --> 00:16:52.760
And also, you might want to
know [INAUDIBLE] about for

00:16:52.760 --> 00:16:57.468
these words that are at
the top of the stack.

00:16:57.468 --> 00:17:02.930
Well, what tendence do they
already have that will

00:17:02.930 --> 00:17:07.680
influence how likely you are to
get other dependencies for them.

00:17:07.680 --> 00:17:11.810
So you can put all of these things as
features into a discriminative classifier,

00:17:11.810 --> 00:17:15.890
kind of like we saw when looking
at max end classifiers before.

00:17:17.320 --> 00:17:22.540
So in the simplest form of
transition-based dependency parser,

00:17:22.540 --> 00:17:29.500
there is hence absolutely no search
whatsoever that at each point you're

00:17:29.500 --> 00:17:34.730
making a greedy decision, that you've
got the stack and buffer in some state.

00:17:34.730 --> 00:17:36.420
You run a classifier.

00:17:36.420 --> 00:17:40.578
It decides the most likely next action and
you just take it.

00:17:40.578 --> 00:17:44.674
And that's been an approach
that's been strongly pursued in

00:17:44.674 --> 00:17:49.396
the MaltParser framework to see how
can a job you can do in this manner by

00:17:49.396 --> 00:17:54.223
having really good classifiers that
are good at choosing the next move.

00:17:54.223 --> 00:17:56.240
I mean,
of course you don't have to do that.

00:17:56.240 --> 00:18:01.130
You could do some kind of beam search
to explore different possibilities.

00:18:01.130 --> 00:18:05.710
But the rather stunning result is that
you can do this form of completely

00:18:05.710 --> 00:18:10.010
greedy transition based parsing and
do really well.

00:18:10.010 --> 00:18:14.480
You can build dependency parsers
that work almost as well

00:18:14.480 --> 00:18:17.855
as the best lexicalized
probabilistic context free grammars.

00:18:17.855 --> 00:18:22.160
I'm doing the kind of
complete CKY parsing style

00:18:22.160 --> 00:18:26.880
search of all possibilities that we
saw previously where we're taking it.

00:18:26.880 --> 00:18:29.950
And we're converting the LPCFGs

00:18:29.950 --> 00:18:33.060
into dependency representations
to evaluate them.

00:18:33.060 --> 00:18:35.749
I'll say a bit more of about
evaluation in a moment.

00:18:37.310 --> 00:18:42.850
Well, if it was just that they were
close to the state of the art that would

00:18:42.850 --> 00:18:49.240
be good, but the dramatic reason why
people really like these parses.

00:18:49.240 --> 00:18:53.570
And they've become extremely widely used,
is that because they're these

00:18:53.570 --> 00:18:58.150
greedy transition based parses
that they're super, super fast.

00:18:58.150 --> 00:19:03.410
So this style of pauses and work way,
way faster than any kind of dynamic

00:19:03.410 --> 00:19:08.230
program parser [INAUDIBLE] to shooing
every possible alternative analysis.

00:19:10.380 --> 00:19:12.738
How do we evaluate dependency parser?

00:19:12.738 --> 00:19:16.133
The standard way to do
that is just by accuracy.

00:19:16.133 --> 00:19:22.162
The sense for each word,
we going to choose something as its ahead.

00:19:22.162 --> 00:19:26.715
We can just say, how many those
decisions that did we get right.

00:19:26.715 --> 00:19:28.618
Let's look at an example of that.

00:19:28.618 --> 00:19:31.939
So here's the simple
sentence we're going to use.

00:19:31.939 --> 00:19:34.270
She saw the video lecture.

00:19:34.270 --> 00:19:41.230
So commonly,
we'll number each word of the sentence

00:19:41.230 --> 00:19:46.850
including giving a number of zero to
this root that we add to the same tense.

00:19:46.850 --> 00:19:50.900
So in this analysis this is showing
you the correct dependencies and

00:19:50.900 --> 00:19:56.840
we can lengthen out the chart
where we have for each word.

00:19:56.840 --> 00:19:59.570
We have its own word number and

00:19:59.570 --> 00:20:05.230
then we say which word index
is the head of that word.

00:20:05.230 --> 00:20:09.090
And in particular for the word that's
the head of the whole sentence saw We're

00:20:09.090 --> 00:20:14.280
saying the word of index of it's governor
is zero, which is this root symbol.

00:20:15.590 --> 00:20:19.980
And then additionally if we want to we
can also label the dependencies and

00:20:19.980 --> 00:20:21.960
that happens over here.

00:20:21.960 --> 00:20:27.350
Okay, so then we build a parser such as
a transition-based dependency parse are.

00:20:27.350 --> 00:20:31.760
And the parse are traced to parse
the sentence and it gets some results.

00:20:31.760 --> 00:20:34.980
And if you look over here,
it starts off well.

00:20:34.980 --> 00:20:39.370
It says that saw is
the root of this sentence.

00:20:39.370 --> 00:20:41.990
And that she is the subject of saw,

00:20:41.990 --> 00:20:44.560
it actually makes a bit
of a boo boo after that.

00:20:44.560 --> 00:20:51.535
It says that she saw something lecturing.

00:20:51.535 --> 00:20:56.920
Saw has as its dependent
lecture as a verb,

00:20:56.920 --> 00:21:01.690
and the video is being analyzed as
the subject of the verb lecture.

00:21:03.030 --> 00:21:06.170
Well, if we do that and
evaluate accuracy, how does it work out?

00:21:06.170 --> 00:21:09.876
So for accuracy, we're taking
the number of correct dependencies

00:21:09.876 --> 00:21:12.087
over the total number of dependencies.

00:21:12.087 --> 00:21:14.112
And there are two ways we can do that.

00:21:14.112 --> 00:21:19.059
One is ignoring the labels for
the grammatic relations, so

00:21:19.059 --> 00:21:24.116
that standardly gets referred to
as un labeled attachments score.

00:21:24.116 --> 00:21:26.392
And so if you look at that
well doing pretty well,

00:21:26.392 --> 00:21:28.832
so this one is correct,this
one is correct.

00:21:28.832 --> 00:21:33.224
This one is correct, this one is correct

00:21:35.176 --> 00:21:39.812
and so
the only place were different Word is

00:21:39.812 --> 00:21:44.705
chosen as the governor for
a word is right here.

00:21:44.705 --> 00:21:50.220
So here what it should be is that
the is a dependent of lecture,

00:21:50.220 --> 00:21:52.765
but in this wrong analysis.

00:21:52.765 --> 00:21:56.280
We say that the is a dependent of video.

00:21:58.090 --> 00:22:01.530
However, if we look at
the labeled accuracy score,

00:22:01.530 --> 00:22:04.710
this wrong parse isn't doing so well.

00:22:04.710 --> 00:22:09.070
So it gets this one right, and

00:22:09.070 --> 00:22:12.690
then gets this one right, but
everything else it gets wrong.

00:22:12.690 --> 00:22:15.290
It gets them wrong for two reasons.

00:22:15.290 --> 00:22:23.210
So, for the case of the, it chooses the
wrong word to be have the sit governor,

00:22:23.210 --> 00:22:28.340
but for video and lecture, although it
chooses the right word to be the governor.

00:22:28.340 --> 00:22:32.300
It chooses the wrong function.

00:22:32.300 --> 00:22:35.134
So because it's taking the lecture,

00:22:35.134 --> 00:22:39.712
lecture is a verb that is
a compliment clause of c.

00:22:39.712 --> 00:22:44.181
That's wrong because it should
be a direct object, and

00:22:44.181 --> 00:22:51.498
then it's analyzing video as the subject
of lecture and that's wrong as well.

00:22:51.498 --> 00:22:55.270
Really we should have this compound
noun structure here and so

00:22:55.270 --> 00:23:00.590
we only gain two out of five right or 40%.

00:23:00.590 --> 00:23:05.064
Here are a couple of numbers just to give
your sense of how well people do with

00:23:05.064 --> 00:23:06.424
dependency parsers.

00:23:06.424 --> 00:23:10.310
So if you want to look more at
dependency parse evaluation,

00:23:10.310 --> 00:23:14.672
one good source of information
was that in the CoNLL conference,

00:23:14.672 --> 00:23:19.525
the conference on natural language
learning that was held in 2006.

00:23:19.525 --> 00:23:24.817
The shared task that was used was to
do dependency parsing over a collection

00:23:24.817 --> 00:23:29.689
of 13 different languages and
many dependency parsers took part.

00:23:29.689 --> 00:23:31.371
And you can see scores.

00:23:31.371 --> 00:23:35.745
So if you look at the result for
MALT parser in that competition,

00:23:35.745 --> 00:23:40.362
which was evaluated primarily
through this label attachment score.

00:23:40.362 --> 00:23:44.898
The scores range from for
the best languages it got about 92% of

00:23:44.898 --> 00:23:50.569
the dependencies right, and for the worst
languages, it got about 65% right.

00:23:50.569 --> 00:23:56.446
It was a huge range, so some languages I
think are intrinsically harder than other.

00:23:56.446 --> 00:24:00.516
But I think there are also issues that the
quality of some of the treebanks is much

00:24:00.516 --> 00:24:03.760
better than others and
that's also reflected in the numbers.

00:24:03.760 --> 00:24:07.379
Just trying to connect up
with what we saw earlier for

00:24:07.379 --> 00:24:12.710
constituency parsing, let me also
give a few numbers from English.

00:24:12.710 --> 00:24:17.620
So these are all dependency numbers, but
this time we're looking at unlabeled

00:24:17.620 --> 00:24:23.250
attachment score since we can always
get unlabeled attachments from

00:24:23.250 --> 00:24:28.870
a constituency parser that has a notion of
heads where it won't be producing labels.

00:24:29.870 --> 00:24:34.940
So if we convert the output of the
Charniak and Collins models of generative

00:24:36.110 --> 00:24:40.390
constituency parsing,
both lexicalized PCFG parsers,

00:24:40.390 --> 00:24:46.690
that their accuracy on
dependencies untyped is about 92%.

00:24:46.690 --> 00:24:52.486
So Yamada and Matsumoto's parser is
another transition-based parser,

00:24:52.486 --> 00:24:59.115
kind of like the MaltParser, and so it
does a bit worse than that, about 90.4%.

00:24:59.115 --> 00:25:01.971
Here's a different style
of dependency parser.

00:25:01.971 --> 00:25:06.255
This is the minimum spanning tree
graph-based style dependency parser.

00:25:06.255 --> 00:25:10.654
It did 91.5%, almost,
almost as well as these.

00:25:10.654 --> 00:25:14.015
But part people have gone on
doing research on this, and

00:25:14.015 --> 00:25:18.237
partly because dependency parsers
are often much simpler, there's

00:25:18.237 --> 00:25:22.761
been quite a lot of work in looking at
combinations of dependency parsers.

00:25:22.761 --> 00:25:27.702
And so for example, here's one
dependency parser from 2006 where it's

00:25:27.702 --> 00:25:32.809
then getting results that are a little
bit above the two constituency parsers.

00:25:32.809 --> 00:25:35.874
Now all of these results
are even a few years out of date.

00:25:35.874 --> 00:25:39.952
There hasn't been a recent careful
comparison of constituency and

00:25:39.952 --> 00:25:41.318
dependency parsers.

00:25:41.318 --> 00:25:45.985
But I think big picture what you
should take away is that greedy

00:25:45.985 --> 00:25:51.015
transition-based dependency
parsers by themselves are perhaps

00:25:51.015 --> 00:25:56.599
a little bit worse in performance
than dynamic programmed PCFG parsers.

00:25:56.599 --> 00:25:58.733
But if so,
it's only a very little bit, and

00:25:58.733 --> 00:26:03.149
their other performance characteristics
make them extremely, extremely attractive.

00:26:05.380 --> 00:26:10.594
Before finishing this presentation of
dependency parsing techniques, there's

00:26:10.594 --> 00:26:15.291
just one more issue I should mention,
which is the issue of projectivity.

00:26:15.291 --> 00:26:20.570
So if you take dependencies
from a CFG tree using heads,

00:26:20.570 --> 00:26:23.990
you have to get a projective
dependency parse.

00:26:23.990 --> 00:26:28.891
And what that means is that your
dependencies can be regarded as something

00:26:28.891 --> 00:26:34.188
in which everything nests together,
just like constituency nests together,

00:26:34.188 --> 00:26:37.523
without there being any
crossing dependencies.

00:26:37.523 --> 00:26:41.682
But most theories of dependency
grammar allow crossing

00:26:41.682 --> 00:26:45.570
dependency as a non-projective structures.

00:26:45.570 --> 00:26:49.730
And indeed, you can't get the semantics
of certain constructions right

00:26:49.730 --> 00:26:52.290
without these non-projective dependencies.

00:26:52.290 --> 00:26:53.780
So let's look at an example of that.

00:26:53.780 --> 00:26:58.420
So here's this sentence, Who did
Bill buy the coffee from yesterday?

00:26:58.420 --> 00:27:04.858
So most of the dependencies nest together
giving us a kind of tree structure.

00:27:04.858 --> 00:27:09.370
But if we then want to hook up who,
then what we want to say is,

00:27:09.370 --> 00:27:14.220
well, who is the object of
this preposition here, from.

00:27:14.220 --> 00:27:16.982
And so if we put in its dependency,

00:27:16.982 --> 00:27:21.845
this dependency has to cross
these two other dependencies,

00:27:21.845 --> 00:27:26.435
and so this is a non-projective
dependency structure.

00:27:26.435 --> 00:27:30.517
And so the question then is
how do we handle this kind of

00:27:30.517 --> 00:27:33.714
non-projectivity in parsing methods?

00:27:33.714 --> 00:27:38.012
In particular,
the transition-based arc-eager algorithm

00:27:38.012 --> 00:27:41.856
I presented only builds
projective dependency trees.

00:27:41.856 --> 00:27:45.526
And so this has been an active area
of investigation in the dependency

00:27:45.526 --> 00:27:46.305
literature.

00:27:46.305 --> 00:27:48.717
I'm not going to cover it in detail here,
but

00:27:48.717 --> 00:27:54.270
I'll just briefly mention the range of
possible analyses that have been pursued.

00:27:54.270 --> 00:27:58.437
So one possibility is just to declare
defeat on non-projective arcs.

00:27:58.437 --> 00:28:02.810
For languages like English,
there are quite few non-projective arcs,

00:28:02.810 --> 00:28:07.604
basically for the same reason that context
free grammars work well for English,

00:28:07.604 --> 00:28:10.820
because by and
large everything is tree structured.

00:28:10.820 --> 00:28:18.123
You can work at getting almost everything
right with a non-projective parser.

00:28:18.123 --> 00:28:22.728
A second possibility is to use
a dependency formalism which only has

00:28:22.728 --> 00:28:24.924
projective representations.

00:28:24.924 --> 00:28:27.244
You'll see one of those
in the next segment.

00:28:27.244 --> 00:28:32.371
And that's kind of analogous to what
context-free grammars actually represent,

00:28:32.371 --> 00:28:37.138
because a context-free grammar also
doesn't represent any connections between

00:28:37.138 --> 00:28:40.259
words that can't be done
inside a tree structure.

00:28:40.259 --> 00:28:44.572
And so effectively in something like
the tree bank representations we saw for

00:28:44.572 --> 00:28:49.417
phase structure grammar, they just fail to
represent connections between words that

00:28:49.417 --> 00:28:51.694
aren't within a tree representation.

00:28:51.694 --> 00:28:55.650
They just hook the word in somewhere
higher up in the structure.

00:28:55.650 --> 00:28:58.760
But there are other methods
that people have pursued.

00:28:58.760 --> 00:29:04.710
A third method people have used
is to do projective parsing and

00:29:04.710 --> 00:29:10.050
then run some kind of postprocessor
that perhaps picks up on classes

00:29:10.050 --> 00:29:15.100
of labels which indicate we're
hooking this onto our analysis but

00:29:15.100 --> 00:29:17.100
really it should be moved somewhere else.

00:29:17.100 --> 00:29:20.209
And then to work out how to
resolve the non-projective links.

00:29:21.570 --> 00:29:24.600
Well, something else you can
do is you can actually add

00:29:24.600 --> 00:29:29.640
extra operations to the transition-based
dependency parser model

00:29:29.640 --> 00:29:33.640
that can handle at least the common
cases of non-projectivity, that is,

00:29:33.640 --> 00:29:38.750
things like question words being moved
to the front of the sentence in English.

00:29:38.750 --> 00:29:39.830
Or finally,

00:29:39.830 --> 00:29:46.040
you can move to a parsing method which
just doesn't assume projectivity.

00:29:46.040 --> 00:29:49.828
So in particular,
the minimum spanning tree-based,

00:29:49.828 --> 00:29:55.149
graph-based parsing methods don't
make any assumptions of projectivity,

00:29:55.149 --> 00:29:59.420
and you can directly build
non-projective structures.

00:29:59.420 --> 00:30:01.785
So in a way this is appealing, but

00:30:01.785 --> 00:30:06.771
in a way it seems like it's possibly
going to a too general situation,

00:30:06.771 --> 00:30:11.759
because you're going from the situation
of only allowing projective

00:30:11.759 --> 00:30:17.250
structures to making no special
requirement of projective structures.

00:30:17.250 --> 00:30:22.060
And if you look at natural languages, what
you find is that they're mostly projective

00:30:22.060 --> 00:30:26.870
and there are only particular
constructions like things like WH movement

00:30:26.870 --> 00:30:31.528
that moves question words to the beginning
of a sentence or various kinds of right

00:30:31.528 --> 00:30:36.250
displacements, like afterthoughts,
that create non-projectivity.

00:30:36.250 --> 00:30:40.390
So in the MSTParser,
all of that when you should and

00:30:40.390 --> 00:30:44.902
shouldn't have non-projectivity
is in the space of the machine

00:30:44.902 --> 00:30:49.800
learning classifier of deciding which
dependencies are likely to construct.

00:30:51.430 --> 00:30:55.250
Okay, I hope that's given you a concrete
sense of how transition-based

00:30:55.250 --> 00:30:58.310
dependency parsers are implemented and

00:30:58.310 --> 00:31:03.140
so maybe you feel like you could
go off and implement one of those.

