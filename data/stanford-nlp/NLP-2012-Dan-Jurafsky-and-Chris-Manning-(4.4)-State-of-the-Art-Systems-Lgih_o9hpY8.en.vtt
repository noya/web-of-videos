WEBVTT
Kind: captions
Language: en

00:00:01.340 --> 00:00:04.030
There are few more issues that come up
in spelling correction that we want to

00:00:04.030 --> 00:00:05.850
include in any kind of
state-of-the-art system.

00:00:07.960 --> 00:00:11.350
One is HCI issues,
Human-Computer Interaction issues.

00:00:11.350 --> 00:00:15.830
So if we're very confident in correction
for example, we might want to autocorrect.

00:00:15.830 --> 00:00:21.200
And so, that happens very often as I
talked about earlier Wiwth the example hte

00:00:21.200 --> 00:00:23.100
which is the the common
misspelling of the.

00:00:23.100 --> 00:00:28.378
And for slightly less confident,
we might want to give a single best

00:00:28.378 --> 00:00:34.160
correction at,
to the user to say yes or no too.

00:00:34.160 --> 00:00:38.140
And if even less confident,
we might want to give our whole list and

00:00:38.140 --> 00:00:39.930
want to pick in this list.

00:00:39.930 --> 00:00:42.840
And if we're just unconfident at all, but

00:00:42.840 --> 00:00:45.950
we're pretty sure we saw an error,
we just don't know how to fix it,

00:00:45.950 --> 00:00:49.600
then we might just flag what does
the user type doesn't error.

00:00:49.600 --> 00:00:52.255
So various things again depending
on our application, and

00:00:52.255 --> 00:00:55.823
depending on the probability and the
confidence value that we might generate.

00:00:58.790 --> 00:01:01.480
In practice, for
almost all noisy channel models.

00:01:03.140 --> 00:01:07.310
Even though we've defined the model
as multiplying a prior and

00:01:07.310 --> 00:01:09.810
a likelihood, and an error model.

00:01:09.810 --> 00:01:13.950
In practice these two probabilities
are computed from making a lot of

00:01:13.950 --> 00:01:17.860
different independence assumptions
about how many errors there were.

00:01:17.860 --> 00:01:20.310
And the fact that the spelling is
independent of neighboring words and

00:01:20.310 --> 00:01:21.690
these are really not true.

00:01:21.690 --> 00:01:25.340
And the result of these incorrect
independence assumptions

00:01:25.340 --> 00:01:28.300
means that these two probabilities
are often not commensurate.

00:01:28.300 --> 00:01:34.000
So we do in fact, instead of just
multiplying these two we weight them and

00:01:34.000 --> 00:01:36.710
the way, since we're multiplying
probabilities we weight them.

00:01:36.710 --> 00:01:38.300
By raising one of them to a power,

00:01:38.300 --> 00:01:40.990
we can't obviously multiply
one of them by something.

00:01:40.990 --> 00:01:43.900
So we weight them by raising one
of them to the power lambda and

00:01:43.900 --> 00:01:46.620
we learn this lambda from
some development test set.

00:01:46.620 --> 00:01:51.560
We pick whatever lambda to raise
the language [INAUDIBLE] probability to

00:01:51.560 --> 00:01:55.080
such that the product is
more likely to pick out

00:01:55.080 --> 00:01:57.490
just those errors that really are errors.

00:01:57.490 --> 00:02:01.400
And we use this weighting
of the noisy channel model

00:02:01.400 --> 00:02:04.120
in almost any application that we
see of the noisy channel model.

00:02:05.530 --> 00:02:09.270
Something else that's used in the state
of the art systems, is to use not just

00:02:09.270 --> 00:02:13.150
the spelling, but the pronunciation
of the word to help us find errors.

00:02:13.150 --> 00:02:17.190
So the metaphone system
which is used in GNU aspell.

00:02:18.470 --> 00:02:24.260
Instead of just asking for
candidates that have a similar spelling,

00:02:24.260 --> 00:02:26.450
ask for candidates that have
a similar pronunciation.

00:02:26.450 --> 00:02:31.520
And that's done by first converting
the misspelling to a pronunciation and

00:02:31.520 --> 00:02:34.120
the metaphone is a simplified.

00:02:35.140 --> 00:02:36.470
Pronunciation system,

00:02:36.470 --> 00:02:41.460
a set of rules that convert a word into
something approximating a pronunciation.

00:02:41.460 --> 00:02:44.910
And here's the kind of rules that get
used, drop duplicate adjacent letters

00:02:44.910 --> 00:02:49.930
except for c, if the word begins with
kn or gn drop that first letter.

00:02:51.020 --> 00:02:54.570
Drop B if it's after M and
if it's at the end of the word and so

00:02:54.570 --> 00:02:57.230
on so
these are dropping various silent letters.

00:02:57.230 --> 00:03:02.410
And various rules like this convert

00:03:02.410 --> 00:03:07.060
the misspelling into a kind of
representation of the pronunciation,

00:03:07.060 --> 00:03:09.960
has a single vowel at the beginning and
then a set of consonants.

00:03:09.960 --> 00:03:14.450
And then we find whose words
pronunciations is nearby the misspellings

00:03:14.450 --> 00:03:18.960
pronunciations we've converted all other
words into the Metaphone pronunciations,

00:03:18.960 --> 00:03:20.520
find similar words.

00:03:20.520 --> 00:03:26.790
And now, we score the words by some
combination of two edit distances.

00:03:26.790 --> 00:03:32.680
How likely is the candidate to be
orthographically changing the misspelling,

00:03:32.680 --> 00:03:34.680
so they'll use some kind of
channel model like thing.

00:03:34.680 --> 00:03:36.670
And the same thing with the pronunciation.

00:03:36.670 --> 00:03:40.090
How likely is the misspelling to
be pronounced like the candidate?

00:03:41.270 --> 00:03:44.690
So a metaphone system
doesn't use a language model

00:03:44.690 --> 00:03:49.260
By use of pronunciation based kind of
channel model, and you can imagine

00:03:49.260 --> 00:03:53.760
also combining a pronunciation based
model with a noisy channel model.

00:03:53.760 --> 00:03:58.290
Again, modern models of
the channel in the last decade or

00:03:58.290 --> 00:04:01.510
so allow a number of kind of
improvements like this so

00:04:01.510 --> 00:04:04.950
incorporating a pronunciation component
into the channel model is one.

00:04:04.950 --> 00:04:09.780
And we might also want to allow richer
edits, so not just single letter edits,

00:04:09.780 --> 00:04:14.990
but kind of edits like a ph
being incorrectly typed as an f.

00:04:14.990 --> 00:04:19.870
Or very common error it's not that all
e's are mistakenly typed as a's, but

00:04:19.870 --> 00:04:23.120
that the sequence e n t is very
likely to be mistyped as a n t.

00:04:24.140 --> 00:04:28.010
So couple different improvements that
a state of the art system might have

00:04:28.010 --> 00:04:28.930
in the channel model.

00:04:30.210 --> 00:04:34.340
And in fact, we consider a very large
number of factors that could influence

00:04:34.340 --> 00:04:37.120
the probability of a misspelling
giving the word the channel model.

00:04:37.120 --> 00:04:40.530
So we've talked about the source letter or
the target letter, and we've talked about

00:04:40.530 --> 00:04:43.360
maybe one surrounding letter, but
we can look at more surrounding letters.

00:04:43.360 --> 00:04:45.250
Or we can look at the position the word.

00:04:45.250 --> 00:04:47.600
Maybe some errors happen
in the middle of the word.

00:04:47.600 --> 00:04:50.530
Some happen at the end.

00:04:50.530 --> 00:04:52.980
We might explicitly model the keyboard and

00:04:52.980 --> 00:04:56.660
talk about nearby keys on the keyboard or
homology.

00:04:56.660 --> 00:05:00.690
We're likely to mistype
a word with our left hand.

00:05:00.690 --> 00:05:03.250
Third finger by using our
right hand third finger,

00:05:03.250 --> 00:05:08.340
so a key which on the same finger on
the alternate hand is homologous.

00:05:08.340 --> 00:05:11.280
Or again, we might use pronunciations,
we might use these

00:05:11.280 --> 00:05:15.220
likely morpheme transformations that
we talked about on the last slide.

00:05:15.220 --> 00:05:18.750
Lots of possible factors that could
influence this channel model.

00:05:19.900 --> 00:05:22.200
There's a picture of one of them,
the keyboard, so again,

00:05:22.200 --> 00:05:27.580
we might want to say that R and
W are likely

00:05:27.580 --> 00:05:32.040
mistypings for E, and so on if we're
on some kind of a thumb keyboard.

00:05:34.230 --> 00:05:37.550
So combining all these
different factors is often done

00:05:37.550 --> 00:05:39.670
with a classifier base model.

00:05:39.670 --> 00:05:42.820
So the classifier base
model is an alternative way

00:05:42.820 --> 00:05:44.550
of doing real word spelling correction.

00:05:44.550 --> 00:05:48.640
And here instead of just two models,
a channel model and

00:05:48.640 --> 00:05:52.540
a language model you might take those
two and a number of other models, and

00:05:52.540 --> 00:05:53.880
combine them in a big classifier.

00:05:53.880 --> 00:05:58.060
Wel, l talk about classifiers
in the next lecture.

00:05:59.710 --> 00:06:02.690
So for example if we had
a specific pair like whether and

00:06:02.690 --> 00:06:04.984
weather commonly confused.

00:06:04.984 --> 00:06:09.670
The real-word confusions,
we might look at features like,

00:06:09.670 --> 00:06:14.270
well, is the word cloudy
in a window of +- 10 words,

00:06:14.270 --> 00:06:19.590
or am I followed by the word to and
then some verb?

00:06:19.590 --> 00:06:24.470
So if the word cloudy is nearby me,
I'm probably the word weather.

00:06:24.470 --> 00:06:29.890
If I'm followed by two VERB,
I'm probably the word whether.

00:06:29.890 --> 00:06:34.370
So, whether to go, whether to say,
whether to do is probably this whether.

00:06:35.760 --> 00:06:39.950
Similarly, if I'm followed by or
not, then I'm probably this whether.

00:06:39.950 --> 00:06:44.270
So each of these features Plus
the language model, plus the channel model

00:06:44.270 --> 00:06:47.210
could be combined into one classifier
that could make a decision.

00:06:47.210 --> 00:06:51.450
And we might build separate classifiers
for each possible likely pair of words.

00:06:51.450 --> 00:06:55.830
So in summary real word spelling
correction can be done with the same noisy

00:06:55.830 --> 00:06:59.910
channel algorithm that used for
non-word spelling correction.

00:06:59.910 --> 00:07:03.350
But we can also use a classifier
based approach where

00:07:03.350 --> 00:07:05.200
we combine a lot of features and

00:07:05.200 --> 00:07:09.410
build classifiers for very frequent kinds
of errors we like to model explicitly.

