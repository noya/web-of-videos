WEBVTT
Kind: captions
Language: en

00:00:00.131 --> 00:00:04.937
[MUSIC]

00:00:04.937 --> 00:00:09.746
Stanford University.

00:00:09.746 --> 00:00:11.463
&gt;&gt; Okay everyone.

00:00:11.463 --> 00:00:12.707
We're ready.

00:00:12.707 --> 00:00:20.231
Okay well welcome to
CS224N in Linguistics 284.

00:00:20.231 --> 00:00:22.155
This is kind of amazing.

00:00:22.155 --> 00:00:27.350
Thank you for everyone who's here that's
involved and also the people who don't fit

00:00:27.350 --> 00:00:32.320
in here and the people who
are seeing it online on SCPD.

00:00:32.320 --> 00:00:37.730
Yeah it's totally amazing the number of
people who've signed up to do this class

00:00:37.730 --> 00:00:42.820
and so in some sense it seems like
you don't need any advertisements for

00:00:42.820 --> 00:00:45.650
why the combination of
natural language process and

00:00:45.650 --> 00:00:48.040
deep learning is a good
thing to learn about.

00:00:48.040 --> 00:00:53.240
But nonetheless today,
this class is really going

00:00:53.240 --> 00:00:57.020
to give some of that advertisement,
so I'm Christopher Manning.

00:00:57.020 --> 00:01:02.170
So what we're gonna do is I'm
gonna start off by saying

00:01:02.170 --> 00:01:07.050
a bit of stuff about what natural language
processing is and what deep learning is,

00:01:07.050 --> 00:01:12.390
and then after that we'll spend a few
minutes on the course logistics.

00:01:12.390 --> 00:01:16.240
And a word from my co-instructor, Richard.

00:01:16.240 --> 00:01:20.650
And then, get through some more
material on why is language

00:01:20.650 --> 00:01:25.720
understanding difficult, and then starting
to do an intro to deep learning for NLP.

00:01:26.780 --> 00:01:29.305
So we've gotten off to
a rocky start today,

00:01:29.305 --> 00:01:34.770
cause I guess we started about ten minutes
late because of that fire alarm going off.

00:01:34.770 --> 00:01:39.590
Fortunately, there's actually not a lot
of hard content in this first lecture.

00:01:39.590 --> 00:01:44.040
This first lecture is really to
explain what an NLP class is and say

00:01:44.040 --> 00:01:48.920
some motivational content about how and
why deep learning is changing the world.

00:01:48.920 --> 00:01:53.190
That's going to change immediately
on the Thursday lecture because for

00:01:53.190 --> 00:01:57.150
the Thursday lecture is then we're
gonna start with sort of vectors and

00:01:57.150 --> 00:02:00.310
derivatives and chain rules and
all of that stuff.

00:02:00.310 --> 00:02:02.750
So you should get mentally prepared for

00:02:02.750 --> 00:02:05.170
that change of level
between the two lectures.

00:02:06.680 --> 00:02:10.570
Okay, so first of all what is
natural language processing?

00:02:10.570 --> 00:02:15.140
So natural language processing, that's
the sort of computer scientist's name for

00:02:15.140 --> 00:02:16.090
the field.

00:02:16.090 --> 00:02:19.383
Essentially synonymous with
computational linguistics which is

00:02:19.383 --> 00:02:21.795
sort of the linguist's name of the field.

00:02:21.795 --> 00:02:26.235
And so it's in this intersection of
computer science and linguistics and

00:02:26.235 --> 00:02:27.955
artificial intelligence.

00:02:27.955 --> 00:02:31.915
Where what we're trying
to do is get computers to

00:02:31.915 --> 00:02:36.480
do clever things with human languages
to be able to understand and

00:02:36.480 --> 00:02:41.440
express themselves in human languages
the way that human beings do.

00:02:41.440 --> 00:02:46.330
So natural language processing counts
as a part of artificial intelligence.

00:02:46.330 --> 00:02:50.290
And there are obviously other important
parts of artificial intelligence,

00:02:50.290 --> 00:02:52.500
of doing computer vision, and robotics,

00:02:52.500 --> 00:02:55.610
and knowledge representation,
reasoning and so on.

00:02:55.610 --> 00:03:02.280
But language has had a very special
part of artificial intelligence,

00:03:02.280 --> 00:03:07.350
and that's because that language has
been this very distinctive properties of

00:03:07.350 --> 00:03:12.610
human beings, and we think and go about
the world largely in terms of language.

00:03:12.610 --> 00:03:17.397
So lots of creatures around the planet
have pretty good vision systems,

00:03:17.397 --> 00:03:20.147
but human beings are alone for language.

00:03:20.147 --> 00:03:24.179
And when we think about how we express
our ideas and go about doing things that

00:03:24.179 --> 00:03:28.158
language is largely our tool for
thinking and our tool for communication.

00:03:28.158 --> 00:03:31.221
So it's been one of the key
technologies that people have thought

00:03:31.221 --> 00:03:35.720
about in artificial intelligence and it's
the one that we're going to look at today.

00:03:35.720 --> 00:03:39.378
So our goal is how can we
get computers to process or

00:03:39.378 --> 00:03:44.621
understand human languages in order
to perform tasks that are useful.

00:03:44.621 --> 00:03:49.258
So that could be things like making
appointments, or buying things, or

00:03:49.258 --> 00:03:54.746
it could be more highfalutin goals of sort
of, understanding the state of the world.

00:03:54.746 --> 00:04:00.106
And so this is a space in which there's
starting to be a huge amount of commercial

00:04:00.106 --> 00:04:05.310
activity in various directions,
some of things like making appointments.

00:04:05.310 --> 00:04:07.780
A lot of it in the direction
of question answering.

00:04:07.780 --> 00:04:14.870
So, luckily for people who do language,
the arrival of mobile has just been super,

00:04:14.870 --> 00:04:20.170
super friendly in terms of the importance
of language has gone way way higher.

00:04:20.170 --> 00:04:23.930
And so now really all of the huge
tech firms whether it's Siri,

00:04:23.930 --> 00:04:26.990
Google Assistant, Facebook and Cortana.

00:04:26.990 --> 00:04:30.690
But what they're furiously doing is

00:04:30.690 --> 00:04:35.560
putting out products that use natural
language to communicate with users.

00:04:35.560 --> 00:04:38.450
And that's an extremely
compelling thing to do.

00:04:38.450 --> 00:04:42.470
It's extremely compelling on phones
because phones have these dinky

00:04:42.470 --> 00:04:46.450
little keyboards that are really
hard to type things on.

00:04:46.450 --> 00:04:51.050
And a lot of you guys are very
fast at texting, I know that, but

00:04:51.050 --> 00:04:55.450
really a lot of those problems are much
worse for a lot of other people.

00:04:55.450 --> 00:04:58.910
So it's a lot harder to put in Chinese
characters than it is to put in

00:04:58.910 --> 00:04:59.910
English letters.

00:04:59.910 --> 00:05:02.500
It's a lot harder if you're elderly.

00:05:02.500 --> 00:05:05.770
It's a lot harder if you've
got low levels of literacy.

00:05:05.770 --> 00:05:09.170
But then there are also
being new vistas opening up.

00:05:09.170 --> 00:05:13.590
So Amazon has had this amazing success
with Alexa, which is really shown

00:05:13.590 --> 00:05:18.250
the utility of having devices that
are just ambient in the environment, and

00:05:18.250 --> 00:05:21.450
that again you can communicate
with by talking to them.

00:05:21.450 --> 00:05:24.650
As a quick shout-out for
Apple, I mean, really,

00:05:24.650 --> 00:05:27.130
we do have Apple to thank for
launching Siri.

00:05:27.130 --> 00:05:32.010
It was, essentially,
Apple taking the bet on saying we can

00:05:32.010 --> 00:05:35.330
turn human language into
consumer technology that

00:05:35.330 --> 00:05:40.410
really did set off this arms race every
other company is now engaging on.

00:05:40.410 --> 00:05:44.740
Okay, I just sort of loosely said meaning.

00:05:44.740 --> 00:05:51.390
One of the things that we'll talk about
more is meaning is a kind of a complex,

00:05:51.390 --> 00:05:56.880
hard thing and it's hard to know what
it means to understand fully meaning.

00:05:56.880 --> 00:06:01.660
At any rate that's certainly a very tough
goal which people refer to as AI-complete

00:06:01.660 --> 00:06:04.600
and it involves all forms of
our understanding of the world.

00:06:04.600 --> 00:06:07.547
So a lot of the time when we
say understand the meaning,

00:06:07.547 --> 00:06:10.764
we might be happy if we sort of
half understood the meaning.

00:06:10.764 --> 00:06:15.918
And we'll talk about different
ways that we can hope to do that.

00:06:15.918 --> 00:06:20.700
Okay, so one of the other things
that we hope that you'll get in

00:06:20.700 --> 00:06:25.573
this class is sort of a bit of
appreciation for human language and

00:06:25.573 --> 00:06:29.200
what it's levels are and
how it's processed.

00:06:29.200 --> 00:06:32.450
Now obviously we're not gonna do a huge
amount of that if you really wanna

00:06:32.450 --> 00:06:33.520
learn a lot about that.

00:06:33.520 --> 00:06:36.614
There are lots of classes that you can
take in the linguistics department and

00:06:36.614 --> 00:06:37.690
learn much more about it.

00:06:37.690 --> 00:06:40.480
But I really hope you can at least
sort of get a bit of a high level of

00:06:40.480 --> 00:06:41.490
understanding.

00:06:41.490 --> 00:06:45.910
So this is kind of the picture that
people traditionally have given for

00:06:45.910 --> 00:06:47.390
levels of language.

00:06:47.390 --> 00:06:49.856
So at the beginning there's input.

00:06:49.856 --> 00:06:52.370
So input would commonly be speech.

00:06:52.370 --> 00:06:53.790
And then you're doing phonetic and

00:06:53.790 --> 00:06:57.660
phonological analysis to
understand that speech.

00:06:57.660 --> 00:06:59.280
Though commonly it is also text.

00:06:59.280 --> 00:07:02.770
And then there's some processing
that's done there which has

00:07:02.770 --> 00:07:06.570
sort of been a bit marginal from
a linguistics point of view, OCR,

00:07:06.570 --> 00:07:08.690
working out the tokenization of the words.

00:07:08.690 --> 00:07:12.220
But then what we do is go through
a series of processing steps

00:07:12.220 --> 00:07:16.610
where we work out complex
words like incomprehensible,

00:07:16.610 --> 00:07:19.030
it has the in in front and
the ible at the end.

00:07:19.030 --> 00:07:22.510
And that sort of morphological analysis,
the parts of words.

00:07:22.510 --> 00:07:23.180
And then we try and

00:07:23.180 --> 00:07:26.890
understand the structure of sentences,
that syntactic analysis.

00:07:26.890 --> 00:07:31.400
So if I have a sentence
like 'I sat on the bench',

00:07:31.400 --> 00:07:37.160
that 'I' is the subject of the verb 'sat',
and the 'on the bench' is the location.

00:07:37.160 --> 00:07:40.695
Then after that we attempt to
do semantic understanding.

00:07:40.695 --> 00:07:45.085
And that's semantic interpretation's
working out the meaning of sentences.

00:07:45.085 --> 00:07:49.484
But simply knowing the meaning
of the words of a sentence isn't

00:07:49.484 --> 00:07:53.717
sufficient to actually really
understand human language.

00:07:53.717 --> 00:07:58.292
A lot is conveyed by the context
in which language is used.

00:07:58.292 --> 00:08:03.314
And so that then leads into areas like
pragmatics and discourse processing.

00:08:03.314 --> 00:08:08.138
So in this class, where we're gonna
spend most of our time is in that middle

00:08:08.138 --> 00:08:12.067
piece of syntactic analysis and
semantic interpretation.

00:08:12.067 --> 00:08:16.348
And that's sort of bulk of our
natural language processing class.

00:08:16.348 --> 00:08:21.164
We will say a little bit right at
the top left where this discussion,

00:08:21.164 --> 00:08:23.036
speech signal analysis.

00:08:23.036 --> 00:08:28.517
And interestingly, that was actually
the first place where deep learning

00:08:28.517 --> 00:08:34.617
really proved itself as super, super
useful for tasks involving human language.

00:08:34.617 --> 00:08:39.617
Okay, so applications of
Natural Language Processing are now

00:08:39.617 --> 00:08:42.648
really spreading out thick and fast.

00:08:42.648 --> 00:08:45.898
And every day you're variously
using applications of

00:08:45.898 --> 00:08:47.812
Natural Language Processing.

00:08:47.812 --> 00:08:49.839
And they vary on a spectrum.

00:08:49.839 --> 00:08:54.967
So they vary from very simple
ones to much more complex ones.

00:08:54.967 --> 00:08:58.551
So at the low level,
there are things like spell checkings, or

00:08:58.551 --> 00:09:01.202
doing the kind of
autocomplete on your phone.

00:09:01.202 --> 00:09:05.564
So that's a sort of a primitive
language understanding task.

00:09:05.564 --> 00:09:08.372
Variously, when you're doing web searches,

00:09:08.372 --> 00:09:12.877
your search engine is considering
synonyms, and things like that for you.

00:09:12.877 --> 00:09:17.016
And, well,
that's also a language understanding task.

00:09:17.016 --> 00:09:20.571
But what we are gonna be more
interested in is trying to

00:09:20.571 --> 00:09:25.237
push our language understanding
computers up to more complex tasks.

00:09:25.237 --> 00:09:29.545
So some of the next level up kind of tasks
that we're actually gonna want to have

00:09:29.545 --> 00:09:34.013
computers look at text information,
be it websites, newspapers or whatever.

00:09:34.013 --> 00:09:37.948
And get the information out of it, to
actually understand the text well enough

00:09:37.948 --> 00:09:41.470
that they know what it's talking
about to at least some extent.

00:09:41.470 --> 00:09:45.920
And so that could be things like expecting
particular kinds of information, like

00:09:45.920 --> 00:09:51.150
products and their prices or people and
what jobs they have and things like that.

00:09:51.150 --> 00:09:55.177
Or it could be doing other related
tasks to understanding the document,

00:09:55.177 --> 00:09:59.411
such as working out the reading level or
intended audience of the document.

00:09:59.411 --> 00:10:02.810
Or whether this tweet is
saying something positive or

00:10:02.810 --> 00:10:06.595
negative about this person,
company, band or whatever.

00:10:06.595 --> 00:10:11.929
And then going even a higher level than
that, what we'd like our computers

00:10:11.929 --> 00:10:17.020
to be able to do is complete whole
level language understanding tasks.

00:10:17.020 --> 00:10:21.260
And some of the prominent tasks of that
kind that we're going to talk about.

00:10:21.260 --> 00:10:25.880
Machine translation, going from one human
language to another human language.

00:10:25.880 --> 00:10:29.847
Building spoken dialogue systems,
so you can chat to a computer and

00:10:29.847 --> 00:10:33.615
have a natural conversation,
just as you do with human beings.

00:10:33.615 --> 00:10:38.605
Or having computers that can actually
exploit the knowledge of the world

00:10:38.605 --> 00:10:42.798
that available on things like
Wikipedia and other sources.

00:10:42.798 --> 00:10:46.028
And so it could actually just
intelligently answer questions for

00:10:46.028 --> 00:10:48.445
you, like a know everything
human being could.

00:10:49.912 --> 00:10:54.765
Okay, and we're starting to see a lot
of those things actually being used

00:10:54.765 --> 00:10:56.419
regularly in industry.

00:10:56.419 --> 00:11:00.405
So every time you're doing a search,
in little places, there are bits of

00:11:00.405 --> 00:11:04.738
natural language processing and
natural language understanding happening.

00:11:04.738 --> 00:11:07.922
So if you're putting in
forms of words with endings,

00:11:07.922 --> 00:11:11.126
your search engine's
considering taking them off.

00:11:11.126 --> 00:11:13.527
If there are spelling errors,
they're being corrected.

00:11:13.527 --> 00:11:15.934
Synonyms are being considered,
and things like that.

00:11:15.934 --> 00:11:19.175
Similarly, when you're being matched for
advertisements.

00:11:19.175 --> 00:11:24.630
But what's really exciting is that
we're now starting to see much

00:11:24.630 --> 00:11:29.100
bigger applications of natural language
processing being commercially successful.

00:11:29.100 --> 00:11:31.700
So in the last few years,
there's just been amazing,

00:11:31.700 --> 00:11:36.190
amazing advances in machine translation
that I'll come back to later.

00:11:36.190 --> 00:11:41.229
There have been amazing advances in
speech recognition so that we just now

00:11:41.229 --> 00:11:46.444
get hugely good performance in speech
recognition even on our cell phones.

00:11:46.444 --> 00:11:49.910
Products like sentiment analysis
they have become hugely commercially

00:11:49.910 --> 00:11:51.073
important, right?

00:11:51.073 --> 00:11:55.392
It depends on your favorite industries but
there are lots of Wall Street Journal

00:11:55.392 --> 00:11:59.194
firms that every hour of the day
are scanning news articles looking for

00:11:59.194 --> 00:12:02.431
sentiment about companies to make buy and
sell decisions.

00:12:02.431 --> 00:12:05.981
And just recently,
really over the last 12 months,

00:12:05.981 --> 00:12:10.535
there's been this huge growth of
interest in how to build chatbots and

00:12:10.535 --> 00:12:13.720
dialog agents for
all sorts of interface tasks.

00:12:13.720 --> 00:12:17.911
And that sort of seems like it's
growing to become a huge new industry.

00:12:17.911 --> 00:12:21.968
Okay, see I'm getting behind already.

00:12:21.968 --> 00:12:24.246
So in just a couple of minutes,

00:12:24.246 --> 00:12:28.815
I want to say that corresponding
things about deep learning.

00:12:28.815 --> 00:12:30.877
But before getting into that,

00:12:30.877 --> 00:12:35.490
let me just say a minute about
what's special about human language.

00:12:35.490 --> 00:12:37.000
Maybe we'll come back to this, but

00:12:37.000 --> 00:12:41.450
I think it's interesting to have
a sense of right at the beginning.

00:12:41.450 --> 00:12:46.380
So there's an important
difference between language and

00:12:46.380 --> 00:12:51.670
most other kinds of things that people
think of when they do signal processing

00:12:51.670 --> 00:12:56.460
and data mining and
all of those kinds of things.

00:12:56.460 --> 00:13:03.770
So for most things, there's just sort of
data that's either the world out there.

00:13:03.770 --> 00:13:08.683
It has some kind of,
pick up some visual system for it.

00:13:08.683 --> 00:13:13.119
Or someone's sort of buying
products at the local Safeway.

00:13:13.119 --> 00:13:16.179
And then someone else is picking
up the sales log and saying,

00:13:16.179 --> 00:13:18.768
let me analyze this and
see what I can find, right?

00:13:18.768 --> 00:13:21.025
So it's just sort of all
this random data and

00:13:21.025 --> 00:13:23.885
then then someone's trying
to make sense of it.

00:13:23.885 --> 00:13:27.035
So fundamentally,
human language isn't like that.

00:13:27.035 --> 00:13:30.854
Human language isn't just sort of a
massive data exhaust that you're trying to

00:13:30.854 --> 00:13:32.454
process into something useful.

00:13:32.454 --> 00:13:35.638
Human language,
almost all of it is that there's some

00:13:35.638 --> 00:13:40.081
human being who actually had some
information they wanted to communicate.

00:13:40.081 --> 00:13:43.445
And they constructed
a message to communicate that

00:13:43.445 --> 00:13:45.877
information to other human beings.

00:13:45.877 --> 00:13:50.800
So it's actually a deliberate
form of sending a particular

00:13:50.800 --> 00:13:52.971
message to other people.

00:13:52.971 --> 00:13:57.902
Okay, and an amazing fact about human
language is it's this very complex

00:13:57.902 --> 00:13:59.651
system that somehow two,

00:13:59.651 --> 00:14:04.356
three, four year old kids amazingly
can start to pick it up and use it.

00:14:04.356 --> 00:14:06.560
So there's something good going on there.

00:14:06.560 --> 00:14:11.430
Another interesting property of
language is that language is actually

00:14:11.430 --> 00:14:16.860
what you could variously call a discrete,
symbolic, or categorical signaling system.

00:14:16.860 --> 00:14:21.290
So we have words for
concepts like rocket or violin.

00:14:21.290 --> 00:14:25.600
And basically, we're communicating
with other people via symbols.

00:14:25.600 --> 00:14:29.050
There are some tiny exceptions for
expressive signaling, so

00:14:29.050 --> 00:14:33.450
you can distinguish saying,
I love it versus I LOVE it.

00:14:33.450 --> 00:14:34.410
And that sounds stronger.

00:14:34.410 --> 00:14:40.586
But 99% of the time it's using these
symbols to communicate meaning.

00:14:40.586 --> 00:14:45.316
And presumably, that came about in
a sort of EE information theory sense.

00:14:45.316 --> 00:14:47.252
Because by having symbols,

00:14:47.252 --> 00:14:52.502
they're very reliable units that can
be signaled reliably over a distance.

00:14:52.502 --> 00:14:54.238
And so that's an important
thing to be aware of, right?

00:14:54.238 --> 00:14:55.998
Language is symbols.

00:14:55.998 --> 00:15:01.432
So if symbols aren't just some
invention of logic or classical AI.

00:15:01.432 --> 00:15:03.106
But then, when we move beyond that,

00:15:03.106 --> 00:15:05.540
there's actually something
interesting going on.

00:15:05.540 --> 00:15:09.250
So when human beings
communicate with language

00:15:09.250 --> 00:15:13.400
that although what they're wanting
to communicate involves symbols.

00:15:13.400 --> 00:15:19.110
That the way they communicate those
symbols is using a continuous substrate.

00:15:19.110 --> 00:15:22.310
And a really interesting
thing about language is you

00:15:22.310 --> 00:15:27.740
can convey exactly the same message by
using different continuous substrates.

00:15:27.740 --> 00:15:31.770
So commonly, we use voice and
so there are audio waves.

00:15:31.770 --> 00:15:36.011
You can put stuff on a piece of paper and
then you have a vision problem.

00:15:36.011 --> 00:15:38.715
You can also use sign
language to communicate.

00:15:38.715 --> 00:15:41.410
And that's a different kind
of continuous substrate.

00:15:41.410 --> 00:15:43.480
So all of those can be used.

00:15:43.480 --> 00:15:46.960
But there's sort of a symbol underlying
all of those different encodings.

00:15:48.420 --> 00:15:54.700
Okay, so what the picture we have is that
the communication medium is continuous.

00:15:55.830 --> 00:15:59.440
Human languages are a symbol system.

00:15:59.440 --> 00:16:03.240
And then the interesting part
is what happens after that.

00:16:03.240 --> 00:16:08.144
So the dominant idea in most of
the history of philosophy and

00:16:08.144 --> 00:16:13.050
science and artificial intelligence
was to sort of project

00:16:13.050 --> 00:16:17.220
the symbol system of
language into our brains.

00:16:17.220 --> 00:16:20.083
And think of brains as
symbolic processors.

00:16:20.083 --> 00:16:24.250
But that doesn't actually seem to have
any basis in what brains are like.

00:16:24.250 --> 00:16:27.840
Everything that we know about
brains is that they're completely

00:16:27.840 --> 00:16:30.170
continuous systems as well.

00:16:30.170 --> 00:16:35.096
And so the interesting idea that's
been emerging out of this work in deep

00:16:35.096 --> 00:16:39.697
learning is to say, no, what we should
be doing is also thinking of our

00:16:39.697 --> 00:16:43.439
brains as having continuous
patterns of activation.

00:16:43.439 --> 00:16:48.115
And so then the picture we have is that
we're going from continuous to symbolic,

00:16:48.115 --> 00:16:51.156
back to continuous every
time that we use language.

00:16:51.156 --> 00:16:52.900
So that's interesting.

00:16:52.900 --> 00:16:57.200
It also points out one of the problems of
doing language understanding that we'll

00:16:57.200 --> 00:16:59.820
come back to a lot of times.

00:16:59.820 --> 00:17:03.780
So in languages we have huge vocabularies.

00:17:03.780 --> 00:17:07.550
So languages have tens of
thousands of words minimum.

00:17:07.550 --> 00:17:11.360
And really, languages like English
with a huge scientific vocabulary,

00:17:11.360 --> 00:17:14.020
have hundreds of thousands
of words in them.

00:17:14.020 --> 00:17:15.120
It depends how you count.

00:17:15.120 --> 00:17:18.600
If you start counting up all of the
morphological forms, you can argue some

00:17:18.600 --> 00:17:22.790
languages have an infinite number of words
cuz they have productive morphology.

00:17:22.790 --> 00:17:26.910
But however you count, it means we've
got this huge problem of sparsity and

00:17:26.910 --> 00:17:29.129
that's one of the big problems that
we're gonna have to deal with.

00:17:30.560 --> 00:17:36.880
Okay, now I'll change gears and say
a little bit of an intro to deep learning.

00:17:36.880 --> 00:17:43.670
So deep learning has been this area that
has erupted over the sort of this decade.

00:17:43.670 --> 00:17:45.280
And I mean, it's just been enormously,

00:17:45.280 --> 00:17:50.340
enormously exciting how deep learning
has succeeded and how it has expanded.

00:17:50.340 --> 00:17:55.580
So really, at the moment it seems like
every month you see in the tech news

00:17:55.580 --> 00:18:00.355
that there's just amazing new improvements
that are coming out from deep learning.

00:18:00.355 --> 00:18:04.085
So one month it's super human
computer vision systems,

00:18:04.085 --> 00:18:07.825
the next month it's machine
translation that's vastly improved.

00:18:07.825 --> 00:18:11.570
The month after that people are working
out how to get computers to

00:18:11.570 --> 00:18:14.510
produce their own artistry
that's incredibly realistic.

00:18:14.510 --> 00:18:15.930
Then the month after that,

00:18:15.930 --> 00:18:20.210
people are producing new text-to-speech
systems that sound amazingly lifelike.

00:18:20.210 --> 00:18:23.760
I mean, there's just been this
sort of huge dynamic of progress.

00:18:23.760 --> 00:18:26.317
So what is underlying all of that?

00:18:26.317 --> 00:18:31.570
So, well, as a starting point, deep
learning, it's part of machine learning.

00:18:31.570 --> 00:18:36.345
So in general, it's this idea of how
can we get computers to learn stuff

00:18:36.345 --> 00:18:41.757
automatically, rather than just us having
to tell them things and coding by hand

00:18:41.757 --> 00:18:47.265
in the kind of traditional write computer
program to tell it what you want it to do.

00:18:47.265 --> 00:18:52.150
But deep learning is also profoundly
different to the vast majority of

00:18:52.150 --> 00:18:56.801
what happened in machine learning
in the 80s, 90s, and 00s.

00:18:56.801 --> 00:19:01.760
And this central difference is that for
most of traditional machine learning,

00:19:01.760 --> 00:19:02.877
if I call it that.

00:19:02.877 --> 00:19:07.255
So this is all of the stuff like
decision trees, logistic regressions,

00:19:07.255 --> 00:19:11.660
naive bayes, support vector machines,
and any of those sort of things.

00:19:11.660 --> 00:19:15.330
Essentially the way
that we did things was,

00:19:15.330 --> 00:19:19.730
what we did was have a human being
who looked carefully at a particular

00:19:19.730 --> 00:19:23.848
problem and worked out what
was important in that problem.

00:19:23.848 --> 00:19:29.036
And then designed features that
would be useful features for

00:19:29.036 --> 00:19:34.028
handling the problem that they
would then encode by hand.

00:19:34.028 --> 00:19:36.652
Normally by writing little
bits of Python code or

00:19:36.652 --> 00:19:39.710
something like that to
recognize those features.

00:19:39.710 --> 00:19:44.350
They're probably a little bit small to
read, but over on the right-hand side,

00:19:44.350 --> 00:19:47.910
these are showing some features for
an entity recognition system.

00:19:47.910 --> 00:19:51.130
Finding person names,
company names, and so on in text.

00:19:51.130 --> 00:19:54.070
And this is just the kind of
system I've written myself.

00:19:54.070 --> 00:19:57.974
So, well, if you want to know whether
a word is a company, you'd wanna look

00:19:57.974 --> 00:20:01.151
whether it was capitalized, so
you have a feature like that.

00:20:01.151 --> 00:20:03.688
It turns out that looking at
the words to the left and

00:20:03.688 --> 00:20:06.470
right would be useful to have features for
that.

00:20:06.470 --> 00:20:09.420
It turns out that looking
at substrings of words is

00:20:09.420 --> 00:20:12.000
useful cause they're kind
of common patterns of

00:20:12.000 --> 00:20:15.590
letter sequences that indicate names
of people versus of names of companies.

00:20:15.590 --> 00:20:19.500
So you put in features for substrings.

00:20:19.500 --> 00:20:22.956
If you see hyphens and things,
that's an indicator of some things.

00:20:22.956 --> 00:20:24.530
You put in a feature for that.

00:20:24.530 --> 00:20:28.140
So you keep on putting in features and
commonly these kind of systems would end

00:20:28.140 --> 00:20:30.825
up with millions of
hand-designed features.

00:20:30.825 --> 00:20:37.430
And that was essentially how Google search
was done until about 2015 as well, right?

00:20:37.430 --> 00:20:40.360
They liked the word signal
rather than feature.

00:20:40.360 --> 00:20:44.670
But the way you improved Google
search was every month some

00:20:44.670 --> 00:20:47.720
bunch of engineers came
up with some new signal.

00:20:47.720 --> 00:20:51.911
That they could show with an experiment
that if you added in these extra features,

00:20:51.911 --> 00:20:53.562
Google search got a bit better.

00:20:53.562 --> 00:20:56.355
And [INAUDIBLE] a degree and
that would get thrown in, and

00:20:56.355 --> 00:20:57.909
things would get a bit better.

00:20:57.909 --> 00:21:03.547
But the thing to think about is, well,
this was advertised as machine learning,

00:21:03.547 --> 00:21:06.663
but what was the machine
actually learning?

00:21:06.663 --> 00:21:10.090
It turns out that the machine
was learning almost nothing.

00:21:10.090 --> 00:21:13.270
So the human being was learning
a lot about the problem, right?

00:21:13.270 --> 00:21:18.190
They were looking at the problem hard,
doing lots of data analysis, developing

00:21:18.190 --> 00:21:22.880
theories, and learning a lot about
what was important for this property.

00:21:22.880 --> 00:21:24.750
What was the machine doing?

00:21:24.750 --> 00:21:27.590
It turns out that the only
thing the machine was doing

00:21:27.590 --> 00:21:29.288
was numeric optimization.

00:21:29.288 --> 00:21:32.010
So once you had all these signals,

00:21:32.010 --> 00:21:35.440
what you're then going to be doing
was building a linear classifier.

00:21:35.440 --> 00:21:39.850
Which meant that you were putting a
parameter weight in front of each feature.

00:21:39.850 --> 00:21:44.630
And the machine learning system's
job was to adjust those numbers so

00:21:44.630 --> 00:21:46.570
as to optimize performance.

00:21:46.570 --> 00:21:49.210
And that's actually something that
computers are really good at.

00:21:49.210 --> 00:21:52.900
Computers are really good at
doing numeric optimization and

00:21:52.900 --> 00:21:55.340
it's something that human beings
are actually less good at.

00:21:55.340 --> 00:21:57.830
Cuz humans, if you say,
here are 100 features,

00:21:57.830 --> 00:22:01.340
put a real number in front of
each one to maximize performance.

00:22:01.340 --> 00:22:03.180
Well, they've got sort of a vague idea but

00:22:03.180 --> 00:22:06.350
they certainly can't do that
as well as a computer can.

00:22:06.350 --> 00:22:11.150
So that was useful but
is doing numeric optimization,

00:22:11.150 --> 00:22:13.200
is that what machine learning means?

00:22:13.200 --> 00:22:14.540
It doesn't seem like it should be.

00:22:15.550 --> 00:22:21.142
Okay, so what we found that in practice
machine learning was sort of 90%

00:22:21.142 --> 00:22:27.109
human beings working out how to describe
data and work out important features.

00:22:27.109 --> 00:22:30.898
And only sort of 10% the computer
running this learning

00:22:30.898 --> 00:22:33.386
numerical optimization algorithm.

00:22:34.874 --> 00:22:38.040
Okay, so
how does that differ with deep learning?

00:22:38.040 --> 00:22:40.050
So deep learning works,

00:22:40.050 --> 00:22:43.730
is part of this field that's
called representation learning.

00:22:43.730 --> 00:22:50.065
And the idea of representation learning is
to say, we can just feed to our computers

00:22:50.065 --> 00:22:55.305
raw signals from the world, whether that's
visual signals or language signals.

00:22:55.305 --> 00:23:00.127
And then the computer can automatically,
by itself, come up with

00:23:00.127 --> 00:23:05.137
good intermediate representations
that will allow it to do tasks well.

00:23:05.137 --> 00:23:09.027
So in some sense,
it's gonna be inventing its own features

00:23:09.027 --> 00:23:14.647
in the same way that in the past the human
being was inventing the features.

00:23:14.647 --> 00:23:17.357
So precisely deep learning,

00:23:18.380 --> 00:23:23.550
the real meaning of the word deep
learning is the argument that you could

00:23:23.550 --> 00:23:29.080
actually have multiple layers
of learned representations.

00:23:29.080 --> 00:23:34.543
And that you'd be able to outperform
other methods of learning

00:23:34.543 --> 00:23:39.503
by having multiple layers
of learned representations.

00:23:39.503 --> 00:23:42.380
That was where the term
deep learning came from.

00:23:43.460 --> 00:23:49.259
Nowadays, half the time, deep learning
just means you're using neural networks.

00:23:49.259 --> 00:23:53.419
And the other half of the time it means
there's some tech reporter writing a story

00:23:53.419 --> 00:23:56.415
and it's vaguely got to do
with intelligent computers and

00:23:56.415 --> 00:23:57.652
all other bets are off.

00:23:57.652 --> 00:24:01.220
Okay, [LAUGH] yeah.

00:24:01.220 --> 00:24:07.040
So with the kind of coincidence
where sort of deep learning

00:24:07.040 --> 00:24:10.670
really means neural networks a lot of
the time, we're gonna be part of that.

00:24:10.670 --> 00:24:15.390
So what we're gonna focus on in this class
is different kinds of neural networks.

00:24:15.390 --> 00:24:19.430
So at the moment,
they're clearly the dominant family

00:24:19.430 --> 00:24:23.240
of ways in which people have reached
success in doing deep learning.

00:24:23.240 --> 00:24:27.220
But it's not the only possible way
that you could do it that people have

00:24:27.220 --> 00:24:31.630
certainly looked at trying to use various
other kinds of probabilistic models and

00:24:31.630 --> 00:24:33.760
other things in deep architectures.

00:24:33.760 --> 00:24:37.089
And I think that may well be
more of that work in the future.

00:24:38.790 --> 00:24:41.610
What are these neural networks
that we are talking about?

00:24:41.610 --> 00:24:45.780
That's something we'll come back to and
talk a lot about both on Thursday and

00:24:45.780 --> 00:24:46.770
next week.

00:24:46.770 --> 00:24:51.250
I mean you noticed a lot of
these neural terminology.

00:24:51.250 --> 00:24:55.175
I mean in some sense if you're kind of
coming from a background of statistics or

00:24:55.175 --> 00:24:58.506
something like that,
you could sort of say neural networks,

00:24:58.506 --> 00:25:02.135
they're kind of nothing really more
than stack logistic regressions or

00:25:02.135 --> 00:25:05.545
perhaps more generally kinda
stacked generalized linear models.

00:25:05.545 --> 00:25:08.340
And in some sense that's true.

00:25:08.340 --> 00:25:12.410
There are some connections to
neuroscience in some cases,

00:25:12.410 --> 00:25:15.960
so that's not a big focus
on this class at all.

00:25:15.960 --> 00:25:21.000
But on the other hand, there's
something very qualitatively different,

00:25:21.000 --> 00:25:26.230
that by the kind of architectures
that people are building now for

00:25:26.230 --> 00:25:30.450
these complex stacking of
neural unit architectures,

00:25:30.450 --> 00:25:35.000
you end up with a behavior and a way of
thinking and a way of doing things that's

00:25:35.000 --> 00:25:40.070
just hugely different, than anything that
was coming before in earlier statistics.

00:25:40.070 --> 00:25:42.230
We're not really gonna take
a historical approach,

00:25:42.230 --> 00:25:47.260
we're gonna concentrate on
methods that work well right now.

00:25:47.260 --> 00:25:51.240
If you'd like to read a long
history of deep learning,

00:25:51.240 --> 00:25:54.840
though I'll warn you it's a pretty dry and
boring history,

00:25:54.840 --> 00:25:59.690
there's this very long arxiv paper by
Jürgen Schmidhuber that you could look at.

00:25:59.690 --> 00:26:04.240
Okay, so why is deep learning exciting?

00:26:04.240 --> 00:26:08.650
So in general our manually designed
features tend to be overspecified,

00:26:08.650 --> 00:26:12.770
incomplete, take a long time to design and
validate, and

00:26:12.770 --> 00:26:16.720
only get you to a certain level of
performance at the end of the day.

00:26:16.720 --> 00:26:20.874
Where the learned features are easy
to adapt, fast to train, and

00:26:20.874 --> 00:26:24.649
they can keep on learning so
that they get to a better level of

00:26:24.649 --> 00:26:28.448
performance than we've been
able to achieve previously.

00:26:28.448 --> 00:26:33.239
So, deep learning ends up providing this
sort of very flexible, almost universal

00:26:33.239 --> 00:26:37.980
learning framework which is just great for
representing all kinds of information.

00:26:37.980 --> 00:26:42.550
Linguistic information but also world
information or visual information.

00:26:42.550 --> 00:26:47.049
It can be used in both supervised
fashions and unsupervised fashions.

00:26:48.520 --> 00:26:52.600
The real reason why deep learning
is exciting to most people

00:26:52.600 --> 00:26:55.140
is it has been working.

00:26:55.140 --> 00:27:00.064
So starting from approximately 2010,
there were initial successes where

00:27:00.064 --> 00:27:04.913
deep learning were shown to work far
better than any of the traditional machine

00:27:04.913 --> 00:27:09.050
learning methods that have been used for
the last 30 years.

00:27:09.050 --> 00:27:10.808
But going even beyond that,

00:27:10.808 --> 00:27:15.203
what has just been totally stunning
is over the last six or seven years,

00:27:15.203 --> 00:27:19.966
there's just been this amazing ramp in
which deep learning methods have been

00:27:19.966 --> 00:27:24.390
keeping on being improved and
getting better at just an amazing speed.

00:27:24.390 --> 00:27:28.567
Which is actually sort of being,
maybe I'm biased, but

00:27:28.567 --> 00:27:34.138
in the length of my lifetime,
I'd actually just say it's unprecedented,

00:27:34.138 --> 00:27:39.534
in terms of seeing a field that has
been progressing quite so quickly in its

00:27:39.534 --> 00:27:45.566
ability to be sort of rolling out better
methods of doing things, month on month.

00:27:45.566 --> 00:27:49.691
And that's why you're sort of seeing
all of this huge industry excitement,

00:27:49.691 --> 00:27:52.890
new products, and you're all here today.

00:27:52.890 --> 00:27:57.300
So why has deep learning succeeded so
brilliantly?

00:27:57.300 --> 00:28:02.140
And I mean this is actually
a slightly more subtle and

00:28:02.140 --> 00:28:06.214
in some sense not quite so
uplifting a tale.

00:28:06.214 --> 00:28:10.937
Because when you look at a lot of
the key techniques that we use for

00:28:10.937 --> 00:28:15.418
deep learning were actually
invented in the 80s or 90s.

00:28:15.418 --> 00:28:16.870
They're not new.

00:28:16.870 --> 00:28:20.310
We're using a lot of stuff that
was done in the 80s and 90s.

00:28:20.310 --> 00:28:26.060
And somehow,
they didn't really take off then.

00:28:26.060 --> 00:28:27.520
So what is the difference?

00:28:28.700 --> 00:28:31.960
Well it turns out that actually
some of the difference,

00:28:31.960 --> 00:28:35.773
actually maybe quite a lot of
the difference, is just that

00:28:35.773 --> 00:28:41.020
technological advances have happened
that make this all possible.

00:28:41.020 --> 00:28:45.600
So we now have vastly greater amounts
of data available because of our

00:28:45.600 --> 00:28:49.280
online society where just about
everything is available as data.

00:28:49.280 --> 00:28:53.350
And having vast amounts of data
really favors deep learning models.

00:28:54.530 --> 00:28:55.898
In the 80s and 90s,

00:28:55.898 --> 00:29:00.550
there sort of wasn't really enough
compute power to do deep learning well.

00:29:00.550 --> 00:29:04.310
So having sort of several
more decades of compute power

00:29:04.310 --> 00:29:07.030
has just made it that we can
now build systems that work.

00:29:07.030 --> 00:29:10.870
I mean in particular there's
been this amazing confluence

00:29:10.870 --> 00:29:16.040
that deep learning has proven to be just
super well suited to the kind of parallel

00:29:16.040 --> 00:29:21.330
vector processing that's available now for
very little money in GPUs.

00:29:21.330 --> 00:29:24.270
So there's been this sort of
marriage between deep learning and

00:29:24.270 --> 00:29:27.130
GPUs, which has enabled a lot
of stuff to have happened.

00:29:28.190 --> 00:29:30.700
So that's actually quite
a lot of what's going on.

00:29:30.700 --> 00:29:34.050
But it's not the only thing that's going
on and it's not the thing that's leading

00:29:34.050 --> 00:29:37.730
to this sort of things keeping on getting
better and better month by month.

00:29:37.730 --> 00:29:40.470
I mean, people have also come up with

00:29:40.470 --> 00:29:44.310
better ways of learning
intermediate representations.

00:29:44.310 --> 00:29:49.400
They've come up with much better ways of
doing end-to-end joint system learning.

00:29:49.400 --> 00:29:52.610
They've come up with much better ways of

00:29:52.610 --> 00:29:56.760
transferring information between domains
and between contexts and things.

00:29:56.760 --> 00:30:01.580
So there are also a lot of new algorithms
and algorithmic advances and they're sort

00:30:01.580 --> 00:30:04.780
of in some sense the more exciting
stuff that we're gonna focus on for

00:30:04.780 --> 00:30:05.630
more of the time.

00:30:07.100 --> 00:30:08.860
Okay, so

00:30:08.860 --> 00:30:14.880
really the first big breakthrough in
deep learning was in speech recognition.

00:30:14.880 --> 00:30:19.710
It wasn't as widely heralded as the second
big breakthrough in deep learning.

00:30:19.710 --> 00:30:23.060
But this was really
the big one that started.

00:30:23.060 --> 00:30:27.779
At the University of Toronto,
George Dahl working with Geoff Hinton

00:30:27.779 --> 00:30:31.810
started showing on tiny datasets, that

00:30:31.810 --> 00:30:36.950
they could do exciting things with deep
neural networks for speech recognition.

00:30:36.950 --> 00:30:44.170
So George Dahl then went off to Microsoft
and then fairly shortly after that,

00:30:44.170 --> 00:30:48.920
another student from Toronto
went to Google and they started

00:30:48.920 --> 00:30:53.470
building big speech recognition systems
that use deep learning networks.

00:30:53.470 --> 00:30:56.090
And speech recognition's a problem
that's been worked on for

00:30:56.090 --> 00:30:58.050
decades by hundreds of people.

00:30:58.050 --> 00:30:59.320
And there are big companies.

00:30:59.320 --> 00:31:03.330
And there was this sort of fairly
standardized technology of

00:31:03.330 --> 00:31:06.820
using Gaussian mixture models for
the acoustic analysis and

00:31:06.820 --> 00:31:09.680
hidden Markov models and blah blah blah.

00:31:09.680 --> 00:31:14.190
Which people have been honing for decades
trying to improve a few percent a year.

00:31:14.190 --> 00:31:17.830
And what they were able to
show was by changing from that

00:31:17.830 --> 00:31:22.770
to using deep learning models for
doing speech recognition, that they

00:31:22.770 --> 00:31:27.050
were immediately able to get just these
enormous decreases in word error rate.

00:31:27.050 --> 00:31:30.640
About a 30% decrease in word error rate.

00:31:30.640 --> 00:31:35.100
Then the second huge example of
the success of deep learning,

00:31:35.100 --> 00:31:40.503
which ended up being a much bigger thing
in terms of everybody noticing it,

00:31:40.503 --> 00:31:44.222
was in the ImageNet computer
vision competition.

00:31:44.222 --> 00:31:51.140
So in 2012 again students of Geoff Hinton
at Toronto set about building a computer

00:31:51.140 --> 00:31:57.790
vision system of doing ImageNet task
of classifying objects into categories.

00:31:57.790 --> 00:32:01.020
And that was again a task that
had been run for several years.

00:32:01.020 --> 00:32:06.746
And performance seemed fairly stalled with
traditional computer vision methods and

00:32:06.746 --> 00:32:11.358
running deep neural networks on GPUs
that they were able to get an over

00:32:11.358 --> 00:32:14.558
one-third error reduction
in one fell swoop.

00:32:14.558 --> 00:32:19.371
And that progress is continued
through the years, but

00:32:19.371 --> 00:32:22.210
we won't say a lot on that here.

00:32:22.210 --> 00:32:25.250
Okay, that's taken me a fair way.

00:32:25.250 --> 00:32:28.320
So let's stop for a moment and
do the logistics, and

00:32:28.320 --> 00:32:30.980
I'll say more about deep learning and NLP.

00:32:30.980 --> 00:32:34.050
Okay, so
this class is gonna have two instructors.

00:32:34.050 --> 00:32:37.990
I'm Chris Manning and I'm a Stanford
faculty, then the other one is Richard,

00:32:37.990 --> 00:32:40.700
who's the chief scientist of
faith of Salesforce, and so

00:32:40.700 --> 00:32:43.290
I'll let him say a minute or two hello.

00:32:43.290 --> 00:32:44.880
&gt;&gt; Hi there, great to be here.

00:32:44.880 --> 00:32:47.597
I guess,
just a brief little bit about myself.

00:32:47.597 --> 00:32:52.280
In 2014, I graduated,
I got my PhD here with Chris and

00:32:52.280 --> 00:32:54.966
Enring in deep learning for NLP.

00:32:54.966 --> 00:32:58.795
And then almost became a professor,
but then started a little company,

00:32:58.795 --> 00:33:01.635
built an ad platform, did some research.

00:33:01.635 --> 00:33:03.765
And then earlier last year,

00:33:03.765 --> 00:33:06.955
we got acquired by Salesforce,
which is how I ended up there.

00:33:06.955 --> 00:33:09.848
I've been teaching CS224D
the last two years and

00:33:09.848 --> 00:33:12.022
super excited to merge to two classes.

00:33:13.882 --> 00:33:16.319
&gt;&gt; Okay.

00:33:16.319 --> 00:33:20.798
&gt;&gt; I think next week, I'll do the two
lectures, so you'll see a lot of me.

00:33:20.798 --> 00:33:23.182
&gt;&gt; [LAUGH]
&gt;&gt; I'll do all the boring equations.

00:33:23.182 --> 00:33:28.575
&gt;&gt; [LAUGH] Okay, and then TAs,
we've got many really wonderful,

00:33:28.575 --> 00:33:32.220
competent, great TAs for this class.

00:33:32.220 --> 00:33:35.786
Yeah, so normally I go through all
the TAs, but there are sort of so

00:33:35.786 --> 00:33:39.672
many, both of them and you, that maybe
I won't go through them all, but

00:33:39.672 --> 00:33:44.036
maybe they could all just sort of stand up
for a minute if you're a TA in the class.

00:33:44.036 --> 00:33:47.885
They're all in that corner, okay,
[LAUGH] and they're clustered.

00:33:47.885 --> 00:33:54.242
[LAUGH] Okay, right,
yeah, so at this point,

00:33:54.242 --> 00:34:00.436
I mean, apologies about the room capacity.

00:34:00.436 --> 00:34:05.332
So the fact of the matter is if this class
is being kind of videoed and broadcast,

00:34:05.332 --> 00:34:09.520
this is sort of the largest SCPD
classroom that they record in.

00:34:09.520 --> 00:34:11.980
So, there's no real choice for this,

00:34:11.980 --> 00:34:16.780
this is the same reason that this is
where 221 is, and this is where 229 is.

00:34:16.780 --> 00:34:23.130
But it's a shame that there aren't enough
seats for everybody, sorry about that.

00:34:23.130 --> 00:34:28.548
It will be available shortly after
each class, also as a video.

00:34:28.548 --> 00:34:33.224
In general for the other information,
look at the website, but there's a couple

00:34:33.224 --> 00:34:37.860
things that I do just wanna say a little
bit about, prerequisites and work to do.

00:34:37.860 --> 00:34:39.585
So, when it comes down to it,

00:34:39.585 --> 00:34:42.898
these are the things that you
sort of really need to know.

00:34:42.898 --> 00:34:47.887
And we'll expect you to know, and if you
don't know, you should start working

00:34:47.887 --> 00:34:51.900
out what you don't know and
what to do about it very quickly.

00:34:51.900 --> 00:34:55.060
So the first one is we're gonna
do the assignments in Python, so

00:34:55.060 --> 00:34:59.040
proficiency in Python,
there's a tutorial on the website,

00:34:59.040 --> 00:35:01.040
not hard to learn if
you do something else.

00:35:02.280 --> 00:35:05.930
Essentially, Python has just become
the lingua franca of nearly all the deep

00:35:05.930 --> 00:35:09.320
learning toolkits, so
that seems the thing to use.

00:35:09.320 --> 00:35:13.990
We're gonna do a lot of stuff
with calculus and vectors and

00:35:13.990 --> 00:35:17.620
matrices, so multivariate calculus,
linear algebra.

00:35:17.620 --> 00:35:22.857
It'll start turning up on Thursday and
even more next week.

00:35:22.857 --> 00:35:26.796
Sort of basic probability and statistics,
you don't need to know anything

00:35:26.796 --> 00:35:29.824
fancy about martingales or
something, I don't either.

00:35:29.824 --> 00:35:33.460
But you should know
the elements of that stuff.

00:35:33.460 --> 00:35:36.137
And then we're gonna assume you know
some fundamentals of machine learning.

00:35:36.137 --> 00:35:39.684
So if you've done 221 or 229, that's fine.

00:35:39.684 --> 00:35:43.099
Again, you don't need to know
all of that content, but

00:35:43.099 --> 00:35:47.969
we sort of assume that you've seen loss
functions, and you have some idea about

00:35:47.969 --> 00:35:52.760
how you do optimization with gradient
descent and things like that.

00:35:52.760 --> 00:35:58.120
Okay, so in terms of what we hope to
teach, the first thing is an understanding

00:35:58.120 --> 00:36:01.790
of and ability to use effective
modern methods for deep learning.

00:36:01.790 --> 00:36:03.630
So we'll be covering all the basics, but

00:36:03.630 --> 00:36:07.270
especially an emphasis on the main
methods that are being used in NLP,

00:36:07.270 --> 00:36:11.300
which is things like recurrent networks,
attention, and things like that.

00:36:11.300 --> 00:36:13.880
Some big picture understanding
of human languages and

00:36:13.880 --> 00:36:16.528
the difficulties in understanding and
producing them.

00:36:16.528 --> 00:36:20.370
And then the third one is essentially
the intersection of those two things.

00:36:20.370 --> 00:36:25.420
So the ability to build systems for
important NLP problems.

00:36:25.420 --> 00:36:29.850
And you guys will be building some of
those for the various assignments.

00:36:29.850 --> 00:36:32.050
So in terms of the work to be done,
this is it.

00:36:32.050 --> 00:36:34.450
So there's gonna be three assignments.

00:36:34.450 --> 00:36:36.500
There's gonna be a midterm exam.

00:36:36.500 --> 00:36:41.024
And then at the end, there's this
bigger thing where you sort of have

00:36:41.024 --> 00:36:45.002
a choice between either you can
come up with your own exciting

00:36:45.002 --> 00:36:48.521
world shattering final project and
propose it to us.

00:36:48.521 --> 00:36:53.171
And we gotta make sure every final project
has a mentor, which can either be Richard

00:36:53.171 --> 00:36:57.840
or me, one of the TAs, or someone else
who knows stuff about deep learning.

00:36:57.840 --> 00:37:02.640
Or else, we can give you
an exciting project, and so

00:37:02.640 --> 00:37:05.360
there'll be sort of
a default final project,

00:37:05.360 --> 00:37:11.260
otherwise known as Assignment 4.

00:37:11.260 --> 00:37:14.440
There's gonna be a final poster session.

00:37:14.440 --> 00:37:18.986
So every team for the final project,
you're gonna have teams up to three for

00:37:18.986 --> 00:37:22.880
the final project,
has to be at the final poster session.

00:37:22.880 --> 00:37:25.947
Now we thought about having it
in our official exam slot, but

00:37:25.947 --> 00:37:30.160
that was on Friday afternoon, and so
we decided people might not like that.

00:37:30.160 --> 00:37:35.560
So we're gonna have it in
the Tuesday early afternoon session,

00:37:35.560 --> 00:37:39.310
which is when the language
class exams are done.

00:37:39.310 --> 00:37:40.980
So no offense to languages, but

00:37:40.980 --> 00:37:46.030
we're assuming that none of you are doing
first year intensive language classes.

00:37:46.030 --> 00:37:48.842
Or at least,
you better find a teammate who isn't.

00:37:48.842 --> 00:37:52.375
&gt;&gt; [LAUGH]
&gt;&gt; Okay, yeah, so

00:37:52.375 --> 00:37:55.672
we've got some late days.

00:37:55.672 --> 00:38:04.150
Note that each assignment has to be handed
in within three days so we can grade it.

00:38:05.670 --> 00:38:12.090
Yeah, okay, yeah, so Assignment 1,
we're gonna hand out on Thursday,

00:38:13.190 --> 00:38:17.060
so for that assignment,
it's gonna be pure Python, except for

00:38:17.060 --> 00:38:22.130
using the NumPy library, which is kinda
the basic vector and matrices library.

00:38:22.130 --> 00:38:27.010
And people are gonna do things
from scratch, because I think

00:38:27.010 --> 00:38:31.770
it's a really important educational skill
that you've actually done things and

00:38:31.770 --> 00:38:33.840
gotten it to work from scratch.

00:38:33.840 --> 00:38:34.650
And you really know for

00:38:34.650 --> 00:38:38.030
yourself what the derivatives
are because you've calculated them.

00:38:38.030 --> 00:38:41.974
And because you've implemented them,
and you've found that you can calculate

00:38:41.974 --> 00:38:45.802
derivatives and implement them, and
the thing does actually learn and work.

00:38:45.802 --> 00:38:47.068
If you've never done this,

00:38:47.068 --> 00:38:50.100
the whole thing's gonna seem
like black magic ever after.

00:38:50.100 --> 00:38:53.085
So it's really important to actually
work through it by yourself.

00:38:53.085 --> 00:38:57.762
But nevertheless, one of what things
that's being transforming deep learning is

00:38:57.762 --> 00:39:00.834
that there are now these
very good software packages,

00:39:00.834 --> 00:39:04.669
which actually make it crazily easy
to build deep learning models.

00:39:04.669 --> 00:39:09.219
That you can literally take one of these
libraries and sort of write 60 lines

00:39:09.219 --> 00:39:13.910
of Python, and you can be training
a state-of-the-art deep learning system

00:39:13.910 --> 00:39:18.261
that will work super well, providing
you've got the data to train it on.

00:39:18.261 --> 00:39:21.515
And that's sort of actually been
an amazing development over

00:39:21.515 --> 00:39:22.930
the last year or two.

00:39:22.930 --> 00:39:26.070
And so for Assignments 2 and
3, we're gonna be doing that.

00:39:26.070 --> 00:39:29.800
In particular, we're gonna be using
TensorFlow, which is the Google

00:39:29.800 --> 00:39:34.620
deep learning library, which is sort of,
well, Google's very close to us.

00:39:34.620 --> 00:39:36.757
But it's also very well engineered and

00:39:36.757 --> 00:39:39.487
has sort of taken off as
the most used library now.

00:39:39.487 --> 00:39:42.640
But there really are a whole bunch of
other good libraries for deep learning.

00:39:42.640 --> 00:39:44.310
And I mentioned some of them below.

00:39:45.440 --> 00:39:51.610
Okay, do people have any
questions on class organization?

00:39:51.610 --> 00:39:54.671
Or anything else up until now,
or do I just power on?

00:39:56.926 --> 00:40:02.500
&gt;&gt; [INAUDIBLE]
&gt;&gt; Yeah Okay, so, and something

00:40:02.500 --> 00:40:07.250
I'm gonna do is repeat all questions,
so they'll actually work on the video.

00:40:07.250 --> 00:40:10.482
So, the question is, how are our
assignments gonna be submitted?

00:40:10.482 --> 00:40:13.830
They're gonna be submitted
electronically online,

00:40:13.830 --> 00:40:16.460
instructions will be on
the first assignment.

00:40:16.460 --> 00:40:21.270
But yeah, everything has to be electronic,
what we use in Gradescope for the grading.

00:40:21.270 --> 00:40:24.070
For written stuff, if you wanna hand
write it, you have to scan it for

00:40:24.070 --> 00:40:26.090
yourself, and submit it online.

00:40:27.460 --> 00:40:28.385
Any other questions?

00:40:28.385 --> 00:40:30.752
&gt;&gt; [INAUDIBLE]
&gt;&gt; Yeah.

00:40:33.426 --> 00:40:35.950
So, the question was,
are the slides on the website?

00:40:35.950 --> 00:40:36.590
Yes, they are.

00:40:36.590 --> 00:40:41.350
The slides were on the website before
the class began, and we're gonna try and

00:40:41.350 --> 00:40:43.510
keep that up all quarter.

00:40:43.510 --> 00:40:47.782
So, you should just be able to find them,
cs224n.stanford.edu.

00:40:47.782 --> 00:40:49.574
Any other questions, yeah?

00:40:56.703 --> 00:41:00.940
Yeah, so that was on the logistics,
if you're doing assignment four.

00:41:00.940 --> 00:41:04.990
It's partly different, and partly
the same, so if you're doing the default

00:41:04.990 --> 00:41:09.190
assignment four, and we'll talk all about
final projects in a couple of weeks.

00:41:09.190 --> 00:41:14.370
You don't have to write a final
project proposal, or talk to a mentor,

00:41:14.370 --> 00:41:21.800
because we've designed the project for you
as a starting off point of the project.

00:41:21.800 --> 00:41:24.730
But on the other hand,
otherwise, it's the same.

00:41:24.730 --> 00:41:27.860
So, it's gonna be an open ended project,

00:41:27.860 --> 00:41:31.980
in which there are lots of things that you
can try to make the system better, and

00:41:31.980 --> 00:41:35.860
we want you to try, and we want you to be
able to report on what are the different

00:41:35.860 --> 00:41:38.990
exciting things you've tried, whether they
did, or didn't make your system better.

00:41:38.990 --> 00:41:44.850
And so, we will be expecting people doing
assignment four to also write up and

00:41:44.850 --> 00:41:46.550
present a poster on what they've done.

00:41:48.130 --> 00:41:48.884
Any other questions?

00:41:50.985 --> 00:41:56.666
Yes, so their question was on
whether we're using Piazza.

00:41:56.666 --> 00:41:59.590
Yes, we're using Piazza for communication.

00:41:59.590 --> 00:42:04.530
So, we've already setup the Piazza, and
we attempted to enroll all the enrolled

00:42:04.530 --> 00:42:09.280
students, so hopefully if you're
an involved student, there's somewhere in

00:42:09.280 --> 00:42:14.680
your junk mailbox, or in one of those
places, a copy of a Piazza announcement.

00:42:14.680 --> 00:42:15.600
Any other questions?

00:42:20.463 --> 00:42:22.680
Okay, 20 some minutes to go.

00:42:22.680 --> 00:42:23.540
I'll power ahead.

00:42:24.920 --> 00:42:28.620
Very quickly, why is NLP hard?

00:42:28.620 --> 00:42:33.210
I think most people,
maybe especially computer scientist,

00:42:33.210 --> 00:42:37.360
going into this just don't
understand why NLP is hard.

00:42:37.360 --> 00:42:41.570
It's just a sequence of words, and they've
been dealing with programming languages.

00:42:41.570 --> 00:42:45.310
And you're just gonna read
the sequence the words.

00:42:45.310 --> 00:42:47.010
Why is this hard?

00:42:47.010 --> 00:42:50.210
It turns out it's hard for
a bunch of reasons,

00:42:50.210 --> 00:42:53.478
because human languages aren't
like programming languages.

00:42:53.478 --> 00:42:59.310
So, human languages
are just all ambiguous.

00:42:59.310 --> 00:43:02.610
Programming languages
are constructed to be unambiguous,

00:43:02.610 --> 00:43:05.230
that's why they have rules like you can.

00:43:05.230 --> 00:43:07.260
And else goes with the nearest 'if' and

00:43:07.260 --> 00:43:10.330
you have to get the indentation
right in Python.

00:43:10.330 --> 00:43:16.220
Human languages aren't like that,
so human languages are when there's

00:43:16.220 --> 00:43:22.115
an 'else' just interpret it with whatever
'if' makes most sense to the hearer.

00:43:22.115 --> 00:43:26.823
And when we do reference
in programming language,

00:43:26.823 --> 00:43:31.748
we use variable names like x and
y, and this variable.

00:43:31.748 --> 00:43:36.422
Whereas, in human languages, we say
things like this and that and she, and

00:43:36.422 --> 00:43:41.900
you're just meant to be able to figure out
from context who's being talked about.

00:43:41.900 --> 00:43:46.560
But that's a big problem, but it's
perhaps, not even the biggest problem.

00:43:46.560 --> 00:43:49.950
The biggest problem is that humans

00:43:49.950 --> 00:43:53.130
use language as an efficient
communication system.

00:43:53.130 --> 00:43:57.960
And the way they do that is by
not saying most things, right?

00:43:57.960 --> 00:44:02.680
When you write a program, we say
everything that's needed to get it to run.

00:44:02.680 --> 00:44:07.670
Where in a human language, you leave out
most of the program, because you think

00:44:07.670 --> 00:44:12.260
that your listener will be able to work
out which code should be there, right?

00:44:12.260 --> 00:44:15.670
So, it's sorta more a code
snippet on StackOverflow, and

00:44:15.670 --> 00:44:19.730
the listener is meant to be able to
fill in the rest of the program.

00:44:19.730 --> 00:44:22.435
So, human language gets its efficiency.

00:44:22.435 --> 00:44:26.060
We kinda actually communicate very
fast by human language, right?

00:44:26.060 --> 00:44:28.107
The rate at which we can speak.

00:44:28.107 --> 00:44:33.017
It's not 5G communications speeds, right?

00:44:33.017 --> 00:44:35.000
It's a slow communication channel.

00:44:35.000 --> 00:44:39.650
But the reason why it works efficiently
is we can say minimal messages.

00:44:39.650 --> 00:44:43.730
And our listener fills in all
the rest with their world knowledge,

00:44:43.730 --> 00:44:47.330
common sense knowledge, and
contextual knowledge of the situation.

00:44:47.330 --> 00:44:51.900
And that's the biggest reason
why natural language is hard.

00:44:51.900 --> 00:44:56.579
So, as sort of a profound version
of why natural language is hard: I

00:44:56.579 --> 00:45:01.339
really like this XKCD cartoon, but
you definitely can't read, and

00:45:01.339 --> 00:45:04.665
I can barely read on
the computer in front of me.

00:45:04.665 --> 00:45:06.570
&gt;&gt; [LAUGH]
&gt;&gt; But I think if you think about it,

00:45:06.570 --> 00:45:12.870
it says actually a lot about why
natural language understanding is hard.

00:45:12.870 --> 00:45:16.320
So, the two women speaking to each other.

00:45:16.320 --> 00:45:20.510
One says, 'anyway, I could care less,' and
the other one says,

00:45:20.510 --> 00:45:25.110
'I think you mean you couldn't care less,
saying you could care less

00:45:25.110 --> 00:45:29.640
implies you care to some extent,' and
the other one says,

00:45:29.640 --> 00:45:35.175
'I don't know,' and then continues.

00:45:36.280 --> 00:45:40.360
We're these unbelievably complicated
beings drifting through a void,

00:45:40.360 --> 00:45:43.170
trying in vain to connect
with one another by

00:45:43.170 --> 00:45:46.220
blindly flinging words
out in to the darkness.

00:45:46.220 --> 00:45:48.750
Every trace of phrasing,
and spelling and tone and

00:45:48.750 --> 00:45:53.300
timing carries countless signals and
contexts and subtexts and more.

00:45:53.300 --> 00:45:57.030
And every listener interprets
these signals in their own way.

00:45:57.030 --> 00:46:01.770
Language isn't a formal system of
language, it's glorious chaos.

00:46:01.770 --> 00:46:05.390
You can never know for
sure what any words will mean to anyone.

00:46:05.390 --> 00:46:09.930
All you can do is try to get better at
guessing how your words affect people.

00:46:09.930 --> 00:46:12.780
So, you have a chance of finding
the ones that will make them

00:46:12.780 --> 00:46:15.680
feel something like you want them to feel.

00:46:15.680 --> 00:46:18.030
Everything else is pointless.

00:46:18.030 --> 00:46:21.480
I assume you're giving me tips
on how you interpret words,

00:46:21.480 --> 00:46:23.763
because you want me to feel less alone.

00:46:23.763 --> 00:46:27.122
If so, then thank you, that means a lot.

00:46:27.122 --> 00:46:30.919
But if you're just running my sentences
passed some mental check list, so

00:46:30.919 --> 00:46:34.275
you can show off how well you know it,
then I could care less.

00:46:34.275 --> 00:46:39.337
&gt;&gt; [LAUGH]
&gt;&gt; And I think if you reflect on this XKCD

00:46:39.337 --> 00:46:44.432
comic, there's actually a lot of
profound content there as to what human

00:46:44.432 --> 00:46:49.377
language understanding is like, and
what the difficulties of it are.

00:46:49.377 --> 00:46:52.317
But that's probably a bit
hard to do in detail, so

00:46:52.317 --> 00:46:56.120
I'm just gonna show you some
simple examples for a minute.

00:46:56.120 --> 00:47:02.550
You get lots of ambiguities, including
funny ambiguities, in natural language.

00:47:02.550 --> 00:47:04.770
So, here are a couple of,

00:47:04.770 --> 00:47:09.650
here's one of my favorites that came
out recently from TIME magazine.

00:47:10.690 --> 00:47:15.665
The Pope's baby steps on gays, no, that's
not how you meant to interpret this.

00:47:15.665 --> 00:47:21.923
You're meant to interpret this as
the Pope's baby steps on gays.

00:47:21.923 --> 00:47:30.486
&gt;&gt; [LAUGH]
&gt;&gt; Okay.

00:47:33.168 --> 00:47:39.000
So a question, I mean,
why do you get those two interpretations?

00:47:39.000 --> 00:47:43.136
What is it about human language,
and English here,

00:47:43.136 --> 00:47:48.407
about English that allows you to
have these two interpretations?

00:47:48.407 --> 00:47:51.334
What are the different things going on?

00:47:51.334 --> 00:47:55.400
Is anyone game to give
an explanation of how we

00:48:18.943 --> 00:48:22.220
Okay, yeah, right.

00:48:22.220 --> 00:48:24.300
I'll repeat the explanation as I go.

00:48:24.300 --> 00:48:28.610
You started off with saying it
was idiomatic, and some sense,

00:48:28.610 --> 00:48:32.040
baby steps is sort of an,
sort of a metaphor,

00:48:32.040 --> 00:48:37.780
an idiom where baby steps is meaning
little steps like a baby would take,

00:48:37.780 --> 00:48:42.090
but I mean, before you even get to that,
you can kind of just think a large part of

00:48:42.090 --> 00:48:46.570
this is just a structural ambiguity,
which then governs the rest of it.

00:48:46.570 --> 00:48:51.520
So, one choice Is that you have this
noun phrase of the Pope's baby, and

00:48:51.520 --> 00:48:54.210
then you start interpreting
it as a real baby.

00:48:54.210 --> 00:48:58.140
And then steps is being
interpreted as a verb.

00:48:58.140 --> 00:49:01.926
So, something we find in a lot
of languages, including English,

00:49:01.926 --> 00:49:05.252
is the same word can have
fundamentally different roles.

00:49:05.252 --> 00:49:11.132
He, and the verbal interpretation verb,
steps would be being used as a verb.

00:49:11.132 --> 00:49:14.928
But the other reading is as you
said it's a noun compound, so

00:49:14.928 --> 00:49:19.245
you can put nouns together, and make
noun compounds very freely in English.

00:49:19.245 --> 00:49:22.790
Computer people do it all the time, right?

00:49:22.790 --> 00:49:27.910
As soon as you've got something like disk
drive enclosure, or network interface hub,

00:49:27.910 --> 00:49:32.670
or something like that, you're just
nailing nouns together to make big nouns.

00:49:32.670 --> 00:49:36.702
So, you can put together baby and
steps as two nouns, and

00:49:36.702 --> 00:49:39.059
make baby steps as a noun phrase.

00:49:39.059 --> 00:49:43.232
And then you can make the Pope's
baby steps is a larger noun phrase.

00:49:43.232 --> 00:49:45.990
And then you're getting this
very different interpretation.

00:49:45.990 --> 00:49:50.510
But simultaneously, at the same time,
you're also changing the meaning of baby.

00:49:50.510 --> 00:49:54.770
So in one case, the baby was this
metaphorical baby, and then in the other

00:49:54.770 --> 00:50:01.740
one it's a perhaps counter-factually
it's a literal baby.

00:50:01.740 --> 00:50:04.132
Let's do at least one more of that.

00:50:04.132 --> 00:50:07.380
Here's another good fun one.

00:50:07.380 --> 00:50:10.791
Boy paralyzed after tumor
fights back to gain black belt.

00:50:10.791 --> 00:50:13.128
&gt;&gt; [LAUGH]
&gt;&gt; Which is, again,

00:50:13.128 --> 00:50:15.640
not how you're meant to read it.

00:50:15.640 --> 00:50:19.000
You're meant to read it as boy,

00:50:19.000 --> 00:50:23.360
paralyzed after tumor,
fights back to gain black belt.

00:50:23.360 --> 00:50:26.535
So, how could we characterize
the ambiguity in that one?

00:50:31.891 --> 00:50:37.913
[LAUGH] So,
someone suggested missing punctuation,

00:50:37.913 --> 00:50:42.590
and if, to some extent, that's true.

00:50:42.590 --> 00:50:45.833
And to some extent,
you can use commas to try and

00:50:45.833 --> 00:50:48.444
make readings clearer in some cases.

00:50:48.444 --> 00:50:53.402
But there are lots of places where
there are ambiguities in language,

00:50:53.402 --> 00:50:59.133
where it's just not usual standard to
put in punctuation, to disambiguate.

00:50:59.133 --> 00:51:03.959
And indeed, if you're the kind of computer
scientist who feels like you want to start

00:51:03.959 --> 00:51:08.585
putting matching parentheses around pieces
of human language to make the unclear

00:51:08.585 --> 00:51:13.325
interpretation much clearer, you're not
then a typical language user anymore.

00:51:13.325 --> 00:51:17.240
[LAUGH]
&gt;&gt; Okay, anyone else gonna have a go,

00:51:17.240 --> 00:51:17.756
yeah?

00:51:28.037 --> 00:51:35.315
Yeah, so, this is sort of the ambiguities
are in the syntax of the sentence.

00:51:35.315 --> 00:51:38.455
So, when you have this 'paralyzed'
that could either be the main

00:51:38.455 --> 00:51:40.937
verb of the sentence, so.

00:51:40.937 --> 00:51:46.347
The boy is paralyzed, then all of
after tumor fights back to gain black

00:51:46.347 --> 00:51:51.437
belt is then this sort of subordinate
clause of saying when it happened.

00:51:51.437 --> 00:51:57.167
And so then the 'tumor' is
the subject of 'fights back',

00:51:57.167 --> 00:52:03.080
or you can have this
alternative where 'paralyzed'

00:52:03.080 --> 00:52:07.560
can also be what's called
a passive participle.

00:52:07.560 --> 00:52:13.080
So, it's introducing a participial
phrase of 'paralyzed after tumor'.

00:52:13.080 --> 00:52:18.310
And so that can then be a modifier of
the boy in the same way an adjective can,

00:52:18.310 --> 00:52:21.190
young boy fights back to gain black belt.

00:52:21.190 --> 00:52:25.710
It could be boy paralyzed after tumor
fights back to gain black belt.

00:52:25.710 --> 00:52:28.210
And then it's the boy that's
the subject of fights.

00:52:29.450 --> 00:52:33.650
Okay, I have on this slide a couple more
examples, but I think I won't go through

00:52:33.650 --> 00:52:40.050
them in detail, since I'm sort
of behind as things are going.

00:52:40.050 --> 00:52:44.510
Okay, so what I wanted to
get into a little bit of for

00:52:46.040 --> 00:52:49.270
the last bit of class
until my time runs out

00:52:49.270 --> 00:52:54.660
is to introduce this idea
of deep learning and NLP.

00:52:54.660 --> 00:52:57.950
And so, I mean essentially,
this is combining

00:52:57.950 --> 00:53:03.240
the two things that we've been talking
about so far, deep learning and NLP.

00:53:03.240 --> 00:53:06.390
So, we're going to use the ideas
of deep learning, neural networks,

00:53:06.390 --> 00:53:09.670
representation learning, and
we're going to apply them to

00:53:09.670 --> 00:53:14.490
problems in language understanding,
natural language processing.

00:53:14.490 --> 00:53:16.790
And so, in the last couple of years,

00:53:16.790 --> 00:53:21.220
especially this is just an area that's
sorta really starting to take off,

00:53:21.220 --> 00:53:25.550
and just for the rest of today's
class we'll say, a little bit

00:53:25.550 --> 00:53:30.120
about what are some of the stuff happening
where they're at a very high level and

00:53:30.120 --> 00:53:35.726
that'll sort of prepare for Thursday,
starting to dive right into the specifics.

00:53:35.726 --> 00:53:40.310
And so, that, so

00:53:40.310 --> 00:53:45.100
there is so different,
different classifications you can look at.

00:53:45.100 --> 00:53:49.510
So on the one hand, deep learning is being
applied to lots of different levels of

00:53:49.510 --> 00:53:53.336
language that things like speech words,
syntax, semantics.

00:53:53.336 --> 00:53:57.348
It's been applied to lots of different
sort of tools, algorithms that we use for

00:53:57.348 --> 00:53:59.240
natural language processing.

00:53:59.240 --> 00:54:04.160
So, that's things like labeling words for
part-of-speech, finding person and

00:54:04.160 --> 00:54:08.900
organization names, or coming up with
syntactic structures of sentences.

00:54:08.900 --> 00:54:11.420
And then it's been applied to lots of

00:54:11.420 --> 00:54:14.140
language applications that
put a lot of this together.

00:54:14.140 --> 00:54:18.440
So things that I've mentioned before, like
machine translation, sentiment analysis,

00:54:18.440 --> 00:54:19.780
dialogue agents.

00:54:19.780 --> 00:54:24.810
And one of the really, really interesting
things is that deep learning models have

00:54:24.810 --> 00:54:30.310
been giving a very unifying method
of using the same tools and

00:54:30.310 --> 00:54:34.160
technologies to understand
a lot of these problems.

00:54:34.160 --> 00:54:37.610
So yes, there are some specifics
of different problems.

00:54:37.610 --> 00:54:41.670
But something that's been quite stunning
in the development of deep learning is

00:54:41.670 --> 00:54:47.560
that there's actually been a very
small toolbox of key techniques,

00:54:47.560 --> 00:54:51.140
which have turned out to
be just vastly applicable

00:54:51.140 --> 00:54:55.380
with enormous accuracy to just many,
many problems.

00:54:55.380 --> 00:55:00.270
Which actually includes not only many,
many language problems, but also,

00:55:00.270 --> 00:55:03.429
most of the rest of what
happens in deep learning,

00:55:03.429 --> 00:55:08.395
whether it's looking at vision problems,
or applying deep learning through

00:55:08.395 --> 00:55:12.684
any other kind of signal analysis,
knowledge representation, or

00:55:12.684 --> 00:55:17.679
anything that you see these few key tools
being used to solve all the problems.

00:55:17.679 --> 00:55:22.671
And what is somewhat embarrassing for
human beings part is that typically,

00:55:22.671 --> 00:55:25.167
they're sort of working super well,

00:55:25.167 --> 00:55:30.315
much better than the techniques that
human beings had previously slaved on for

00:55:30.315 --> 00:55:35.486
decades developing, without very much
customization for different tasks.

00:55:35.486 --> 00:55:42.577
Okay, so deep learning and language it
all starts off with word meaning, and so

00:55:42.577 --> 00:55:49.620
this is a very central idea gonna develop
starting off with the second class.

00:55:49.620 --> 00:55:55.740
So, what we're gonna do with words is
say were going to represent a word,

00:55:55.740 --> 00:55:58.820
in particular we're going to
represent the meaning of the word.

00:55:58.820 --> 00:56:00.430
As a vector of your numbers.

00:56:00.430 --> 00:56:04.050
So here's my vector for the word expect.

00:56:04.050 --> 00:56:07.130
And so I made that, whatever it is,
an 8-dimensional vector,

00:56:07.130 --> 00:56:10.080
I think, since that was good for my slide.

00:56:10.080 --> 00:56:12.831
But really,
we don't use much that small vectors.

00:56:12.831 --> 00:56:17.840
So minimally, we might use something
like 25-dimensional vectors.

00:56:17.840 --> 00:56:21.970
Commonly, we might be using something
like 300-dimensional vectors.

00:56:21.970 --> 00:56:23.640
And if we're really going to town

00:56:24.720 --> 00:56:27.570
because we wanna have the best
ever system doing something,

00:56:27.570 --> 00:56:31.290
we might be using a 1000-dimensional
vector or something like that.

00:56:31.290 --> 00:56:34.060
So when we have vectors for words,

00:56:34.060 --> 00:56:38.320
that means we're placing words in
a high-dimensional vector space.

00:56:38.320 --> 00:56:43.620
And what we find out is,
when we have these methods for

00:56:43.620 --> 00:56:47.365
learning word vectors from deep
learning and place words into these

00:56:47.365 --> 00:56:52.840
high-dimensional vector spaces,
these act as wonderful semantic spaces.

00:56:52.840 --> 00:56:57.620
So, words with similar meanings will
cluster together in the vector space, but

00:56:57.620 --> 00:56:58.790
actually more than that.

00:56:58.790 --> 00:57:01.760
We'll find out that there
are directions in the vector space

00:57:01.760 --> 00:57:04.740
that actually tell you about
components and meaning.

00:57:04.740 --> 00:57:08.200
So we, one of the problems of
human beings is that they're not

00:57:08.200 --> 00:57:11.430
very good at looking at
high-dimensional spaces.

00:57:11.430 --> 00:57:14.510
So, for the human beings,
we always have to project down onto two or

00:57:14.510 --> 00:57:15.810
three dimensions.

00:57:15.810 --> 00:57:20.330
And so, in the background,
you can see a little bit of a word cloud

00:57:20.330 --> 00:57:25.420
of a 2D projection of a word vector space,
which you can't read at all.

00:57:25.420 --> 00:57:29.570
But we could sort of
start to zoom in on it.

00:57:29.570 --> 00:57:32.400
And then you get something
that's just about readable.

00:57:32.400 --> 00:57:38.312
So in one part of the space, this is
where country words are clustering.

00:57:38.312 --> 00:57:42.589
And in another part of the space, this
is where you're seeing verbs clustering.

00:57:42.589 --> 00:57:47.200
And you're seeing kind of it's grouping
together verbs that mean most similarly.

00:57:47.200 --> 00:57:51.200
So 'come' and 'go' are very similar,
'say' and 'think' are similar, 'think' and

00:57:51.200 --> 00:57:52.510
'expect' are similar.

00:57:53.630 --> 00:57:57.000
'Expecting' and 'thinking' are actually
similar to 'seeing things' a lot of

00:57:57.000 --> 00:57:59.860
the time, because people often
use see as an analogy for think.

00:58:00.940 --> 00:58:01.440
Yes?

00:58:11.980 --> 00:58:15.813
Okay, so the question is, what do
the axes in these vector spaces mean?

00:58:15.813 --> 00:58:21.220
And, in some sense,
the glib answer is nothing.

00:58:21.220 --> 00:58:26.030
So when we learn these vector spaces,
well actually we have these 300 D vectors.

00:58:26.030 --> 00:58:29.800
And they have these axes
corresponding to those vectors.

00:58:29.800 --> 00:58:34.730
And often in practice, we do sort of
look at some of those elements in

00:58:34.730 --> 00:58:38.388
along the axes and see if we can
interpret them because it's easy to do.

00:58:38.388 --> 00:58:43.168
But really, there's no particular
reason to think that elements and

00:58:43.168 --> 00:58:45.250
meaning should follow those vector lines.

00:58:45.250 --> 00:58:48.490
They could be any other angle
in the vector space, and so

00:58:48.490 --> 00:58:50.980
they don't necessarily mean anything.

00:58:50.980 --> 00:58:55.990
When we wanna do a 2D projection
like this, what we're then using

00:58:55.990 --> 00:59:00.390
is some method to try and
most faithfully get out some of

00:59:00.390 --> 00:59:04.940
the main meaning from the high dimensional
vector space so we can show it to you.

00:59:04.940 --> 00:59:09.190
So the simplest method that many of you
might have seen before in other places,

00:59:09.190 --> 00:59:13.000
is doing PCA,
doing a principal components analysis.

00:59:13.000 --> 00:59:16.120
There's another method that we'll get
to called t-SNE, which is kind of

00:59:16.120 --> 00:59:20.560
a non-linear dimensionality
reduction which is commonly used.

00:59:20.560 --> 00:59:25.760
But these are just to try and give human
beings some sense of what's going on.

00:59:25.760 --> 00:59:30.090
And it's important to realize that any
of these low dimensional projections

00:59:30.090 --> 00:59:33.010
can be extremely,
extremely misleading, right?

00:59:33.010 --> 00:59:37.110
Because they are just leaving out
a huge amount of the information

00:59:37.110 --> 00:59:40.520
that's actually in the vector space.

00:59:40.520 --> 00:59:45.455
Here's, I'm just looking at closest words,
to the word frog.

00:59:45.455 --> 00:59:48.845
I'm using the GLOVE embeddings that we did
at Stanford and we'll talk about more,

00:59:48.845 --> 00:59:50.685
in the next couple of lectures.

00:59:50.685 --> 00:59:55.336
So frogs and toad are the nearest words,
which looks good.

00:59:55.336 --> 00:59:59.842
But if we then look at these other
words that we don't understand,

00:59:59.842 --> 01:00:04.598
it turns out that they're also names for
other pretty kinds of frogs.

01:00:04.598 --> 01:00:10.160
So these word meaning vectors are a great
basis of starting to do things.

01:00:10.160 --> 01:00:11.740
But I just wanna give you a sense, for

01:00:11.740 --> 01:00:15.250
the last few minutes,
that we can do a lot beyond that.

01:00:15.250 --> 01:00:19.260
And the surprising thing is we're gonna
keep using some of these vectors.

01:00:19.260 --> 01:00:24.710
So traditionally, if we're looking at
complex words like uninterested, we might

01:00:24.710 --> 01:00:30.500
just think of them as being made up as
morphemes of sort of smaller symbols.

01:00:30.500 --> 01:00:33.170
But what we're gonna do is say, well no.

01:00:33.170 --> 01:00:35.780
We can also think of parts of words

01:00:35.780 --> 01:00:40.550
as vectors that represent
the meaning of those parts of words.

01:00:40.550 --> 01:00:45.310
And then what we'll wanna do is build
a neural network which can compose

01:00:45.310 --> 01:00:50.680
the meaning of larger units
out of these smaller pieces.

01:00:50.680 --> 01:00:55.150
That was work that Minh-Thang Luong and
Richard did a few years ago at Stanford.

01:00:56.280 --> 01:01:01.540
Going beyond that, we want to
understand the structure of sentences.

01:01:01.540 --> 01:01:05.450
And so another tool we'll use
deep learning for is to make

01:01:06.570 --> 01:01:11.342
syntactic pauses that find out
the structure of sentences.

01:01:11.342 --> 01:01:16.920
So Danqi Chen who's over there,
is one of the TAs for the class.

01:01:16.920 --> 01:01:22.240
So something that she worked on
a couple of years ago was doing neural

01:01:22.240 --> 01:01:25.080
network methods for dependency parsing.

01:01:25.080 --> 01:01:27.300
And that was hugely successful.

01:01:27.300 --> 01:01:31.630
And essentially, if you've seen any
of the recent Google announcements

01:01:31.630 --> 01:01:34.160
with their Parsey McParseface and
syntax net.

01:01:34.160 --> 01:01:37.720
That essentially what that's
using is a more honed and

01:01:37.720 --> 01:01:42.830
larger version of the technique
that Danqi introduced.

01:01:42.830 --> 01:01:46.230
So once we've got some of
the structure of sentences,

01:01:46.230 --> 01:01:51.740
we then might want to understand
the meaning of sentences.

01:01:51.740 --> 01:01:55.513
And people have worked on the meaning
of sentences for decades.

01:01:55.513 --> 01:02:00.063
And I certainly don't wanna
belittle other ways of working

01:02:00.063 --> 01:02:02.435
out the meaning of sentences.

01:02:02.435 --> 01:02:05.680
But in the terms of doing
deep learning for NLP,

01:02:05.680 --> 01:02:11.140
in this class I also wanna give a sense
of how we'll do things differently.

01:02:11.140 --> 01:02:16.228
So the traditional way of doing things,
which is commonly lambda calculus,

01:02:16.228 --> 01:02:19.760
calculus-based semantic theories.

01:02:19.760 --> 01:02:24.849
That you're giving meaning functions for
individual words by hand.

01:02:24.849 --> 01:02:28.994
And then there's a careful,
logical algebra for

01:02:28.994 --> 01:02:36.019
how you combine together the meanings of
words to get kind of semantic expressions.

01:02:36.019 --> 01:02:40.242
Which have also sometimes been used for
programming languages where people worked

01:02:40.242 --> 01:02:43.390
on denotational semantics for
programming languages.

01:02:43.390 --> 01:02:45.340
But that's not what we're gonna do here.

01:02:45.340 --> 01:02:50.574
What we're gonna do is say, well,
if we start off with the meaning of words

01:02:50.574 --> 01:02:55.829
being vectors, we'll make meanings for
phrases which are also vectors.

01:02:55.829 --> 01:02:57.818
And then we have bigger phrases and

01:02:57.818 --> 01:03:00.773
sentences also have their
meaning being a vector.

01:03:00.773 --> 01:03:04.946
And if we wanna know what
the relationships between meanings of

01:03:04.946 --> 01:03:09.669
sentences or between sentences and
the world, such as a visual scene,

01:03:09.669 --> 01:03:14.156
the way we'll do that is we'll try
to learn a neural network that can

01:03:14.156 --> 01:03:16.150
make those decisions for us.

01:03:19.412 --> 01:03:20.620
Yeah, let's see.

01:03:20.620 --> 01:03:25.130
So we can use it for
all kinds of semantics.

01:03:25.130 --> 01:03:28.560
This was actually one of the pieces
of work that Richard did while he was

01:03:28.560 --> 01:03:33.540
a PhD student,
was doing sentiment analysis.

01:03:33.540 --> 01:03:36.890
And so
this was trying to do a much better,

01:03:36.890 --> 01:03:40.110
careful, real meaning representation and

01:03:40.110 --> 01:03:44.440
understanding of the positive and
negative sentiments of sentences

01:03:44.440 --> 01:03:49.130
by actually working out which parts
of sentences have different meanings.

01:03:49.130 --> 01:03:55.100
So the sentences, This movie
doesn't care about cleverness, wit,

01:03:55.100 --> 01:03:59.950
or any other kind of intelligent humor,
and the system is actually very accurately

01:03:59.950 --> 01:04:04.740
able to work out, well there's all of
this positive stuff down here, right?

01:04:04.740 --> 01:04:07.260
There's cleverness,
wit, intelligent humor.

01:04:07.260 --> 01:04:11.330
It's all very positive, and that's
the kind of thing a traditional sentiment

01:04:11.330 --> 01:04:16.178
analysis system would fall apart on, and
just say this is a positive sentence.

01:04:16.178 --> 01:04:19.350
But our neural network system
is noticing that there's

01:04:19.350 --> 01:04:21.860
this movie doesn't care
at the beginning and

01:04:21.860 --> 01:04:25.930
is accurately deciding the overall
sentiment for the sentence is negative.

01:04:27.440 --> 01:04:32.140
Okay, I'm gonna run out of time, so
I'll skip a couple of things, but

01:04:32.140 --> 01:04:36.800
let me just mention two other
things that've been super exciting.

01:04:36.800 --> 01:04:42.760
So there's this enormous excitement
now about trying to build chat bots,

01:04:42.760 --> 01:04:44.140
dialogue agents.

01:04:44.140 --> 01:04:47.910
Of having speech and
language understanding interfaces

01:04:49.310 --> 01:04:52.456
that humans can interact
with mobile computers.

01:04:52.456 --> 01:04:56.155
There's Alexa and
other things like that with and

01:04:56.155 --> 01:05:01.395
I think it's fair to say that the state
of the technology at the moment

01:05:01.395 --> 01:05:05.615
is that speech recognition has
made humongous advances, right?

01:05:05.615 --> 01:05:10.480
So I mean, speech recognition
has been going on for decades,

01:05:10.480 --> 01:05:16.220
and as someone involved with language
technology, I'd been claiming to people,

01:05:16.220 --> 01:05:18.980
from the 1990s, no,
speech recognition is really good.

01:05:18.980 --> 01:05:21.650
We've worked out really good
speech recognition systems.

01:05:21.650 --> 01:05:27.040
But the fact of the matter is they were
sorta not very good and real human beings

01:05:27.040 --> 01:05:32.010
would not use them if they had any choice
because the accuracy was just so low.

01:05:32.010 --> 01:05:36.610
Whereas, in the last few years
neural network-based deep

01:05:36.610 --> 01:05:41.630
learning speech recognition systems
have become amazingly good.

01:05:41.630 --> 01:05:45.620
I think, I mean maybe this isn't true
of the young people in this room

01:05:45.620 --> 01:05:46.340
apart from me.

01:05:46.340 --> 01:05:51.270
But I think a lot of people don't actually
realize how good that they've gotten.

01:05:51.270 --> 01:05:56.870
Because I think that there are a lot of
people that try things out in 2012 and

01:05:56.870 --> 01:05:59.920
decide, they're pretty reasonable,
but not fantastic, and

01:05:59.920 --> 01:06:02.000
haven't really used it since.

01:06:02.000 --> 01:06:06.300
So I encourage all of you, if you don't
regularly use speech recognition to go

01:06:06.300 --> 01:06:09.765
home and
try saying some things to your phone.

01:06:09.765 --> 01:06:14.960
And, I think it's now just amazing how
well the speech recognition works.

01:06:14.960 --> 01:06:16.460
But there's a problem.

01:06:16.460 --> 01:06:19.420
The speech recognition works flawlessly.

01:06:19.420 --> 01:06:23.660
And then your phone has no idea
what you're saying, and so it says,

01:06:23.660 --> 01:06:25.960
would you like me to Google that for you?

01:06:25.960 --> 01:06:28.080
So the big problem, and

01:06:28.080 --> 01:06:32.280
the centerpiece of the kind of stuff that
we're working on in this class, is well

01:06:32.280 --> 01:06:36.420
how can we actually make the natural
language understanding equally good?

01:06:36.420 --> 01:06:40.586
And so that's a big concentration
that what we're going to work on.

01:06:40.586 --> 01:06:42.923
One place that's actually,

01:06:42.923 --> 01:06:48.740
have any of you played with
Google's Inbox program on cell phones?

01:06:48.740 --> 01:06:49.630
Any of you tried that out?

01:06:49.630 --> 01:06:52.110
A few of you have.

01:06:52.110 --> 01:06:57.129
So one cool but
very simple example of a deployed deep

01:06:57.129 --> 01:07:03.418
learning dialogue agent is
Google Inbox's Suggested Replies.

01:07:03.418 --> 01:07:08.826
So you having recurrent neural network
that's going through the message and

01:07:08.826 --> 01:07:14.650
is then suggesting three replies to your
message to send back to the other person.

01:07:14.650 --> 01:07:19.600
And you know although there are lots
of concerns in that program of sort of

01:07:19.600 --> 01:07:22.690
privacy and other things, and
they're careful how they're doing it.

01:07:22.690 --> 01:07:26.770
Actually often the replies it comes
up with are really rather good.

01:07:26.770 --> 01:07:31.420
If you're looking to cut down on your
email load, give Google Inbox a try and

01:07:31.420 --> 01:07:35.700
you might find that actually you can reply
to quite a bit of your email using it.

01:07:36.990 --> 01:07:41.570
Okay, the one other example I
wanted to mention before finishing

01:07:41.570 --> 01:07:43.860
was Machine Translation.

01:07:43.860 --> 01:07:48.050
So Machine Translation, this is actually
when natural language processing started.

01:07:48.050 --> 01:07:51.185
It didn't actually start with
language understanding in general.

01:07:51.185 --> 01:07:57.330
Where natural language processing started
was, it was the beginning of the Cold War.

01:07:57.330 --> 01:08:01.867
Americans and Russians alarmed that each
other knew too much about something they

01:08:01.867 --> 01:08:04.573
couldn't understand what
people were saying.

01:08:04.573 --> 01:08:08.898
And coming off of the successes
of code breaking in World War II,

01:08:08.898 --> 01:08:14.570
people thought, we can just get our
computers to do language translation.

01:08:14.570 --> 01:08:17.677
And in the early days it
worked really terribly, and

01:08:17.677 --> 01:08:22.548
things started to get a bit better in
the 2000s, and I presume you've all seen

01:08:22.548 --> 01:08:26.662
kind of classic Google Translate,
and that's a lot of half worked.

01:08:26.662 --> 01:08:31.170
You could sorta get the gist of what it's
saying, but it still worked very terribly.

01:08:31.170 --> 01:08:36.903
Whereas just in the last couple of
years really only starting in 2014,

01:08:36.903 --> 01:08:41.908
there's then started to be use of
end-to-end trained deep learning

01:08:41.908 --> 01:08:48.480
systems to do machine translation which is
then called neural machine translation.

01:08:48.480 --> 01:08:52.720
And it's certainly not the case that
all the problems in MT are solved,

01:08:52.720 --> 01:08:56.170
there's still lots of work to do
to improve machine translation.

01:08:56.170 --> 01:09:00.480
But again,
this is a case in which just overnight

01:09:00.480 --> 01:09:05.720
replacing the 200 person years
of work on Google Translate

01:09:05.720 --> 01:09:11.280
with a new deep learning based machine
translation system has overnight

01:09:11.280 --> 01:09:14.880
produced a huge improvement
in translation quality.

01:09:14.880 --> 01:09:17.460
And there was a big
long article about that

01:09:17.460 --> 01:09:22.140
in the New York Times magazine a few
weeks ago that you might've seen.

01:09:22.140 --> 01:09:26.742
And so rather than traditional
approaches to translation where

01:09:26.742 --> 01:09:31.598
again just running a big, deep,
recurrent neural network where

01:09:31.598 --> 01:09:36.370
it starts off reading through
a source sentence generating vector

01:09:36.370 --> 01:09:40.997
internal representations that
represent the sentence so far.

01:09:40.997 --> 01:09:44.093
And then once it's gone to
the end of the sentence,

01:09:44.093 --> 01:09:48.000
it then starts to generate
out words in the translation.

01:09:48.000 --> 01:09:51.190
So generating words in
sequence in the translation

01:09:51.190 --> 01:09:54.680
is then what's referred to as
kind of neural language models,

01:09:54.680 --> 01:09:58.660
and that is also a key technology that
we use in a lot of things that we do.

01:09:58.660 --> 01:10:03.812
So that's both what's used in
the kind of Google Inbox, recurrent

01:10:03.812 --> 01:10:08.800
neural network, and in the generation side
of a neural machine translation system.

01:10:09.920 --> 01:10:15.810
Okay, so we've gotten to,
I just have one more minute and

01:10:15.810 --> 01:10:18.820
try and get us out of here not too
late even though we started late.

01:10:18.820 --> 01:10:24.495
I mean, the final thing I want to
say it's just sort of to emphasize

01:10:24.495 --> 01:10:29.185
the fact the amazing thing that's
happening here is it's all vectors, right?

01:10:29.185 --> 01:10:33.604
We're using this for
all representations of language,

01:10:33.604 --> 01:10:38.390
whether it's sounds,
parts of words, words, sentences,

01:10:38.390 --> 01:10:44.481
conversations, they're all getting
turned into these real value vectors.

01:10:44.481 --> 01:10:46.942
And that's something that
we'll talk about a lot more.

01:10:46.942 --> 01:10:50.846
I'll talk about it for
word vectors on Thursday and

01:10:50.846 --> 01:10:55.406
Richard will talk a lot more
about the vectors next time.

01:10:55.406 --> 01:10:59.676
I mean, that's something that appalls many
people, but I think it's important to

01:10:59.676 --> 01:11:04.646
realize it's actually something a lot
more subtle than many people realize.

01:11:04.646 --> 01:11:08.850
You could think that there's no structure
in this big long vector of numbers.

01:11:08.850 --> 01:11:12.472
But equally you could say,
well I could reshape that vector and

01:11:12.472 --> 01:11:16.585
I could turn into a matrix or a higher
order array which we call a tensor.

01:11:16.585 --> 01:11:18.480
Or I could say different parts of it or

01:11:18.480 --> 01:11:21.910
directions of it represent
different kinds of information.

01:11:21.910 --> 01:11:24.560
It's actually a very
flexible data structure with

01:11:24.560 --> 01:11:26.990
huge representational capacity and

01:11:26.990 --> 01:11:33.130
that's what deep learning systems really
take advantage of in all that they do.

01:11:33.130 --> 01:11:34.006
Okay, thanks a lot.

01:11:35.393 --> 01:11:38.507
&gt;&gt; [APPLAUSE]

