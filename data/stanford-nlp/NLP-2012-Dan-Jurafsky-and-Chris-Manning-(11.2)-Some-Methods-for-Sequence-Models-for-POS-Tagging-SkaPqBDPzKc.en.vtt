WEBVTT
Kind: captions
Language: en

00:00:00.754 --> 00:00:05.614
Now let me return to part-of-speech taking
and say a little bit more about, how

00:00:05.614 --> 00:00:11.240
sequence models befall and what kind of
features end up being used and used for.

00:00:11.240 --> 00:00:14.937
So what are the main sources of
information part-of-speech taking?

00:00:16.080 --> 00:00:20.310
One source of information is
knowledge of neighboring words and

00:00:20.310 --> 00:00:24.190
their purpose of speech tags.

00:00:24.190 --> 00:00:26.220
Bill saw that man yesterday.

00:00:26.220 --> 00:00:28.700
We have a lot of part
of speech ambiguities.

00:00:28.700 --> 00:00:34.180
So, Bill can be either a proper noun or
a verb.

00:00:34.180 --> 00:00:38.180
Saw, can be either a noun or a verb.

00:00:38.180 --> 00:00:40.970
That, can be either a determiner,

00:00:40.970 --> 00:00:46.220
or what's tagged as IN when
introducing a complement clause.

00:00:46.220 --> 00:00:50.015
Man, can be a noun or a verb.

00:00:50.015 --> 00:00:53.449
But at this point we start to notice
that there are some constraints from

00:00:53.449 --> 00:00:54.317
neighborhoods.

00:00:54.317 --> 00:00:58.929
So it just can't be the case that,
that, is the determiner and

00:00:58.929 --> 00:01:01.110
it's followed by a verb.

00:01:01.110 --> 00:01:03.200
That this is a bad sequence.

00:01:03.200 --> 00:01:06.270
And so
this is sequence information that gives us

00:01:06.270 --> 00:01:09.240
some ideas as to how to
part-of-speech tag things.

00:01:09.240 --> 00:01:13.025
And when people started working
on part-of-speech tags,

00:01:13.025 --> 00:01:16.447
people thought of that as
the main source of evidence.

00:01:16.447 --> 00:01:19.460
But it turns out that
that's not really the case.

00:01:19.460 --> 00:01:24.690
That the easiest and
biggest source of evidence is statistics.

00:01:24.690 --> 00:01:28.910
Knowledge about how often words
have different parts of speech.

00:01:28.910 --> 00:01:33.511
So we can also get a long
way by just saying, man,

00:01:33.511 --> 00:01:36.329
is very rarely used as a verb.

00:01:36.329 --> 00:01:40.368
And therefore,
just without even looking at the context,

00:01:40.368 --> 00:01:44.747
we probably should take
the part-of-speech tag noun for man.

00:01:44.747 --> 00:01:49.359
And that latter source of
information proves most useful, but

00:01:49.359 --> 00:01:55.900
that's not to mean that the first source
of information isn't also useful.

00:01:55.900 --> 00:01:59.760
So what we're going to want to do is
start putting more and better features

00:01:59.760 --> 00:02:05.280
into our maximum entry tagger,
producing a feature based sequence model.

00:02:05.280 --> 00:02:10.460
And one part of that is just features
that we can find over the word itself.

00:02:10.460 --> 00:02:13.040
So knowing what the word is is useful, but

00:02:13.040 --> 00:02:17.464
it turns out you can get a lot of
further value, especially from rare and

00:02:17.464 --> 00:02:22.290
unknown words by also putting in features
that pick out properties of words.

00:02:22.290 --> 00:02:26.610
So, looking not just to the word,
but it's lower case form.

00:02:26.610 --> 00:02:30.950
So, maybe there are many words that we
haven't seen capitalized at the beginning

00:02:30.950 --> 00:02:33.714
of a sentence, but
if we know what their lower case form is,

00:02:33.714 --> 00:02:38.090
and its parts-of-speech are,
then that will help us.

00:02:38.090 --> 00:02:41.770
Knowing the beginning of a word,
so if you know a word starts with,

00:02:41.770 --> 00:02:45.990
un, that gives you a bit of information
about what its part-of-speech is.

00:02:45.990 --> 00:02:49.520
Knowing the suffix of a word,
so if you know a word ends in,

00:02:49.520 --> 00:02:53.170
ly, it's almost certainly
an adverb in English.

00:02:53.170 --> 00:02:55.852
Capitalization is useful.

00:02:55.852 --> 00:03:00.146
So in English, the capital letter,
once you're away from the beginning of

00:03:00.146 --> 00:03:03.660
the sentence, is a very good
clue that you gotta proper noun.

00:03:03.660 --> 00:03:07.170
And here's an interesting different
kind of feature that we've made a lot of

00:03:07.170 --> 00:03:09.500
use of in some of our Stanford systems.

00:03:09.500 --> 00:03:14.008
We call these word shape features, an idea
first suggested by Michael Collins.

00:03:14.008 --> 00:03:18.522
It's a different way at making features
from words that creates natural

00:03:18.522 --> 00:03:22.870
equivalent classes that is very useful for
generalization.

00:03:22.870 --> 00:03:27.840
And so the idea here is that you're
mapping a word into of the small

00:03:27.840 --> 00:03:31.090
set of equivalence classes
that represents its shape.

00:03:31.090 --> 00:03:34.850
So here what we're doing, and there are
different exact schemes that you can use.

00:03:34.850 --> 00:03:39.640
We can say, this is a digit character,
this is also a digit character.

00:03:39.640 --> 00:03:40.927
Let's collapse for

00:03:40.927 --> 00:03:45.322
our equivalence classing sequence
of characters that are the same.

00:03:45.322 --> 00:03:47.555
Then there's a hyphen here, and

00:03:47.555 --> 00:03:52.000
then we've got a sequence of
lower case letter characters.

00:03:52.000 --> 00:03:56.996
And so
we will give that the word shape of d-x.

00:03:56.996 --> 00:03:59.643
Some number of digit, followed by hyphen,

00:03:59.643 --> 00:04:02.750
followed some number
of lower case letters.

00:04:02.750 --> 00:04:06.010
And that kind of feature
proves to be a very useful

00:04:06.010 --> 00:04:09.300
feature in quite a few of
our discriminative models.

00:04:09.300 --> 00:04:11.450
So here's the headline, good news.

00:04:11.450 --> 00:04:15.219
If you get clever using all
these kinds of features and

00:04:15.219 --> 00:04:20.242
just build a model that looks at
the current word and assigns a tag to it,

00:04:20.242 --> 00:04:24.599
it turns out that without looking
at the context whatsoever,

00:04:24.599 --> 00:04:30.345
you can build a part of speech taker
that overall gets 93.7% of words right.

00:04:30.345 --> 00:04:33.271
And actually does quite well
on unknown words as well.

00:04:33.271 --> 00:04:37.862
Commonly we pull out separately the
accuracy of the unknown words because it's

00:04:37.862 --> 00:04:41.904
always lower and can be distinctively
different from the accuracy for

00:04:41.904 --> 00:04:43.620
known words.

00:04:43.620 --> 00:04:46.250
So here's some figures overall
just to give you a picture

00:04:46.250 --> 00:04:50.890
of the kind of accuracies you should be
expecting from part-of-speech taggers, and

00:04:50.890 --> 00:04:54.120
how different features
impact the classification.

00:04:54.120 --> 00:04:58.820
So we discussed before,
this idea of a baseline method

00:04:58.820 --> 00:05:03.430
of just giving the most frequent tag to
words and calling everything else a noun.

00:05:03.430 --> 00:05:04.770
So overall, that gives about 90%, but

00:05:04.770 --> 00:05:07.829
only gets about half of
the unknown words right.

00:05:09.170 --> 00:05:13.630
The next set of models that
people looked at were HMM models,

00:05:13.630 --> 00:05:17.130
hidden Markov models, which I'm not
really going to cover in this class.

00:05:17.130 --> 00:05:21.740
But this was in the mid-90s, the state
of art of part-of-speech tagging.

00:05:21.740 --> 00:05:25.399
And so
that got around 95% of all words right and

00:05:25.399 --> 00:05:29.370
did just a little bit
better on unknown words.

00:05:29.370 --> 00:05:33.590
We just saw, on the previous slide,
that just having a straight classifier,

00:05:33.590 --> 00:05:35.570
no sequence model, but

00:05:35.570 --> 00:05:39.560
with which carefully chosen features,
actually works rather well.

00:05:39.560 --> 00:05:42.370
It does much better on unknown words.

00:05:42.370 --> 00:05:47.364
And doesn't actually perform
badly on known words.

00:05:47.364 --> 00:05:49.140
But people have gone on from there.

00:05:50.320 --> 00:05:54.430
The idea that you could use features
to do a better job was able

00:05:54.430 --> 00:05:58.148
to be incorporated into
hidden Markov models as well.

00:05:58.148 --> 00:06:03.806
And so produced this high performance
hidden Markov model based tagger,

00:06:03.806 --> 00:06:08.580
which used feature-based ideas for
predicting unknown words.

00:06:08.580 --> 00:06:10.315
And that performed rather nicely.

00:06:10.315 --> 00:06:16.590
So it gets around 96.2% overall and very
competitive performance on unknown words.

00:06:16.590 --> 00:06:21.030
But you can keep on building features
into your maximum-entropy Markov model,

00:06:21.030 --> 00:06:24.950
including using context features that
we didn't have in the first model.

00:06:24.950 --> 00:06:29.798
So then if we go into sort of
a standard Markov marker model tagger,

00:06:29.798 --> 00:06:35.876
the kind we've discussed, that that might
be getting almost 97% on all words.

00:06:35.876 --> 00:06:40.670
And start doing better,
again, on unknown words.

00:06:40.670 --> 00:06:46.190
A network has been pushed up further at
several places, including at Stanford.

00:06:46.190 --> 00:06:50.990
So at Stanford, we have a model almost
like an maximum-entropy Markov model,

00:06:50.990 --> 00:06:54.500
but allows some
bidirectional dependencies.

00:06:54.500 --> 00:06:59.810
And so that's then pushing the overall
accuracy after about 97.2%.

00:06:59.810 --> 00:07:04.593
And pushing up the unknown word
accuracy further toward that 90%.

00:07:04.593 --> 00:07:09.026
And that's getting close to how good you
can expect part-of-speech taggers to

00:07:09.026 --> 00:07:09.630
perform.

00:07:09.630 --> 00:07:14.136
Because for reasons of humans themselves
not being sure of what the right answer is

00:07:14.136 --> 00:07:16.499
to a part-of-speech tagging problems.

00:07:16.499 --> 00:07:21.195
And also just because the gold standards
have errors because sometimes human's goof

00:07:21.195 --> 00:07:23.605
and put in the wrong part-of-speech tag,

00:07:23.605 --> 00:07:26.490
even when it seems like
the correct answer is clear.

00:07:26.490 --> 00:07:31.316
But it seems like around 98% is the upper
bound of what you could possibly

00:07:31.316 --> 00:07:36.970
hope to score on the kind of test sets
we have for part-of-speech tagging.

00:07:36.970 --> 00:07:41.553
And if one wants to keep on working on
improving things, normally the way one

00:07:41.553 --> 00:07:46.421
goes about that is by staring hard at
the output of your part-of-speech tag, or

00:07:46.421 --> 00:07:47.437
whatever it is.

00:07:47.437 --> 00:07:52.201
And looking at where it makes errors and
thinking of ways in which you could encode

00:07:52.201 --> 00:07:56.685
some information into features that
would let you detect that something has

00:07:56.685 --> 00:08:01.030
gone wrong and get the system to
prefer some other configuration.

00:08:01.030 --> 00:08:03.250
I'm just going to give
an example of that now.

00:08:03.250 --> 00:08:07.158
So, here we have an error of
the part-of-speech tagger,

00:08:07.158 --> 00:08:08.809
there's the word, as.

00:08:08.809 --> 00:08:13.720
And the part-of-speech tagger has
chosen the preposition tag for

00:08:13.720 --> 00:08:17.955
it, whereas what it should
have chosen is the adverb tag.

00:08:17.955 --> 00:08:21.780
Because this is, as soon, modifying soon.

00:08:21.780 --> 00:08:23.940
Well, how could we fix that?

00:08:23.940 --> 00:08:29.090
Well, it seems like the information that
we want to use is that if the next word

00:08:29.090 --> 00:08:36.580
is, soon, that's a really good clue that
as will be functioning as an adverb.

00:08:36.580 --> 00:08:41.020
And so we can fix this error by adding
a feature that looks at the next word.

00:08:41.020 --> 00:08:44.550
So we're using next words,
as well as previous words and

00:08:44.550 --> 00:08:46.910
previous part-of-speech tags.

00:08:46.910 --> 00:08:50.248
So here the part-of-speech tagger for,
intrinsic,

00:08:50.248 --> 00:08:52.710
has labeled it as a proper noun.

00:08:52.710 --> 00:08:57.619
That's a common error because if the
part-of-speech tagger sees a capitalized

00:08:57.619 --> 00:09:00.248
word that it never saw
in the training data,

00:09:00.248 --> 00:09:04.105
normally its first best guess is to say,
that's a proper noun.

00:09:04.105 --> 00:09:08.900
But that's not necessarily true at the
beginning of a sentence when all words get

00:09:08.900 --> 00:09:09.828
capitalized.

00:09:09.828 --> 00:09:15.680
But maybe we actually know about the word,
intrinsic.

00:09:18.796 --> 00:09:21.810
And that was seen several
times in the training data.

00:09:21.810 --> 00:09:23.855
And we know that it's an adjective.

00:09:23.855 --> 00:09:28.945
So if we can utilize that knowledge we'd
be able to get this case right as well.

00:09:28.945 --> 00:09:33.235
So if we put in a feature of
what's the word, lowercased,

00:09:33.235 --> 00:09:37.795
that that feature would argue that this
word should be tagged as an adjective.

00:09:37.795 --> 00:09:40.911
And so we might be able to
hope to fix that error.

00:09:40.911 --> 00:09:45.972
Note that both of those features didn't
require any sequence information.

00:09:45.972 --> 00:09:50.120
We were looking at features
of word to the right, and,

00:09:50.120 --> 00:09:52.580
what's the lower case form of a word?

00:09:52.580 --> 00:09:56.010
And that's an interesting
general observation.

00:09:56.010 --> 00:10:02.050
In early work on sequence models people
were very fixated on sequence models and

00:10:02.050 --> 00:10:06.160
using the sort of sequence of labeling,

00:10:06.160 --> 00:10:09.180
the sequence of tags,
to predict other tags.

00:10:09.180 --> 00:10:14.166
It turns out for many of the problems
that were and are conventionally done as

00:10:14.166 --> 00:10:18.880
sequence labeling, that the sequence
information is barely useful.

00:10:18.880 --> 00:10:23.720
It normally gives you a fraction of extra
performance, but very, very little.

00:10:23.720 --> 00:10:28.024
And so, we already saw in this
case the part-of-speech tagging,

00:10:28.024 --> 00:10:30.891
that just using this model,
of using allot of

00:10:30.891 --> 00:10:35.436
features of the current word to
predict the take performs very nicely.

00:10:35.436 --> 00:10:40.047
So that gave us this performance
of 93.7 % on all tokens.

00:10:40.047 --> 00:10:43.123
And 82.6 on unknown tokens.

00:10:43.123 --> 00:10:47.606
But you can do a lot better than that, as
was being suggested on the previous slide,

00:10:47.606 --> 00:10:50.761
by also considering things like,
what's the next word?

00:10:50.761 --> 00:10:52.960
And using that to influence the tag.

00:10:52.960 --> 00:10:54.170
And what's the previous word?

00:10:54.170 --> 00:10:56.424
And using that to influence the tag.

00:10:56.424 --> 00:11:00.580
And so that's what's being referred
to here as the 3Words model.

00:11:00.580 --> 00:11:06.540
So you're having features independently
of these 3Words influencing the tag.

00:11:06.540 --> 00:11:08.970
And it's actually quite stunning
how well that performs.

00:11:08.970 --> 00:11:13.254
So that gives you a token
accuracy of about 96.6% and

00:11:13.254 --> 00:11:16.836
an unknown word accuracy of about 86.8%.

00:11:16.836 --> 00:11:21.411
And the thing to notice is that
that performance is actually quite

00:11:21.411 --> 00:11:25.500
similar to the performance
you get with sequence models.

00:11:25.500 --> 00:11:30.421
So if we go back to the performance here,
that you can see that that

00:11:30.421 --> 00:11:36.061
performance is very close to the
performance that's being listed here for

00:11:36.061 --> 00:11:39.570
the MEMM tagger, 96.9%, 86.9%.

00:11:39.570 --> 00:11:44.118
96.6%, 86.8%, fractionally below but

00:11:44.118 --> 00:11:48.290
exceedingly close in performance.

00:11:48.290 --> 00:11:51.800
Okay, so what we've learned
about part-of-speech taking

00:11:51.800 --> 00:11:56.570
is that by itself changing from generative
to discriminative models doesn't

00:11:56.570 --> 00:12:00.390
give a big boost to
part-of-speech taggin performance.

00:12:00.390 --> 00:12:06.130
The big boost comes from being able to put
in lots of features of observations and

00:12:06.130 --> 00:12:08.230
combine them together in a good way.

00:12:08.230 --> 00:12:11.640
So, that's things like suffix analysis,
word shape features,

00:12:11.640 --> 00:12:13.710
lower casing, things like that.

00:12:13.710 --> 00:12:17.320
So, this additional power from having
rich features has been shown to

00:12:17.320 --> 00:12:22.330
result in major improvements to
the accuracy of sequence models.

00:12:22.330 --> 00:12:24.610
There is some cost and the cost,

00:12:24.610 --> 00:12:28.290
as you'll probably find out in the
assignment, is that training discriminant

00:12:28.290 --> 00:12:32.210
models is just much slower than
training generative models.

00:12:32.210 --> 00:12:34.490
If you remember back to language models,

00:12:34.490 --> 00:12:38.190
you can estimate language models
essentially just by counting data.

00:12:38.190 --> 00:12:44.420
Whereas for discriminative models, we have
to do processes of numerical optimization,

00:12:44.420 --> 00:12:47.720
and they just are much
more time intensive.

00:12:47.720 --> 00:12:50.991
That completes the discussion
of part-of-speech taggers.

00:12:50.991 --> 00:12:55.066
And so now you should be in a position,
not only that you understand something

00:12:55.066 --> 00:12:59.331
about part-of-speech tagging, but
in general, how to apply maximum entropy

00:12:59.331 --> 00:13:03.870
sequence models to part-of-speech tagging
and other similar sequence problems.

