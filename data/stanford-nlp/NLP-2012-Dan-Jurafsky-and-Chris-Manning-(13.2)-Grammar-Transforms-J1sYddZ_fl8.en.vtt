WEBVTT
Kind: captions
Language: en

00:00:00.550 --> 00:00:03.699
In this segment I'm going to
tell you about the kinds of

00:00:03.699 --> 00:00:07.934
grammar transforms that we used to
do the efficient parsing of PCFGs.

00:00:07.934 --> 00:00:14.288
So the most frequently known grammar
transformation is the Chomsky normal form.

00:00:14.288 --> 00:00:19.850
So the idea of the Chomsky normal form is
that CFG rules are restricted to being up

00:00:19.850 --> 00:00:25.350
to simple forms that they either
X goes to YZ where all of x,

00:00:25.350 --> 00:00:27.880
y and z are non-terminals or

00:00:27.880 --> 00:00:33.130
they're simply the form of a non-terminal
X rewrites as a terminal W.

00:00:34.150 --> 00:00:39.390
So you can take any CFG and
transform it into i's Chomsky normal form,

00:00:39.390 --> 00:00:45.490
derived normal form and produce another
CFG which recognizes the same language.

00:00:45.490 --> 00:00:49.310
That is, it doesn't necessarily
give the same tree structures, but

00:00:49.310 --> 00:00:52.600
the same strings are part of and
not part of the language.

00:00:53.790 --> 00:00:57.760
And the way that you do that is by
going through a series of transforms

00:00:57.760 --> 00:01:00.740
that get rid of the MP rules and
the unary rules and

00:01:00.740 --> 00:01:04.155
then divide that rules that have more
then two things on the left side.

00:01:04.155 --> 00:01:06.639
Let's just quickly go through
an example of how we do that.

00:01:07.810 --> 00:01:12.030
So here's our ugly phrase structure
grammar with all the bad cases in it.

00:01:12.030 --> 00:01:16.730
So first off, let's do epsilon removal, so
there's just one rule with epsilon in it,

00:01:16.730 --> 00:01:19.110
so we're going to get rid of that one.

00:01:19.110 --> 00:01:22.590
And the way we're going to do that is
every time that there had been a rule

00:01:22.590 --> 00:01:27.930
which has an NP on the right-hand side,
we're going to split it into two rules,

00:01:27.930 --> 00:01:32.510
one just as before and one that then

00:01:32.510 --> 00:01:37.935
notes that the noun phrase can be empty,
and so just says S can go to a VP.

00:01:37.935 --> 00:01:43.475
Okay, so if we keep on doing that through
all the other places that NP turns up,

00:01:43.475 --> 00:01:45.066
we then get this grammar.

00:01:45.066 --> 00:01:48.755
So then at this point, we see that
there are a lot of unary rules, and

00:01:48.755 --> 00:01:50.975
more than there were before.

00:01:50.975 --> 00:01:53.245
And so we're going to want to
start getting rid of them.

00:01:53.245 --> 00:01:56.900
So the way we do that is we
pick the first one, say, and

00:01:56.900 --> 00:02:00.497
then we work down
the consequences of it downwards.

00:02:00.497 --> 00:02:04.240
So now we're saying that S
can go straight to a VP.

00:02:05.280 --> 00:02:09.730
And so that means we now look for
where there's a VP on the left-hand side.

00:02:09.730 --> 00:02:14.810
And since an S can immediately go to a VP,
as well as keeping this rule,

00:02:14.810 --> 00:02:19.300
we're going to have to add another
one that says an S can go to V NP,

00:02:21.310 --> 00:02:25.649
and so we make that change.

00:02:27.330 --> 00:02:31.388
So now we have this grammar, and
unfortunately, those changes mean that

00:02:31.388 --> 00:02:35.127
we've introduced a new unary rule
with an S on the left-hand side.

00:02:35.127 --> 00:02:39.747
So you have to do this unary removal
recursively until every unary has

00:02:39.747 --> 00:02:41.070
disappeared.

00:02:41.070 --> 00:02:46.850
So now we have S goes to V, and well,
where does V appear on the left-hand side?

00:02:46.850 --> 00:02:48.980
That happens in the lexicon over here.

00:02:48.980 --> 00:02:53.640
So when we get rid of this rule,
we're going to have to add new

00:02:53.640 --> 00:02:59.650
lexical entries saying that an S can go
to people and so on for the other cases.

00:02:59.650 --> 00:03:03.378
And so that then gets us to this state.

00:03:03.378 --> 00:03:06.221
Okay, and
then at that point we just keep on going.

00:03:06.221 --> 00:03:10.593
So we're going to get rid of this
VP goes to V, but that means we're

00:03:10.593 --> 00:03:15.124
going to look again for places where
a V appears on the left-hand side,

00:03:15.124 --> 00:03:19.050
and we're going to further
increase the size of our lexicon.

00:03:20.230 --> 00:03:23.940
And then there are just still more
unaries and so we keep on going.

00:03:23.940 --> 00:03:27.210
So the first one here is NP goes to NP.

00:03:27.210 --> 00:03:31.738
That's an A over A unary that
doesn't add anything apart from for

00:03:31.738 --> 00:03:33.580
idea's linguistic structure so

00:03:33.580 --> 00:03:38.020
we can just erase that without changing
the language that's recognized.

00:03:38.020 --> 00:03:40.630
And then we have here, NP goes to N.

00:03:40.630 --> 00:03:41.590
And so then again,

00:03:41.590 --> 00:03:45.501
we're going to have to start looking
where N appears on the left-hand side.

00:03:45.501 --> 00:03:50.027
And what we'll find in this case is,
now there's nowhere in

00:03:50.027 --> 00:03:54.641
the grammar where N appears on
the right-hand side of a rule,

00:03:54.641 --> 00:03:59.420
so we don't actually have to
split these lexical entries.

00:03:59.420 --> 00:04:04.490
We can actually just rename
them to put NP in for each one.

00:04:04.490 --> 00:04:05.515
And so then we keep on going.

00:04:05.515 --> 00:04:09.570
There are couple of other
unary rules down here.

00:04:09.570 --> 00:04:14.100
So once we get rid of them all we
get a grammar looks like this.

00:04:14.100 --> 00:04:17.190
And so now the next step is to say,
well, gee,

00:04:17.190 --> 00:04:21.610
we've still got some rules that have
three things on the left-hand side,

00:04:21.610 --> 00:04:24.940
and we're going to have to
change those into binary rules.

00:04:24.940 --> 00:04:29.737
And the way that we do that is we
introduce extra categories, so

00:04:29.737 --> 00:04:31.467
let's take this one.

00:04:31.467 --> 00:04:38.903
So what we're going to say is that
a VP goes to the first thing here,

00:04:38.903 --> 00:04:45.374
a V, and then we're going to
introduce a new category,

00:04:45.374 --> 00:04:52.190
say X, and then we're going
to say that X goes to NP PP.

00:04:52.190 --> 00:04:54.776
So I just called it X here, but

00:04:54.776 --> 00:05:00.363
to make this a little bit simpler
we're going to use systematic but

00:05:00.363 --> 00:05:04.931
unwieldy names for them so
we can call this at VP_V.

00:05:04.931 --> 00:05:09.941
And the way to think of this is that
this is just the name of a nonterminal,

00:05:09.941 --> 00:05:12.335
just like any other nonterminal.

00:05:12.335 --> 00:05:13.745
You just treat it as an atom.

00:05:13.745 --> 00:05:16.900
But we've given a systematic
way to introduce them.

00:05:16.900 --> 00:05:23.740
So we make those changes, and then this is
our final grammar in Chomsky Normal form.

00:05:25.280 --> 00:05:29.699
Now if a linguist hands you their grammar
like this and you do these steps and

00:05:29.699 --> 00:05:34.609
hand it back to them and say, here it is
in Chomsky Normal Form, they're not likely

00:05:34.609 --> 00:05:39.543
to like what they see because it's made a
real mess of the structure of the grammar.

00:05:39.543 --> 00:05:43.180
But that's not really something
that you should worry about.

00:05:43.180 --> 00:05:48.240
You should regard this as an internal
representation inside your system

00:05:48.240 --> 00:05:50.370
which will allow efficient parsing and

00:05:50.370 --> 00:05:55.060
isn't really designed to be a structure
of the language as the linguist sees it.

00:05:56.570 --> 00:06:01.135
So that this is a system that lets
us do grammar transformations for

00:06:01.135 --> 00:06:02.610
efficient parsing.

00:06:02.610 --> 00:06:06.827
And we haven't exhibited it here,
but with some extra bookkeeping and

00:06:06.827 --> 00:06:10.340
symbol names, you can do these
kind of transformations and

00:06:10.340 --> 00:06:14.275
still be able to reconstruct
the original trees that you would have

00:06:14.275 --> 00:06:17.253
made without doing
the grammar transformation.

00:06:17.253 --> 00:06:21.899
Nevertheless, in practice while doing
full Chomsky Normal Form is a pain,

00:06:21.899 --> 00:06:26.618
you should be able to see from the way
that we deconstructed the rules with more

00:06:26.618 --> 00:06:31.264
than three things on the left-hand side,
that turning them back into unary

00:06:31.264 --> 00:06:35.141
rules from binary rules,
that's going to be straightforward.

00:06:35.141 --> 00:06:39.273
But reconstructing the empties and
the unaries is trickier, and so

00:06:39.273 --> 00:06:42.270
at this point there is actually a divide.

00:06:42.270 --> 00:06:48.880
The thing that you want to know is
binarization of grammar rules is

00:06:48.880 --> 00:06:53.740
absolutely essential to the algorithms
that we're going to show that allow cubic

00:06:53.740 --> 00:06:59.200
time CFG parsing, cubic time parsing
of arbitrary context free grammars.

00:06:59.200 --> 00:07:02.440
So any system for efficient polynomial

00:07:02.440 --> 00:07:07.480
time parsing of context free grammars
somewhere does binarization.

00:07:07.480 --> 00:07:12.390
It might be done in advance, like in the
example we're going to show with the CKY

00:07:12.390 --> 00:07:15.900
algorithm, where we explicitly
transform the grammar and

00:07:15.900 --> 00:07:19.240
then parse, or for
some other forms of parsing.

00:07:19.240 --> 00:07:23.130
The binarization gets hidden
inside the workings of the parser,

00:07:23.130 --> 00:07:26.570
but binarization is always done somewhere.

00:07:26.570 --> 00:07:31.480
On the other hand, the getting rid of the
unaries and the empties is more optional.

00:07:31.480 --> 00:07:37.040
So if you want to have the neatest
version of the algorithms, you

00:07:37.040 --> 00:07:43.100
will want to do the unaries and empties
as well, but leaving the unaries and

00:07:43.100 --> 00:07:47.240
empties around doesn't change the
asymptotic complexity of the algorithms.

00:07:47.240 --> 00:07:50.300
So, commonly it's more convenient
to leave some of them in and

00:07:50.300 --> 00:07:52.330
we'll demonstrate that
with our real examples.

00:07:54.470 --> 00:07:57.210
So, we've discussed this
as a grammar transform.

00:07:57.210 --> 00:08:00.810
But what we normally actually do
in statistical parsing these days

00:08:00.810 --> 00:08:05.170
is read trees from a tree bank and
then do stuff to them and

00:08:05.170 --> 00:08:09.300
then count the subtrees and
they become our grammar.

00:08:09.300 --> 00:08:13.052
So what we're going to do,
is we're going to say,

00:08:13.052 --> 00:08:17.728
by and large, what we're reading
in trees from a tree bank.

00:08:17.728 --> 00:08:22.313
And look, this subtree is going to
be something for our grammar, and

00:08:22.313 --> 00:08:26.122
this subtree here is going to
be something for our grammar.

00:08:26.122 --> 00:08:30.315
But well, we don't want to have
these subtrees with three or

00:08:30.315 --> 00:08:36.620
more things beneath them, because that
ruins our efficient parsability property.

00:08:36.620 --> 00:08:40.590
So as we read in the trees,
we're going to transform them and

00:08:40.590 --> 00:08:42.620
turn them into binary trees.

00:08:42.620 --> 00:08:46.740
And we've done it in the same way as we
discussed before, by introducing this

00:08:46.740 --> 00:08:50.880
new non-terminal and dividing up
the rule that had three children.

00:08:52.480 --> 00:08:55.540
And we may want to do the same
things with empties and unaries.

00:08:55.540 --> 00:08:57.940
So let's just discuss
that a little bit more.

00:08:57.940 --> 00:09:01.780
So here is an actual tree
from the pin tree bank, so

00:09:01.780 --> 00:09:07.020
it was a headline of a newspaper article,
and the headline was just atone.

00:09:07.020 --> 00:09:11.430
And so the way that's been analyzed
is by saying that that's a sentence,

00:09:11.430 --> 00:09:12.530
an imperative sentence.

00:09:12.530 --> 00:09:14.910
So here's an imperative verb, and

00:09:14.910 --> 00:09:18.100
the imperative verb has
an unexpressed NP subject.

00:09:18.100 --> 00:09:20.210
So this is an empty here.

00:09:20.210 --> 00:09:23.050
Okay, and
this says that it's a headline, and

00:09:23.050 --> 00:09:25.900
these are the functional tags
saying this is a subject.

00:09:25.900 --> 00:09:30.440
So normally, when we process tree bank
trees, the kind of things we do is,

00:09:30.440 --> 00:09:33.468
first of all,
we strip off the functional tags and

00:09:33.468 --> 00:09:38.480
we just deal with the basic categories,
which gets us to over here.

00:09:38.480 --> 00:09:43.520
Very commonly, our parsing algorithms
don't explicitly deal with the empties,

00:09:43.520 --> 00:09:50.760
so we also just delete the empty node and
everything that's above an empty node.

00:09:50.760 --> 00:09:54.100
And so
that then maps us onto this tree here, and

00:09:54.100 --> 00:09:56.100
this tree has a lot of unaries in it.

00:09:57.280 --> 00:10:00.400
Now it's possible to
also get rid of unaries.

00:10:00.400 --> 00:10:03.860
Now if you use the algorithm
that we showed before,

00:10:03.860 --> 00:10:08.630
you get rid of unaries by
keeping the highest node.

00:10:08.630 --> 00:10:12.261
So if you kept the truly
highest node out of root node,

00:10:12.261 --> 00:10:16.796
you'd even get rid of this S, and
it'd just be root goes to Atone.

00:10:16.796 --> 00:10:20.470
The start symbol of the grammar
would rewrite as a word.

00:10:20.470 --> 00:10:21.860
Commonly we don't do that, and

00:10:21.860 --> 00:10:25.220
we'll at least keep the rewrite
from our start symbol

00:10:25.220 --> 00:10:29.620
to the different types of things that you
can get, a sentence or a noun phrase.

00:10:29.620 --> 00:10:32.830
But then after that if
we keep the high node,

00:10:32.830 --> 00:10:35.870
we'll have S goes straight to a word,
atone.

00:10:35.870 --> 00:10:37.770
Normally we don't want to do that,

00:10:37.770 --> 00:10:43.090
because we like to keep our lexicon which
has parts of speech rewriting as words.

00:10:43.090 --> 00:10:48.180
So it's more usual to keep
the low end of a unary chain and

00:10:48.180 --> 00:10:50.480
get rid of the higher up things.

00:10:50.480 --> 00:10:53.940
But in that case if you want
to have a unique start symbol,

00:10:53.940 --> 00:10:59.630
you definitely have to keep your start
symbol and allow the start symbol only

00:10:59.630 --> 00:11:03.830
to rewrite unirally to
either a non-terminal,

00:11:03.830 --> 00:11:07.590
phrasal category, or to a pre-terminal.

00:11:07.590 --> 00:11:11.220
It turns out that you don't actually
have to do any of this stuff.

00:11:11.220 --> 00:11:15.360
And so it's perfectly okay to
leave unaries in your grammar and

00:11:15.360 --> 00:11:18.500
use the algorithms that
we're going to show.

00:11:18.500 --> 00:11:22.627
It makes them a bit more complex and
messier in terms of a parsing algorithm.

00:11:22.627 --> 00:11:28.800
But it makes it much easier to reconstruct
the original parse trees on the way out.

00:11:28.800 --> 00:11:33.640
So the parsing algorithms that we're about
to show in the next segment actually work

00:11:33.640 --> 00:11:36.010
over a representation like this.

00:11:36.010 --> 00:11:38.270
So we still have unary rules but

00:11:38.270 --> 00:11:42.460
we've deleted the functional tags and
the empty elements.

00:11:44.620 --> 00:11:49.070
Okay, so I hope you have a sense now about
what's an error in grammar rules and

00:11:49.070 --> 00:11:53.800
how we can transform them to get
them in frameworks that allow for

00:11:53.800 --> 00:11:56.650
more efficient and
cleaner parsing algorithms.

00:11:56.650 --> 00:12:00.309
And now we'll go on and
look at a particular parsing

00:12:00.309 --> 00:12:04.234
algorithm that works with binary and
unary CFG rules.

