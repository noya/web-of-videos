WEBVTT
Kind: captions
Language: en

00:00:00.970 --> 00:00:05.850
In this segment I'm going to introduce
the way of doing parsing of context free

00:00:05.850 --> 00:00:08.720
grammars exactly in polynomial time.

00:00:08.720 --> 00:00:12.270
In particular, it will give us means
in finding the most probable parse

00:00:12.270 --> 00:00:15.830
of a sentence according to
PCFG in polynomial time.

00:00:15.830 --> 00:00:19.620
And the method that I'm going to
introduce is the famous parsing method in

00:00:19.620 --> 00:00:21.860
the 60s called the CKY algorithm.

00:00:23.640 --> 00:00:27.420
So, remember our goal in constituency
parsing is we start with a sentence.

00:00:27.420 --> 00:00:31.020
This is the example we are going
to use fish people fish tanks.

00:00:31.020 --> 00:00:35.430
We have a grammar with probabilities for
the roles in the PCFG and

00:00:35.430 --> 00:00:41.200
what we want to do is find a sentence
structure that's licensed by the grammar.

00:00:41.200 --> 00:00:45.940
And in the PCFG case, normally the most
probable sub-sentence structure.

00:00:45.940 --> 00:00:49.530
And remember crucially what
we want to do is do this

00:00:49.530 --> 00:00:51.890
without doing exponential amount of work.

00:00:51.890 --> 00:00:55.560
And if we explore everything exhaustively,
since they can be an exponential number of

00:00:55.560 --> 00:00:58.430
parses it will do
an exponential number of work.

00:00:58.430 --> 00:01:03.520
But the CKY algorithm gives
us a cubic time algorithm but

00:01:03.520 --> 00:01:05.460
it's in terms of the length
of the sentence and

00:01:05.460 --> 00:01:09.610
the size of the grammar in terms of the
number of non-terminals that allows us to

00:01:09.610 --> 00:01:14.120
do this by compact representation,
the use of dynamic programming, again.

00:01:14.120 --> 00:01:17.720
And just like that edit distance
algorithm in the first week.

00:01:17.720 --> 00:01:20.250
Let's see how it goes about doing that.

00:01:20.250 --> 00:01:25.162
So, the secret of what it does is
it uses this data structure here,

00:01:25.162 --> 00:01:28.433
which gets referred to
as a parse triangle.

00:01:31.998 --> 00:01:35.230
Or also, quite commonly, as a chart.

00:01:37.270 --> 00:01:41.950
And so
the way it works is that this cell here

00:01:41.950 --> 00:01:45.890
is going to describe things
you can build over fish.

00:01:45.890 --> 00:01:51.350
This square here is going to describe
things that you can build over people.

00:01:51.350 --> 00:01:54.890
Then this square here is going to describe

00:01:54.890 --> 00:01:59.820
things that you can build over
fish people and so on up.

00:01:59.820 --> 00:02:04.940
And so what we can see is that since
this is basically half a square,

00:02:04.940 --> 00:02:09.880
the number of squares that
we have is order n squared.

00:02:09.880 --> 00:02:15.380
And so what we're going to show is that
we can fill in each square in order n.

00:02:15.380 --> 00:02:18.110
And so the resulting
algorithm runs in cubic time.

00:02:21.519 --> 00:02:26.698
So the secret to the CKY algorithm
is that we fill up this chart,

00:02:26.698 --> 00:02:31.320
work in layers according
to the size of the span.

00:02:31.320 --> 00:02:36.810
So the first thing we do is fill
in the cells for single words.

00:02:37.980 --> 00:02:43.010
Then we fill in the second row of the
chart, and so these cells in the second

00:02:43.010 --> 00:02:48.110
row of the chart are precisely
the cells that describe two words.

00:02:53.224 --> 00:02:56.459
Then we fill up the third
row of the chart,

00:02:56.459 --> 00:03:01.200
which are constituents that
are three words in length.

00:03:01.200 --> 00:03:04.053
And finally we fill up the top cell and

00:03:04.053 --> 00:03:09.772
that will give us categories that pass,
that cover the entire sentence.

00:03:09.772 --> 00:03:13.812
Let's look in detail how we fill
in one of the cells of this chart.

00:03:16.134 --> 00:03:20.572
So here we're assuming that we've
all ready filled in these two cells,

00:03:20.572 --> 00:03:25.081
now actually according to the grammar
I'm using, I haven't filled them

00:03:25.081 --> 00:03:29.600
exhaustively and I put in enough
that we can get the general idea.

00:03:29.600 --> 00:03:35.210
And so what we then want to do, is to
fill in a cell above it, so we want to

00:03:35.210 --> 00:03:41.130
fill in this cell up here that describes
the two word constituent people fish.

00:03:41.130 --> 00:03:45.440
And the way we do it is what
we're going to do is build things

00:03:45.440 --> 00:03:49.680
in the binary fashion by saying
let's take a constituent from here,

00:03:49.680 --> 00:03:56.485
a constituent from here, and a grammar
rule that's able to combine them.

00:03:56.485 --> 00:04:00.970
And then we can build the thing on
the left-hand side of the grammar

00:04:00.970 --> 00:04:06.695
role with the probability that comes from
multiplying the three probabilities.

00:04:06.695 --> 00:04:11.170
So what we're going to build, so
what we're going to build up here,

00:04:11.170 --> 00:04:15.920
is that a noun phrase,
which is built from two noun phrases.

00:04:15.920 --> 00:04:22.941
And it's probability is
going to be 0.35 times 0.14,

00:04:22.941 --> 00:04:27.842
times the probability of the role 0.1 and

00:04:27.842 --> 00:04:35.306
if you multiply that all together
that comes out to 0.0049.

00:04:35.306 --> 00:04:40.840
Okay, but that's not the only thing
that we can build in this cell.

00:04:40.840 --> 00:04:47.200
So we can also take this verb and
the same noun phrase and

00:04:47.200 --> 00:04:54.170
then we can build a verb phrase
out of a verb and a noun phrase.

00:04:54.170 --> 00:04:57.400
And so we're going to write
down that possibility as well.

00:04:57.400 --> 00:05:02.510
So we're going to have VP goes to V NP.

00:05:04.370 --> 00:05:10.137
And so the probability of that is going to

00:05:10.137 --> 00:05:16.625
be 0.1 times 0.14 times 0.50,

00:05:16.625 --> 00:05:20.782
which equals 0.007.

00:05:20.782 --> 00:05:25.930
Okay, and then at that point we keep on
going and see what else we can build.

00:05:25.930 --> 00:05:31.900
Well another thing that we can build is
that we can take this NP and the VP and

00:05:33.340 --> 00:05:37.980
then we can combine them with
this S role right at the top.

00:05:37.980 --> 00:05:42.930
So we can build here an S out of an NP and

00:05:42.930 --> 00:05:48.180
a VP and the probability of that

00:05:48.180 --> 00:05:54.260
is 0.35 times 0.06 times

00:05:54.260 --> 00:05:57.880
S goes to NP VP, 0.9 and the product of

00:05:59.960 --> 00:06:05.940
those is also,
no it's a different number the ones

00:06:05.940 --> 00:06:09.951
we've seen before, 0.0189.

00:06:09.951 --> 00:06:15.580
Okay, and we've run every binary
rule that we possibly could.

00:06:15.580 --> 00:06:18.130
And one possibility is that they'll,

00:06:18.130 --> 00:06:23.670
the collisions that we'll find multiple
ways of building an S or a VP.

00:06:23.670 --> 00:06:27.670
I don't actually have an example of
that now but what I am going to do

00:06:27.670 --> 00:06:32.900
is illustrate the same thing once
we extend on the unary rules.

00:06:32.900 --> 00:06:36.530
So in my grand math I
also have unary rules.

00:06:36.530 --> 00:06:42.000
So I have a rule like S
goes to VP right here.

00:06:42.000 --> 00:06:46.900
So that rule can be applied
just inside this cell

00:06:46.900 --> 00:06:49.640
since I can build a VP right here.

00:06:49.640 --> 00:06:54.150
So I can also build S goes to VP here.

00:06:54.150 --> 00:07:01.415
And the probability of that will be
the probability I calculated before,

00:07:01.415 --> 00:07:07.370
0.007 times the probability
of that rule 0.1.

00:07:07.370 --> 00:07:14.232
And then though that
multiplied out gets to 0.0007.

00:07:14.232 --> 00:07:21.420
Okay, so at this point though if to
have my cubic time passing algorithm I'm

00:07:21.420 --> 00:07:26.810
not wanting to store these two
ways of making S in a cell.

00:07:26.810 --> 00:07:34.094
What I want to do is just recognize I can
build an S over this two word span and

00:07:34.094 --> 00:07:38.368
for PCFG where I am trying to
find the most probable parse.

00:07:38.368 --> 00:07:43.112
What I want to record is simply the best
way of making an S over that span was

00:07:43.112 --> 00:07:47.147
precisely because the independence
assumptions of a PCFG,

00:07:47.147 --> 00:07:51.892
if that constituent is used in the most
probable parse of the sentence,

00:07:51.892 --> 00:07:56.430
what we'll be using is the best way
of making And is so for that span.

00:07:56.430 --> 00:08:02.464
So in this case here, what I do is
compare the two ways of making an S and

00:08:02.464 --> 00:08:08.401
here are their probabilities
0.0189 versus 0.0007,

00:08:08.401 --> 00:08:14.125
so the S goes to NPVP as the higher
probability way of making an S and

00:08:14.125 --> 00:08:18.530
so I keep that one and
I just don't store this one.

00:08:19.860 --> 00:08:23.530
Okay, and so now I've filled in the cell,

00:08:23.530 --> 00:08:27.550
I mean again actually strictly only
partially, for this higher up cell.

00:08:27.550 --> 00:08:29.601
And so repeating that over and over,

00:08:29.601 --> 00:08:32.591
moving up the chart is
the heart of the CKY algorithm.

00:08:35.660 --> 00:08:40.016
Now the original CKY algorithm that's
just for normal form grammars,

00:08:40.016 --> 00:08:42.020
which I showed earlier.

00:08:42.020 --> 00:08:48.460
But as I indicated, you can easily extend
the CKY algorithm to handle unary roles.

00:08:48.460 --> 00:08:50.460
It makes the algorithm kind of messier,

00:08:50.460 --> 00:08:54.320
but it doesn't increase its
algorithmic complexity.

00:08:54.320 --> 00:09:00.170
It turns out you can also easily extend
the CKY algorithm to handle empties.

00:09:00.170 --> 00:09:02.180
Let's just look quickly
at how you do that.

00:09:02.180 --> 00:09:07.660
So, if before we had the sentence,
people fish tanks.

00:09:10.590 --> 00:09:17.221
Well the way we did things was we call
these words word numbers 1, 2 and 3.

00:09:17.221 --> 00:09:23.221
And we build our CKY chart above them.

00:09:28.650 --> 00:09:35.890
And this cell here is for the stuff
about of word one, the 1, 1 cell.

00:09:35.890 --> 00:09:41.020
This is the 2, 2 cell and
this is the 3, 3 cell.

00:09:41.020 --> 00:09:48.500
And then we call this one 1, 2, 2,
3 and this one is the 1, 3 cell.

00:09:48.500 --> 00:09:54.092
And so we're measuring our
constituent spans from the first

00:09:54.092 --> 00:10:00.900
word they contain to the last word
they contain, inclusive on both ends.

00:10:00.900 --> 00:10:04.696
If instead of that we want to
work with empties in our grammar,

00:10:04.696 --> 00:10:09.750
we use the trick of fence posts that you
see at various places in computer science.

00:10:09.750 --> 00:10:15.095
So, we have the same sentence,
people fish tanks,

00:10:15.095 --> 00:10:22.995
instead what we do is we put our
numbers between the words, 0, 1, 2, 3.

00:10:22.995 --> 00:10:31.400
And then we build a chart over those
numbers which has four points, so we have.

00:10:43.891 --> 00:10:44.610
So like that.

00:10:44.610 --> 00:10:48.331
I guess I need to move
this 3 over a little.

00:10:48.331 --> 00:10:52.530
Okay, so this then becomes the 0, 0 cell,

00:10:52.530 --> 00:10:56.847
which will store any
empties that we put here.

00:10:56.847 --> 00:11:01.372
And similarly,
this will become the 1, 1 cell,

00:11:01.372 --> 00:11:05.310
the 2, 2 cell, and the 3, 3 cell.

00:11:05.310 --> 00:11:10.830
And so each of these will store all and
only empty constituents.

00:11:13.740 --> 00:11:18.027
And so, then the actual words
now have a span of one,

00:11:18.027 --> 00:11:21.740
because it stretches from position 0 to 1.

00:11:21.740 --> 00:11:28.174
So we're now going to put the actual
words in the second row of the chart,

00:11:28.174 --> 00:11:33.860
and so they'll be the 0,
1, 1, 2, and 2, 3 entries.

00:11:33.860 --> 00:11:36.860
At that point,
we just continue on as we did before.

00:11:36.860 --> 00:11:42.150
So here we then have the 0,
2 and the 1, 3 entries.

00:11:42.150 --> 00:11:46.930
And here we have the 0,
3 entry, which is again things

00:11:46.930 --> 00:11:51.421
that span the whole sentence
from position 0 to 3.

00:11:51.421 --> 00:11:55.373
But that could possibly include
empties here, empties here or

00:11:55.373 --> 00:11:58.067
empties at any of these points in between.

00:11:58.067 --> 00:12:02.313
I'm not going to go through this algorithm
in detail, but it's something that you

00:12:02.313 --> 00:12:06.330
could work out for an exercise and see
that it does work in exactly the same way.

00:12:07.932 --> 00:12:13.730
But what I do want to emphasize again is
this idea that binarization is vital.

00:12:13.730 --> 00:12:17.110
The way you get cubic time
parsing algorithms for

00:12:17.110 --> 00:12:20.360
CFGs is by doing binarization.

00:12:20.360 --> 00:12:25.270
That means that each rule has at most
two things on the right hand side, and

00:12:25.270 --> 00:12:27.570
that allows a cubic time algorithm.

00:12:27.570 --> 00:12:32.610
As soon as you allow more than two things
on the right hand side, you're minimally

00:12:32.610 --> 00:12:37.520
in a higher order polynomial algorithm,
and if you make no limits

00:12:37.520 --> 00:12:42.710
as to how long the right hand side can be,
well then the algorithm is exponential.

00:12:42.710 --> 00:12:48.520
So if you look at the literature for
CFG and PCFG parsing,

00:12:48.520 --> 00:12:53.490
sometimes you see parsing algorithms that
explicitly work on binarized grammars.

00:12:53.490 --> 00:12:57.475
That's going to be the case for
the CKY algorithm that I tell you, and so

00:12:57.475 --> 00:13:02.030
we're going to transform our grammar
first then feed it to the CKY algorithm.

00:13:02.030 --> 00:13:04.410
Some other grammars aren't like that.

00:13:04.410 --> 00:13:08.507
So, this actually spelling the e in there,

00:13:08.507 --> 00:13:13.400
they do the binarization internal for
the grammar.

00:13:13.400 --> 00:13:18.555
So, the early algorithm looks like
it works on an arbitrary PCFG but

00:13:18.555 --> 00:13:23.990
actually it does binarization internal
to the workings of the parser.

00:13:27.630 --> 00:13:32.661
Okay, so here's the CKY algorithm
that we're going to use.

00:13:32.661 --> 00:13:35.701
In the next segment,
we'll go through in detail how it works.

00:13:35.701 --> 00:13:38.300
But let me just point out
a few things about it.

00:13:38.300 --> 00:13:42.400
So we going to have
an array of scores where we

00:13:42.400 --> 00:13:45.980
stored probabilities of
things that we can build.

00:13:45.980 --> 00:13:47.891
So that for each span, so

00:13:47.891 --> 00:13:52.270
these are the two span indices
from beginning and to and.

00:13:52.270 --> 00:13:56.796
And then for each nonterminal,
we're going to record the probability of

00:13:56.796 --> 00:14:00.300
building a constituent over
that span of a certain type.

00:14:00.300 --> 00:14:03.233
And if you can't build a certain
nonterminal over span,

00:14:03.233 --> 00:14:06.040
we'll say it's probability is zero.

00:14:06.040 --> 00:14:12.411
And secondly, here, we're recording back
pointers, which is then saying that for

00:14:12.411 --> 00:14:17.368
each nonterminal over each span,
we're recording a pointer as to

00:14:17.368 --> 00:14:22.250
what was the best way of building
that nonterminal over the span.

00:14:22.250 --> 00:14:23.970
What did you make it out of?

00:14:23.970 --> 00:14:26.720
Now you don't actually have to store this.

00:14:26.720 --> 00:14:29.801
This is one of these time space tradeoffs.

00:14:29.801 --> 00:14:34.526
You can do parsing faster if you do
store this, because then once you get to

00:14:34.526 --> 00:14:39.904
the end, you know the best way of building
every constituent over every span,

00:14:39.904 --> 00:14:43.839
and so you can easily write
out the resulting parse tree.

00:14:43.839 --> 00:14:47.680
But if you'd actually prefer to conserve
space, you don't have to store it.

00:14:47.680 --> 00:14:52.860
So for example, in the Stanford parser, we
don't actually store these explicitly, and

00:14:52.860 --> 00:14:58.110
we reconstruct the best paths simply from
knowing the scores in the score table.

00:14:58.110 --> 00:15:02.070
And that's actually a fairly good tradeoff
because it greatly reduces the space

00:15:02.070 --> 00:15:07.610
requirements and getting out the final
paths is actually still quite quick.

00:15:07.610 --> 00:15:12.410
Okay, so this first part of the algorithm
is the part that is the part of

00:15:12.410 --> 00:15:18.060
the lexicon where we're filling in
nonterminals that words can rewrite as.

00:15:18.060 --> 00:15:19.490
And so it's pretty simple.

00:15:19.490 --> 00:15:26.658
So we're going through each word and
then we're saying if we've got a rule for

00:15:26.658 --> 00:15:30.784
nonterminal of A goes to tanks or
something,

00:15:30.784 --> 00:15:36.450
then we're going to put its score
into this cell of the chart.

00:15:36.450 --> 00:15:40.070
So it might a probability of 0.3.

00:15:40.070 --> 00:15:44.380
And that's the main part
of the CKY algorithm.

00:15:44.380 --> 00:15:47.800
And then everything down here
is dealing with unary rules.

00:15:47.800 --> 00:15:50.882
So dealing with unary rules
is a bit more complex.

00:15:50.882 --> 00:15:55.813
So once we have some things in a cell,
if we then have other unary rules

00:15:55.813 --> 00:16:00.659
like B goes through A, well then if
we put this into a cell Well then,

00:16:00.659 --> 00:16:04.258
we'll also be able to build
a B over the same span.

00:16:04.258 --> 00:16:08.273
But the problem is we might then
also have a rule C goes to B, and

00:16:08.273 --> 00:16:11.220
then we'll be able to
build a C over the span.

00:16:11.220 --> 00:16:14.539
And in fact, we might even have a rule,
A goes to C,

00:16:14.539 --> 00:16:18.550
which means we find another
way to build an A over a span.

00:16:18.550 --> 00:16:23.185
So what we actually have to
do is keep on applying unary

00:16:23.185 --> 00:16:28.129
rules until we stop discovering
new constituents that we

00:16:28.129 --> 00:16:32.463
can build over a span with
better probabilities.

00:16:32.463 --> 00:16:33.898
And so, that's what this does.

00:16:33.898 --> 00:16:37.627
So this is a little check as to
whether we found a better way of

00:16:37.627 --> 00:16:42.269
building a non-terminal in an individual
iteration of this while loop.

00:16:42.269 --> 00:16:45.139
And so we consider all of our unary rules,

00:16:45.139 --> 00:16:50.670
work out what probability they assigned
the category on the left hand side.

00:16:50.670 --> 00:16:52.540
And if it's a better probability,

00:16:52.540 --> 00:16:57.930
that's right here, we then store it in the
back trace and say we've done some work.

00:16:57.930 --> 00:17:04.912
And providing we've done some work, well
then, we're going to, Do another iteration

00:17:04.912 --> 00:17:11.464
right through the loop of checking out
all of the possible unary rules again.

00:17:13.221 --> 00:17:15.740
Okay, but
this is still actually the easy part.

00:17:15.740 --> 00:17:17.420
This is just the lexicon.

00:17:17.420 --> 00:17:20.830
Then we go on and
actually build the rest of the chart.

00:17:22.320 --> 00:17:24.037
And so that's this part.

00:17:24.037 --> 00:17:30.189
So what we do is remember, we are ordering
our work by the size of constituent span.

00:17:30.189 --> 00:17:33.747
So we start off with two
word span constituents and

00:17:33.747 --> 00:17:37.470
build up to the length of the sentence.

00:17:37.470 --> 00:17:40.470
And then we go across
the cells from left to right.

00:17:40.470 --> 00:17:46.402
So we start with two word constituents
starting with position 0 and

00:17:46.402 --> 00:17:52.420
then heading to the right most
position in our parse triangle.

00:17:52.420 --> 00:17:57.290
This works out the end, and then this
is the crucial part of the algorithm.

00:17:57.290 --> 00:18:02.520
So we're then saying okay,
maybe we're filling in a cell from 1 to 7.

00:18:02.520 --> 00:18:06.020
And so
we're going to build it with binary rules.

00:18:06.020 --> 00:18:09.310
And so that means it has
to be built in some ways.

00:18:09.310 --> 00:18:14.302
So it can be built with something
from 1 to 4, and 4 to 7, or

00:18:14.302 --> 00:18:20.551
alternatively, it could be built with
something from 1 to 2, and 2 to 7.

00:18:20.551 --> 00:18:25.245
And so we have to try out these
different possibilities, and

00:18:25.245 --> 00:18:28.290
that's the choice of the split point.

00:18:28.290 --> 00:18:30.980
And then once we've
decided the split point,

00:18:30.980 --> 00:18:33.715
we're going to consider all grammar rules.

00:18:33.715 --> 00:18:39.415
If they exist, we work out the probability
of building the left hand side,

00:18:39.415 --> 00:18:42.409
so imagine we have a rule, A goes to BC.

00:18:42.409 --> 00:18:47.495
The probability of building
an A over this span in terms

00:18:47.495 --> 00:18:52.579
of if you build a B here and
a C there, and we just work out

00:18:52.579 --> 00:18:57.910
those three probabilities and
multiply them together.

00:18:57.910 --> 00:19:02.420
Okay, and if we found a better way
of building an A over that span,

00:19:02.420 --> 00:19:03.410
we record it.

00:19:04.480 --> 00:19:09.470
And so again,
that's the heart of the CKY algorithm for

00:19:09.470 --> 00:19:12.250
binary rules working higher up the chart.

00:19:12.250 --> 00:19:16.090
All the rest of this is then
again handling unaries,

00:19:16.090 --> 00:19:19.010
which we do in exactly
the same way as before.

00:19:19.010 --> 00:19:26.063
Over each span, we then say, well, do we
also have a rule that says D goes to A?

00:19:26.063 --> 00:19:30.071
If so, we can also go to D, and then we
have to repeat this over and over again,

00:19:30.071 --> 00:19:33.800
until we've stopped being able to
build anything better than before.

00:19:35.620 --> 00:19:40.260
Okay, so then, that was for
one cell of the chart.

00:19:40.260 --> 00:19:43.407
And so then we're finishing off our for
loops for

00:19:43.407 --> 00:19:48.322
the different beginning points working
across rows of our chart and then for

00:19:48.322 --> 00:19:52.010
the different spans working
up the path's triangles.

00:19:52.010 --> 00:19:55.450
So we go across here,
then kind of hit up like this.

00:19:56.700 --> 00:20:01.230
Okay, and so then when we're done,
we found the best way to build every

00:20:01.230 --> 00:20:06.498
constituent over every
non-terminal over every span.

00:20:06.498 --> 00:20:11.990
And we've in particular found what you
can build right in the top cell here.

00:20:11.990 --> 00:20:17.080
And if we have a start category, we know
that we want to build that start category.

00:20:17.080 --> 00:20:22.200
So at that point, we can use this
chart to look down at and find

00:20:22.200 --> 00:20:27.210
the highest probability paths for sentence
and simply return that back to the user.

00:20:27.210 --> 00:20:31.100
And there's obviously not a bit of
algorithm here, which I'm admitting for

00:20:31.100 --> 00:20:34.330
now, but I think it should be
fairly clear how to do that.

00:20:36.780 --> 00:20:38.268
So, there's a lot to grasp here.

00:20:38.268 --> 00:20:41.702
And I think it will take
seeing the concrete example in

00:20:41.702 --> 00:20:44.690
the next segment before
this makes any sense.

00:20:44.690 --> 00:20:49.378
That this algorithm does give a very easy
way to see why this is an algorithm that

00:20:49.378 --> 00:20:52.219
is cubic,
both in the length of the sentence and

00:20:52.219 --> 00:20:55.600
in the number of
non-terminals in the grammar.

00:20:55.600 --> 00:21:00.900
So if you look at what we have here,
we have a for loop of the span size,

00:21:00.900 --> 00:21:04.730
which is of order
the length of the sentence.

00:21:04.730 --> 00:21:09.860
You have a for loop of the beginning,
which is order length of the sentence.

00:21:09.860 --> 00:21:12.222
And then you have a for
loop of the split point,

00:21:12.222 --> 00:21:14.230
which is order length of the sentence.

00:21:14.230 --> 00:21:19.880
So we're O (n cubed) in terms
of the length of the sentence.

00:21:19.880 --> 00:21:22.410
And then once we start
exploring grammar rules,

00:21:22.410 --> 00:21:26.660
we're considering all triples
of non-terminals, and so

00:21:26.660 --> 00:21:32.470
then we order g cubed for the number
of non-terminals in the grammar.

00:21:32.470 --> 00:21:36.731
So I'm saying that the size of
the set of non-terminals equals g.

00:21:38.040 --> 00:21:43.890
But let me mention for when you guys
are implementing your own version that

00:21:43.890 --> 00:21:48.242
this is the simplistic way of doing it,
which is

00:21:48.242 --> 00:21:54.340
a polynomial algorithm with the right
minimal order of complexity.

00:21:54.340 --> 00:21:58.530
But in practice,
if you want to have a fast,

00:21:58.530 --> 00:22:02.160
PCFG parser,
you don't want to naively do this.

00:22:02.160 --> 00:22:08.030
Rather, you want to be doing some checking
and indexing to make things go fast.

00:22:08.030 --> 00:22:13.080
So, the kind of thing that you want to
do is not just naively iterate over

00:22:13.080 --> 00:22:18.420
all triples of non-terminals,
but instead, to say, well,

00:22:18.420 --> 00:22:24.753
once I've got to here,
I know that I'm loading, say, from 0 to 4,

00:22:24.753 --> 00:22:30.040
and 4 to 7, loading up to 0 to 7.

00:22:30.040 --> 00:22:34.960
So, I know what constituents
I could build over 0 to 4.

00:22:34.960 --> 00:22:40.610
What I actually want to do is say that
each of these things is in this list.

00:22:40.610 --> 00:22:44.730
Okay, tell me what grammar
rules have this as that

00:22:44.730 --> 00:22:46.910
each one of these as if
they're left corner.

00:22:46.910 --> 00:22:50.460
So perhaps you have S goes to NP VP, but

00:22:50.460 --> 00:22:55.610
you might also have NP goes to NP PP.

00:22:56.810 --> 00:23:00.461
So these are both rules that
have NP as their left corner.

00:23:00.461 --> 00:23:05.168
So these are precisely the rules
that are going to be ones that will

00:23:05.168 --> 00:23:09.410
work down here because they
work with this category.

00:23:09.410 --> 00:23:14.609
And so by doing some clever indexing,
you can make things quite a lot faster.

00:23:14.609 --> 00:23:17.017
Okay, so that's the CKY algorithm.

00:23:17.017 --> 00:23:19.606
I'm sure it's kind of
confusing up until now.

00:23:19.606 --> 00:23:23.855
I hope it will become a lot clearer once
we work through an example in the next

00:23:23.855 --> 00:23:24.470
segment.

