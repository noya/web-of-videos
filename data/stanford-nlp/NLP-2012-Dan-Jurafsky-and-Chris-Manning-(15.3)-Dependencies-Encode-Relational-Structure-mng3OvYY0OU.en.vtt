WEBVTT
Kind: captions
Language: en

00:00:00.960 --> 00:00:04.535
In this segment, I'm going to
show you the dependency syntaxes,

00:00:04.535 --> 00:00:08.510
a very natural representation for
relation extraction applications.

00:00:11.120 --> 00:00:14.590
One domain in which a lot of work
has been done in relation extraction

00:00:14.590 --> 00:00:16.970
is in the biomedical text domain.

00:00:16.970 --> 00:00:21.090
So here, for example, we have the
sentence, the results demonstrated that

00:00:21.090 --> 00:00:26.430
KaiC interacts rhythmically with SasA,
KaiA and KaiB.

00:00:26.430 --> 00:00:30.570
And what we'd like to get out of
that is a protein interaction event.

00:00:30.570 --> 00:00:35.190
So here's the interacts that is sort
of indicates the relation, and these

00:00:35.190 --> 00:00:40.720
are the proteins involved, and there are a
bunch of other proteins involved as well.

00:00:40.720 --> 00:00:44.330
Well, the point we get out
of here is that if we can

00:00:45.900 --> 00:00:50.878
have this kind of dependency syntax, and
it's very easy starting from here to

00:00:50.878 --> 00:00:55.690
follow along the arguments of the subject
and the preposition with, and

00:00:55.690 --> 00:00:59.620
to easily see the relation
that we'd like to get out.

00:00:59.620 --> 00:01:05.460
And if we are just a little bit clever, we
can then also follow along the conjunction

00:01:05.460 --> 00:01:12.550
relations, and see that KaiC is also
interacting with these other two proteins.

00:01:12.550 --> 00:01:18.040
And that's something that a lot
of people have worked on.

00:01:18.040 --> 00:01:22.520
In particular, one representation that's
being widely used for relation extraction

00:01:22.520 --> 00:01:28.030
applications in biomedicine is
the Stanford dependencies representation.

00:01:28.030 --> 00:01:33.090
So the basic form of this representation
is as a projective dependency tree.

00:01:33.090 --> 00:01:35.510
And it was designed that way, so

00:01:35.510 --> 00:01:40.700
it could be easily generated by
post-processing off free structured tree.

00:01:40.700 --> 00:01:43.780
So if you have a notion of headedness
in a phrase structure tree,

00:01:43.780 --> 00:01:50.260
the Stanford dependency software provides
a set of matching pattern rules that will

00:01:50.260 --> 00:01:55.015
then type the dependency relations, and
give you out a Stanford dependency tree.

00:01:55.015 --> 00:02:01.170
But Stanford dependencies can also
be a noun pristinely odd generated

00:02:01.170 --> 00:02:06.370
directly by dependency pauses, such as
the MaltParser we looked at recently.

00:02:07.840 --> 00:02:11.410
Okay, so this is roughly what
the representation looks like.

00:02:11.410 --> 00:02:17.480
So it's just as we saw before with the
words connected by type dependency arcs.

00:02:19.970 --> 00:02:24.395
But something that has been explored in
the Stanford dependencies framework is

00:02:24.395 --> 00:02:28.330
starting from that basic
dependencies representation.

00:02:28.330 --> 00:02:32.560
Let's make some changes to it to
facilitate relation extraction

00:02:32.560 --> 00:02:34.130
applications.

00:02:34.130 --> 00:02:39.540
And the idea here is to emphasize
the relationships between

00:02:39.540 --> 00:02:42.890
content words that are useful for
relation extraction applications.

00:02:42.890 --> 00:02:45.740
Let me give a couple of examples.

00:02:45.740 --> 00:02:51.970
So one example is that commonly,
you'll have a content word like based,

00:02:51.970 --> 00:02:55.990
and where the company here is based,
Los Angeles.

00:02:55.990 --> 00:03:01.130
And it's separated by this preposition,
in, a function word.

00:03:01.130 --> 00:03:04.340
And you can think of these function
words as really functioning

00:03:04.340 --> 00:03:07.170
like case markers in
a lot of other languages.

00:03:07.170 --> 00:03:11.830
So it seemed more useful if we
directly connected based LA, and

00:03:11.830 --> 00:03:16.220
we introduced a relationship of prep_in.

00:03:16.220 --> 00:03:20.881
And so that's what we do and
we simplify the structure.

00:03:20.881 --> 00:03:24.729
But there's some other places too
in which we can do a better job

00:03:24.729 --> 00:03:29.682
at representing the semantics with some
modifications of the graph structure.

00:03:29.682 --> 00:03:34.685
And so a particular place of that is
these coordination relationships.

00:03:34.685 --> 00:03:39.350
So we very directly got here,
that Bell makes products, but

00:03:39.350 --> 00:03:44.300
we'd also like to get out that
Bell distributes products.

00:03:44.300 --> 00:03:49.020
Well, one way we can do
that is by recognizing

00:03:49.020 --> 00:03:53.570
this and relationship,
and saying okay, well,

00:03:53.570 --> 00:03:58.905
that means that Bell
should also be the subject

00:03:58.905 --> 00:04:03.680
of distributing and

00:04:03.680 --> 00:04:06.650
what they distribute is products.

00:04:09.600 --> 00:04:15.730
And similarly, down here,
we can recognized

00:04:15.730 --> 00:04:21.840
that they're computer products
as well as electronic products.

00:04:21.840 --> 00:04:24.880
So we can make those
changes to the graph and

00:04:24.880 --> 00:04:27.760
get a kind of reduced
graph representation.

00:04:28.930 --> 00:04:33.780
Now, once you do this, there are some
things that are not as simple.

00:04:33.780 --> 00:04:37.920
In particular, if you look at this
structure, it's no longer a dependency

00:04:37.920 --> 00:04:43.050
tree because we have multiple
arcs pointing at this node,

00:04:43.050 --> 00:04:45.750
and multiple arcs pointing at this node.

00:04:47.610 --> 00:04:48.560
But on the other hand,

00:04:48.560 --> 00:04:54.720
the relations that we'd like to extract
are represented much more directly.

00:04:54.720 --> 00:04:58.830
And let me just show you one graph
that gives an indication of this.

00:04:58.830 --> 00:05:06.640
So this was a graph that was originally
put together by Jari BjÃ¶rne et al,

00:05:06.640 --> 00:05:12.750
who, with the team that won the BioNLP
2009, shared task on relation extraction

00:05:12.750 --> 00:05:17.670
using as the representational
substrates Stanford dependencies.

00:05:17.670 --> 00:05:23.190
And what they wanted to illustrate with
this graph is how much more effective

00:05:23.190 --> 00:05:29.290
dependency structures were at linking
up the words that you wanted to extract

00:05:29.290 --> 00:05:34.250
in a relation, then simply looking for
words in the linear context.

00:05:35.900 --> 00:05:41.110
So here,
what we have is that this is the distance

00:05:41.110 --> 00:05:45.990
which can be measured either by just
counting words to the left or right, or

00:05:45.990 --> 00:05:49.650
by counting the number of dependency
arcs that you have to follow,

00:05:49.650 --> 00:05:53.240
and this is the percent
of time that it occurred.

00:05:53.240 --> 00:05:56.750
And so what you see is,
if you just look at linear distance,

00:05:56.750 --> 00:06:02.040
there are lots of times that
there are arguments of relations

00:06:02.040 --> 00:06:06.670
that you want to connect out that are 4,
5, 6, 7, 8 words away.

00:06:06.670 --> 00:06:11.519
In fact, there's even a pretty
large residue here, well over 10%,

00:06:11.519 --> 00:06:17.080
where the linear distance in a way
in words is greater than ten words.

00:06:17.080 --> 00:06:21.300
If on the other hand though,
you try and identify,

00:06:21.300 --> 00:06:25.520
relate the arguments of relations
by looking at dependency distance,

00:06:25.520 --> 00:06:30.630
then what you discover is that
the vast majority of the arguments

00:06:30.630 --> 00:06:36.345
are very close by neighbors in terms
of dependency distance, so about 40%,

00:06:36.345 --> 00:06:41.890
7% of them are direct dependencies,
and another 30% a distance 2.

00:06:41.890 --> 00:06:43.870
So take those together, and

00:06:43.870 --> 00:06:48.500
that's greater than three-quarters of
the dependencies that you want to find.

00:06:48.500 --> 00:06:51.470
And then, this number trails away quickly.

00:06:51.470 --> 00:06:53.850
So there are virtually no

00:06:53.850 --> 00:06:58.680
arguments of relations that aren't fairly
close together in dependency distance.

00:06:58.680 --> 00:07:04.540
And it's precisely because of this
reason that you can get a lot of mileage

00:07:04.540 --> 00:07:09.350
in doing relation extraction by having
a representation like dependency syntax.

00:07:11.770 --> 00:07:16.080
Okay, I hope that's given you some idea
of why knowing about syntax is useful

00:07:16.080 --> 00:07:19.470
when you want to do various somatic
tasks in natural language processing.

