Lecture-1-|-Natural-Language-Processing-with-Deep-Learning	stanford-nlp\Lecture-1-_-Natural-Language-Processing-with-Deep-Learning-OQQ-W_63UgQ.en.vtt	https://www.youtube.com/watch?v=OQQ-W_63UgQ	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 1 introduces the concept of Natural Language Processing (NLP) and the problems NLP faces today. The concept of representing words as numeric vectors is then introduced, and popular approaches to designing word vectors are discussed.  Key phra
Lecture-10:-Neural-Machine-Translation-and-Models-with-Attention	stanford-nlp\Lecture-10---Neural-Machine-Translation-and-Models-with-Attention-IxQtK2SjWWM.en.vtt	https://www.youtube.com/watch?v=IxQtK2SjWWM	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 10 introduces translation, machine translation, and neural machine translation. Google's new NMT is highlighted followed by sequence models with attention as well as sequence model decoders.  --------------------------------------------------
Lecture-11:-Gated-Recurrent-Units-and-Further-Topics-in-NMT	stanford-nlp\Lecture-11---Gated-Recurrent-Units-and-Further-Topics-in-NMT-6_MO12fPC-0.en.vtt	https://www.youtube.com/watch?v=6_MO12fPC-0	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 11 provides a final look at gated recurrent units like GRUs/LSTMs followed by machine translation evaluation, dealing with large vocabulary output, and sub-word and character-based models. Also includes research highlight ""Lip reading senten
Lecture-12:-End-to-End-Models-for-Speech-Processing	stanford-nlp\Lecture-12---End-to-End-Models-for-Speech-Processing-3MjIkWxXigM.en.vtt	https://www.youtube.com/watch?v=3MjIkWxXigM	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 12 looks at traditional speech recognition systems and motivation for end-to-end models. Also covered are Connectionist Temporal Classification (CTC) and Listen Attend and Spell (LAS), a sequence-to-sequence based model for speech recognition
Lecture-13:-Convolutional-Neural-Networks	stanford-nlp\Lecture-13---Convolutional-Neural-Networks-Lg6MZw_OOLI.en.vtt	https://www.youtube.com/watch?v=Lg6MZw_OOLI	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 13 provides a mini tutorial on Azure and GPUs followed by research highlight "Character-Aware Neural Language Models." Also covered are CNN Variant 1 and 2 as well as comparison between sentence models: BoV, RNNs, CNNs.  ---------------------
Lecture-14:-Tree-Recursive-Neural-Networks-and-Constituency-Parsing	stanford-nlp\Lecture-14---Tree-Recursive-Neural-Networks-and-Constituency-Parsing-RfwgqPkWZ1w.en.vtt	https://www.youtube.com/watch?v=RfwgqPkWZ1w	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 14 looks at compositionality and recursion followed by structure prediction with simple Tree RNN: Parsing. Research highlight ""Deep Reinforcement Learning for Dialogue Generation"" is covered is backpropagation through Structure.  Key phrase
Lecture-15:-Coreference-Resolution	stanford-nlp\Lecture-15---Coreference-Resolution-rpwEWLaueRk.en.vtt	https://www.youtube.com/watch?v=rpwEWLaueRk	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 15 covers what is coreference via a working example. Also includes research highlight "Summarizing Source Code", an introduction to coreference resolution and neural coreference resolution.  ---------------------------------------------------
Lecture-16:-Dynamic-Neural-Networks-for-Question-Answering	stanford-nlp\Lecture-16---Dynamic-Neural-Networks-for-Question-Answering-T3octNTE7Is.en.vtt	https://www.youtube.com/watch?v=T3octNTE7Is	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 16 addresses the question ""Can all NLP tasks be seen as question answering problems?"".  Key phrases: Coreference Resolution, Dynamic Memory Networks for Question Answering over Text and Images  ----------------------------------------------
Lecture-17:-Issues-in-NLP-and-Possible-Architectures-for-NLP	stanford-nlp\Lecture-17---Issues-in-NLP-and-Possible-Architectures-for-NLP-B4v545V3Dq0.en.vtt	https://www.youtube.com/watch?v=B4v545V3Dq0	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 17 looks at solving language, efficient tree-recursive models SPINN and SNLI, as well as research highlight "Learning to compose for QA." Also covered are interlude pointer/copying models and sub-word and character-based models.  ------------
Lecture-18:-Tackling-the-Limits-of-Deep-Learning-for-NLP	stanford-nlp\Lecture-18---Tackling-the-Limits-of-Deep-Learning-for-NLP-JYwNmSe4HqE.en.vtt	https://www.youtube.com/watch?v=JYwNmSe4HqE	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 18 looks at tackling the limits of deep learning for NLP followed by a few presentations.  -------------------------------------------------------------------------------  Natural Language Processing with Deep Learning  Instructors: - Chris M
Lecture-2-|-Word-Vector-Representations:-word2vec	stanford-nlp\Lecture-2-_-Word-Vector-Representations---word2vec-ERibwqs9p38.en.vtt	https://www.youtube.com/watch?v=ERibwqs9p38	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 2 continues the discussion on the concept of representing words as numeric vectors and popular approaches to designing word vectors.  Key phrases: Natural Language Processing. Word Vectors. Singular Value Decomposition. Skip-gram. Continuous 
Lecture-3-|-GloVe:-Global-Vectors-for-Word-Representation	stanford-nlp\Lecture-3-_-GloVe---Global-Vectors-for-Word-Representation-ASn7ExxLZws.en.vtt	https://www.youtube.com/watch?v=ASn7ExxLZws	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 3 introduces the GloVe model for training word vectors. Then it extends our discussion of word vectors (interchangeably called word embeddings) by seeing how they can be evaluated intrinsically and extrinsically. As we proceed, we discuss the
Lecture-4:-Word-Window-Classification-and-Neural-Networks	stanford-nlp\Lecture-4---Word-Window-Classification-and-Neural-Networks-uc2_iwVqrRI.en.vtt	https://www.youtube.com/watch?v=uc2_iwVqrRI	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 4 introduces single and multilayer neural networks, and how they can be used for classification purposes.  Key phrases: Neural networks. Forward computation. Backward propagation. Neuron Units. Max-margin Loss. Gradient checks. Xavier paramet
Lecture-5:-Backpropagation-and-Project-Advice	stanford-nlp\Lecture-5---Backpropagation-and-Project-Advice-isPiE-DBagM.en.vtt	https://www.youtube.com/watch?v=isPiE-DBagM	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 5 discusses how neural networks can be trained using a distributed gradient descent technique known as back propagation.  Key phrases: Neural networks. Forward computation. Backward propagation. Neuron Units. Max-margin Loss. Gradient checks.
Lecture-6:-Dependency-Parsing	stanford-nlp\Lecture-6---Dependency-Parsing-PVShkZgXznc.en.vtt	https://www.youtube.com/watch?v=PVShkZgXznc	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 6 covers dependency parsing which is the task of analyzing the syntactic dependency structure of a given input sentence S. The output of a dependency parser is a dependency tree where the words of the input sentence are connected by typed dep
Lecture-7:-Introduction-to-TensorFlow	stanford-nlp\Lecture-7---Introduction-to-TensorFlow-PicxU81owCs.en.vtt	https://www.youtube.com/watch?v=PicxU81owCs	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 7 covers Tensorflow. TensorFlow is an open source software library for numerical computation using data flow graphs. It was originally developed by researchers and engineers working on the Google Brain Team within Googles Machine Intelligence
Lecture-8:-Recurrent-Neural-Networks-and-Language-Models	stanford-nlp\Lecture-8---Recurrent-Neural-Networks-and-Language-Models-Keqep_PKrY8.en.vtt	https://www.youtube.com/watch?v=Keqep_PKrY8	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 8 covers traditional language models, RNNs, and RNN language models. Also reviewed are important training problems and tricks, RNNs for other sequence tasks, and bidirectional and deep RNNs.  --------------------------------------------------
Lecture-9:-Machine-Translation-and-Advanced-Recurrent-LSTMs-and-GRUs	stanford-nlp\Lecture-9---Machine-Translation-and-Advanced-Recurrent-LSTMs-and-GRUs-QuELiw8tbx8.en.vtt	https://www.youtube.com/watch?v=QuELiw8tbx8	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	Lecture 9 recaps the most important concepts and equations covered so far followed by machine translation and fancy RNN models tackling MT.  Key phrases: Language Models. RNN. Bi-directional RNN. Deep RNN. GRU. LSTM.  --------------------------------
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(1.1)-Intro-to-NLP	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(1.1)-Intro-to-NLP-zQ6gzQ5YZ8o.en.vtt	https://www.youtube.com/watch?v=zQ6gzQ5YZ8o	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(1.2)-Regular-Expressions-in-Practical-NLP	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(1.2)-Regular-Expressions-in-Practical-NLP-R545HdFX_pc.en.vtt	https://www.youtube.com/watch?v=R545HdFX_pc	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(1.2)-Regular-Expressions	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(1.2)-Regular-Expressions-8rxdwu_-mvg.en.vtt	https://www.youtube.com/watch?v=8rxdwu_-mvg	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(1.3)-Word-Tokenization	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(1.3)-Word-Tokenization-dzSQ0-SEqxQ.en.vtt	https://www.youtube.com/watch?v=dzSQ0-SEqxQ	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(1.4)-Word-Normalization-and-Stemming	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(1.4)-Word-Normalization-and-Stemming-rHWCHeDmXFc.en.vtt	https://www.youtube.com/watch?v=rHWCHeDmXFc	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(1.5)-Sentence-Segmentation	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(1.5)-Sentence-Segmentation-iIFGqZm1Z4U.en.vtt	https://www.youtube.com/watch?v=iIFGqZm1Z4U	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(10.1)-The-Maximum-Entropy-Model-Presentation	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(10.1)-The-Maximum-Entropy-Model-Presentation-ElxyTbjlkig.en.vtt	https://www.youtube.com/watch?v=ElxyTbjlkig	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(10.2)-Feature-Overlap/Feature-Interaction	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(10.2)-Feature-Overlap_Feature-Interaction-maBBMXzMNjo.en.vtt	https://www.youtube.com/watch?v=maBBMXzMNjo	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(10.3)-Conditional-Maxent-Models-for-Classification	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(10.3)-Conditional-Maxent-Models-for-Classification-JYoUWM-ZHik.en.vtt	https://www.youtube.com/watch?v=JYoUWM-ZHik	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(10.4)-Smoothing/Regularization/Priors-for-Maxent-Models	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(10.4)-Smoothing_Regularization_Priors-for-Maxent-Models-0rWjWv_pASo.en.vtt	https://www.youtube.com/watch?v=0rWjWv_pASo	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(11.1)-An-Introduction-to-Parts-of-Speech-and-POS-Tagging	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(11.1)-An-Introduction-to-Parts-of-Speech-and-POS-Tagging-_IKLe1Xfe30.en.vtt	https://www.youtube.com/watch?v=_IKLe1Xfe30	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(11.2)-Some-Methods-for-Sequence-Models-for-POS-Tagging	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(11.2)-Some-Methods-for-Sequence-Models-for-POS-Tagging-SkaPqBDPzKc.en.vtt	https://www.youtube.com/watch?v=SkaPqBDPzKc	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(12.2)-Empirical/Data-Driven-Approach-to-Parsing	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(12.2)-Empirical_Data-Driven-Approach-to-Parsing-NqM0ec6ikUc.en.vtt	https://www.youtube.com/watch?v=NqM0ec6ikUc	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(12.2)-Syntactic-Structure:-Constituency-vs.-Dependency	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(12.2)-Syntactic-Structure---Constituency-vs.-Dependency-svswQnMSPDM.en.vtt	https://www.youtube.com/watch?v=svswQnMSPDM	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(12.3)-The-Exponential-Problem-in-Parsing	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(12.3)-The-Exponential-Problem-in-Parsing-Fp-JzljFqPs.en.vtt	https://www.youtube.com/watch?v=Fp-JzljFqPs	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(13.1)-CFGs-and-PCFGs	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(13.1)-CFGs-and-PCFGs-vcOkZBrgFuE.en.vtt	https://www.youtube.com/watch?v=vcOkZBrgFuE	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(13.2)-Grammar-Transforms	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(13.2)-Grammar-Transforms-J1sYddZ_fl8.en.vtt	https://www.youtube.com/watch?v=J1sYddZ_fl8	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(13.3)-CKY-Parsing	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(13.3)-CKY-Parsing-I89KPQWylIU.en.vtt	https://www.youtube.com/watch?v=I89KPQWylIU	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(13.4)-CKY-Example	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(13.4)-CKY-Example-mjXUBvOXrHU.en.vtt	https://www.youtube.com/watch?v=mjXUBvOXrHU	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(13.5)-Constituency-Parser-Evaluation	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(13.5)-Constituency-Parser-Evaluation-5HxiCZVa4J0.en.vtt	https://www.youtube.com/watch?v=5HxiCZVa4J0	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(14.1)-Lexicalization-of-PCFGs	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(14.1)-Lexicalization-of-PCFGs-Bp41ErrGw44.en.vtt	https://www.youtube.com/watch?v=Bp41ErrGw44	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(14.2)-Charniak's-Model	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(14.2)-Charniaks-Model-3abwEBmFcfg.en.vtt	https://www.youtube.com/watch?v=3abwEBmFcfg	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(14.3)-PCFG-Independence-Assumptions	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(14.3)-PCFG-Independence-Assumptions-6rJuZYI90hk.en.vtt	https://www.youtube.com/watch?v=6rJuZYI90hk	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(14.4)-The-Return-of-Unlexicalized-PCFGs	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(14.4)-The-Return-of-Unlexicalized-PCFGs-TArRDS2kWzg.en.vtt	https://www.youtube.com/watch?v=TArRDS2kWzg	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(14.5)-Latent-Variable-PCFGs	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(14.5)-Latent-Variable-PCFGs-B5M9pM7aOkw.en.vtt	https://www.youtube.com/watch?v=B5M9pM7aOkw	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(15.1)-Dependency-Parsing-Introduction	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(15.1)-Dependency-Parsing-Introduction-5-ME6ktPAck.en.vtt	https://www.youtube.com/watch?v=5-ME6ktPAck	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(15.2)-Greedy-Transition-Based-Parsing	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(15.2)-Greedy-Transition-Based-Parsing-ZxuvhSscUwQ.en.vtt	https://www.youtube.com/watch?v=ZxuvhSscUwQ	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(15.3)-Dependencies-Encode-Relational-Structure	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(15.3)-Dependencies-Encode-Relational-Structure-mng3OvYY0OU.en.vtt	https://www.youtube.com/watch?v=mng3OvYY0OU	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(17.1)-Introduction-to-Information-Retrieval	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(17.1)-Introduction-to-Information-Retrieval-j_ICWJctAfY.en.vtt	https://www.youtube.com/watch?v=j_ICWJctAfY	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(17.2)-Term-Document-Incidence-Matrices	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(17.2)-Term-Document-Incidence-Matrices-b6cjKqTE04s.en.vtt	https://www.youtube.com/watch?v=b6cjKqTE04s	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(17.3)-The-Inverted-Index	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(17.3)-The-Inverted-Index-eNw-gLdTJ_s.en.vtt	https://www.youtube.com/watch?v=eNw-gLdTJ_s	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(17.4)-Query-Processing-with-the-Inverted-Index	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(17.4)-Query-Processing-with-the-Inverted-Index-LxdyZBBO9Wg.en.vtt	https://www.youtube.com/watch?v=LxdyZBBO9Wg	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(17.5)-Phrase-Queries-and-Positional-Indexes	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(17.5)-Phrase-Queries-and-Positional-Indexes-rbUyRtSaRxk.en.vtt	https://www.youtube.com/watch?v=rbUyRtSaRxk	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.1)-Introducing-Ranked-Retrieval	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.1)-Introducing-Ranked-Retrieval-AOQlY-jE-PQ.en.vtt	https://www.youtube.com/watch?v=AOQlY-jE-PQ	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.2)-Scoring-with-the-Jaccard-Coefficient	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.2)-Scoring-with-the-Jaccard-Coefficient-V8x3g7ata_s.en.vtt	https://www.youtube.com/watch?v=V8x3g7ata_s	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.3)-Term-Frequency-Weighting	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.3)-Term-Frequency-Weighting-EyyfelaGYK0.en.vtt	https://www.youtube.com/watch?v=EyyfelaGYK0	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.4)-Inverse-Document-Frequency-Weighting	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.4)-Inverse-Document-Frequency-Weighting-zQeYrMh5GG0.en.vtt	https://www.youtube.com/watch?v=zQeYrMh5GG0	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.5)-TF-IDF-Weighting	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.5)-TF-IDF-Weighting-zWX0ApyUqRk.en.vtt	https://www.youtube.com/watch?v=zWX0ApyUqRk	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.6)-The-Vector-Space-Model	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.6)-The-Vector-Space-Model-yvNt_qDRbDQ.en.vtt	https://www.youtube.com/watch?v=yvNt_qDRbDQ	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.7)-Calculating-TF-IDF-Cosine-Scores	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.7)-Calculating-TF-IDF-Cosine-Scores-eyJLEaPqTso.en.vtt	https://www.youtube.com/watch?v=eyJLEaPqTso	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.8)-Evaluating-Search-Engines	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(18.8)-Evaluating-Search-Engines-5t_Lp1JMJFM.en.vtt	https://www.youtube.com/watch?v=5t_Lp1JMJFM	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(19.1)-Word-Senses-and-Word-Relations	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(19.1)-Word-Senses-and-Word-Relations-rihmpHrm350.en.vtt	https://www.youtube.com/watch?v=rihmpHrm350	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(19.2)-WordNet-and-Other-Online-Thesauri	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(19.2)-WordNet-and-Other-Online-Thesauri-8DApiZ1yLJo.en.vtt	https://www.youtube.com/watch?v=8DApiZ1yLJo	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(19.3)-Word-Similarity-and-Thesaurus-Methods	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(19.3)-Word-Similarity-and-Thesaurus-Methods-KmDCt-q-3mg.en.vtt	https://www.youtube.com/watch?v=KmDCt-q-3mg	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(19.4)-Word-Similarity:-Distributional-Similarity-I	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(19.4)-Word-Similarity---Distributional-Similarity-I-QYYqOCQH0DM.en.vtt	https://www.youtube.com/watch?v=QYYqOCQH0DM	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(19.5)-Word-Similarity:-Distributional-Similarity-II	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(19.5)-Word-Similarity---Distributional-Similarity-II-1B9pca2cKOk.en.vtt	https://www.youtube.com/watch?v=1B9pca2cKOk	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(2.1)-Defining-Minimum-Edit-Distance	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(2.1)-Defining-Minimum-Edit-Distance-jhSdB36RYWk.en.vtt	https://www.youtube.com/watch?v=jhSdB36RYWk	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(2.2)-Computing-Minimum-Edit-Distance	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(2.2)-Computing-Minimum-Edit-Distance-Q7QQCNM7AJ4.en.vtt	https://www.youtube.com/watch?v=Q7QQCNM7AJ4	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(2.3)-Backtrace-for-Computing-Alignments	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(2.3)-Backtrace-for-Computing-Alignments-F5QiG4S3jRs.en.vtt	https://www.youtube.com/watch?v=F5QiG4S3jRs	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(2.4)-Weighted-Minimum-Edit-Distance	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(2.4)-Weighted-Minimum-Edit-Distance-DfdRSL0jo5s.en.vtt	https://www.youtube.com/watch?v=DfdRSL0jo5s	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(2.5)-Minimum-Edit-Distance-in-Computational-Biology	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(2.5)-Minimum-Edit-Distance-in-Computational-Biology-_hVeYOgb3zs.en.vtt	https://www.youtube.com/watch?v=_hVeYOgb3zs	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(20.1)-What-is-Question-Answering?	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(20.1)-What-is-Question-Answering-pH3Ks_Qumas.en.vtt	https://www.youtube.com/watch?v=pH3Ks_Qumas	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(20.2)-Answer-Types-and-Query-Formulation	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(20.2)-Answer-Types-and-Query-Formulation-2O67yjOo5XA.en.vtt	https://www.youtube.com/watch?v=2O67yjOo5XA	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(20.3)-Passage-Retrieval-and-Answer-Extraction	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(20.3)-Passage-Retrieval-and-Answer-Extraction-Dv4Tu_gmuuw.en.vtt	https://www.youtube.com/watch?v=Dv4Tu_gmuuw	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(20.4)-Using-Knowledge-in-QA	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(20.4)-Using-Knowledge-in-QA-PbCHPRgiqd0.en.vtt	https://www.youtube.com/watch?v=PbCHPRgiqd0	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(20.5)-Advanced:-Answering-Complex-Questions	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(20.5)-Advanced---Answering-Complex-Questions-OQqo527P-AM.en.vtt	https://www.youtube.com/watch?v=OQqo527P-AM	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(21.1)-Introduction-to-Summarization	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(21.1)-Introduction-to-Summarization-04MnRcSLeV0.en.vtt	https://www.youtube.com/watch?v=04MnRcSLeV0	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(21.2)-Generating-Snippets	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(21.2)-Generating-Snippets-3MeAR8_Btx4.en.vtt	https://www.youtube.com/watch?v=3MeAR8_Btx4	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(21.3)-Evaluating-Summaries:-ROUGE	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(21.3)-Evaluating-Summaries---ROUGE-virRuxlM4qM.en.vtt	https://www.youtube.com/watch?v=virRuxlM4qM	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(21.4)-Summarizing-Multiple-Documents	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(21.4)-Summarizing-Multiple-Documents-kW1OVQBmLKU.en.vtt	https://www.youtube.com/watch?v=kW1OVQBmLKU	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.1)-Introduction-to-N-grams	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.1)-Introduction-to-N-grams-O7k8M8FwGLg.en.vtt	https://www.youtube.com/watch?v=O7k8M8FwGLg	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.2)-Estimating-N-gram-Probabilities	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.2)-Estimating-N-gram-Probabilities-JfOdKOmYtqI.en.vtt	https://www.youtube.com/watch?v=JfOdKOmYtqI	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.3)-Evaluation-and-Perplexity	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.3)-Evaluation-and-Perplexity-7D7vueT-ac0.en.vtt	https://www.youtube.com/watch?v=7D7vueT-ac0	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.4)-Generalization-and-Zeros	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.4)-Generalization-and-Zeros-2OJP6SgYIKY.en.vtt	https://www.youtube.com/watch?v=2OJP6SgYIKY	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.5)-Smoothing:-Add-One	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.5)-Smoothing---Add-One-DnPk_RpxITM.en.vtt	https://www.youtube.com/watch?v=DnPk_RpxITM	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.6)-Interpolation	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.6)-Interpolation-oZHRFj8heWM.en.vtt	https://www.youtube.com/watch?v=oZHRFj8heWM	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.7)-Good-Turing-Smoothing	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.7)-Good-Turing-Smoothing-nqWuyWVxAYE.en.vtt	https://www.youtube.com/watch?v=nqWuyWVxAYE	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.8)-Kneser-Ney-Smoothing	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(3.8)-Kneser-Ney-Smoothing-dnj8QlJ6SJQ.en.vtt	https://www.youtube.com/watch?v=dnj8QlJ6SJQ	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(4.1)-The-Spelling-Correction-Task	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(4.1)-The-Spelling-Correction-Task-tD3Fp-dc0gs.en.vtt	https://www.youtube.com/watch?v=tD3Fp-dc0gs	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(4.2)-The-Noisy-Channel-Model-of-Spelling	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(4.2)-The-Noisy-Channel-Model-of-Spelling-HMzvU-hbV3c.en.vtt	https://www.youtube.com/watch?v=HMzvU-hbV3c	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(4.3)-Real-Word-Spelling-Correction	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(4.3)-Real-Word-Spelling-Correction-dAbLZIAsHOE.en.vtt	https://www.youtube.com/watch?v=dAbLZIAsHOE	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(4.4)-State-of-the-Art-Systems	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(4.4)-State-of-the-Art-Systems-Lgih_o9hpY8.en.vtt	https://www.youtube.com/watch?v=Lgih_o9hpY8	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.1)-What-is-Text-Classification?	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.1)-What-is-Text-Classification-MgjrV_oXCrk.en.vtt	https://www.youtube.com/watch?v=MgjrV_oXCrk	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.2)-Naive-Bayes	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.2)-Naive-Bayes-S_Jdoubh-fE.en.vtt	https://www.youtube.com/watch?v=S_Jdoubh-fE	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.3)-Formalizing-the-Naive-Bayes-Classifier	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.3)-Formalizing-the-Naive-Bayes-Classifier-AAcIGGv7Q2g.en.vtt	https://www.youtube.com/watch?v=AAcIGGv7Q2g	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.4)-Naive-Bayes:-Learning	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.4)-Naive-Bayes---Learning-gSWf4EHvgBo.en.vtt	https://www.youtube.com/watch?v=gSWf4EHvgBo	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.5)-Naive-Bayes:-Relationship-to-Language-Modeling	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.5)-Naive-Bayes---Relationship-to-Language-Modeling-x2sZQvIeYLg.en.vtt	https://www.youtube.com/watch?v=x2sZQvIeYLg	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.6)-Multinomial-Naive-Bayes:-A-Worked-Example	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.6)-Multinomial-Naive-Bayes---A-Worked-Example-HQG7hZRoCpE.en.vtt	https://www.youtube.com/watch?v=HQG7hZRoCpE	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.7)-Precision	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.7)-Precision-0lY6D5WOzC8.en.vtt	https://www.youtube.com/watch?v=0lY6D5WOzC8	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.8)-Text-Classification:-Evaluation	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.8)-Text-Classification---Evaluation-vDpGw-r-uNQ.en.vtt	https://www.youtube.com/watch?v=vDpGw-r-uNQ	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.9)-Practical-Issues-in-Text-Classification	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(5.9)-Practical-Issues-in-Text-Classification-yvfZdqt2qek.en.vtt	https://www.youtube.com/watch?v=yvfZdqt2qek	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(6.1)-What-is-Sentiment-Analysis?	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(6.1)-What-is-Sentiment-Analysis-uXu2uEubV9Q.en.vtt	https://www.youtube.com/watch?v=uXu2uEubV9Q	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(6.2)-Sentiment-Analysis:-A-Baseline-Algorithm	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(6.2)-Sentiment-Analysis---A-Baseline-Algorithm-eSfE1gI9ckU.en.vtt	https://www.youtube.com/watch?v=eSfE1gI9ckU	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(6.3)-Sentiment-Lexicons	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(6.3)-Sentiment-Lexicons-WfqRBYMuVcM.en.vtt	https://www.youtube.com/watch?v=WfqRBYMuVcM	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(6.4)-Learning-Sentiment-Lexicons	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(6.4)-Learning-Sentiment-Lexicons-45Jm3DLPG14.en.vtt	https://www.youtube.com/watch?v=45Jm3DLPG14	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(6.5)-Other-Sentiment-Tasks	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(6.5)-Other-Sentiment-Tasks-igfaZhB37HI.en.vtt	https://www.youtube.com/watch?v=igfaZhB37HI	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(7.1)-Generative-vs.-Discriminative-Models	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(7.1)-Generative-vs.-Discriminative-Models-cWxJyT1d6pY.en.vtt	https://www.youtube.com/watch?v=cWxJyT1d6pY	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(7.2)-Making-Features-from-Text-for-Discriminative-NLP	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(7.2)-Making-Features-from-Text-for-Discriminative-NLP-J2ujeDcW-Do.en.vtt	https://www.youtube.com/watch?v=J2ujeDcW-Do	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(7.3)-Feature-Based-Linear-Classifiers	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(7.3)-Feature-Based-Linear-Classifiers-iq5fa3cI50E.en.vtt	https://www.youtube.com/watch?v=iq5fa3cI50E	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(7.4)-Building-a-Maxent-Model:-The-Nuts-and-Bolts	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(7.4)-Building-a-Maxent-Model---The-Nuts-and-Bolts-g9NOP_AqrcE.en.vtt	https://www.youtube.com/watch?v=g9NOP_AqrcE	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(7.5)-Generative-vs.-Discriminative-Models:-Overcounting	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(7.5)-Generative-vs.-Discriminative-Models---Overcounting-4874uV6mvHI.en.vtt	https://www.youtube.com/watch?v=4874uV6mvHI	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(7.6)-Maximizing-the-Likelihood	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(7.6)-Maximizing-the-Likelihood-0qBmP4zcI0Y.en.vtt	https://www.youtube.com/watch?v=0qBmP4zcI0Y	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(8.1)-Introduction-to-Information-Extraction	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(8.1)-Introduction-to-Information-Extraction-yfAZAo_GYWQ.en.vtt	https://www.youtube.com/watch?v=yfAZAo_GYWQ	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(8.2)-Evaluation-of-Named-Entity-Recognition	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(8.2)-Evaluation-of-Named-Entity-Recognition-uPU2oZM15I8.en.vtt	https://www.youtube.com/watch?v=uPU2oZM15I8	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(8.3)-Sequence-Models-for-Named-Entity-Recognition	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(8.3)-Sequence-Models-for-Named-Entity-Recognition-766a76-HMP4.en.vtt	https://www.youtube.com/watch?v=766a76-HMP4	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(8.4)-Maximum-Entropy-Sequence-Models	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(8.4)-Maximum-Entropy-Sequence-Models-u47vdOv5Pdk.en.vtt	https://www.youtube.com/watch?v=u47vdOv5Pdk	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(9.1)-What-is-Relation-Extraction?	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(9.1)-What-is-Relation-Extraction-FDfwqAwQxDs.en.vtt	https://www.youtube.com/watch?v=FDfwqAwQxDs	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(9.2)-Using-Patterns-to-Extract-Relations	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(9.2)-Using-Patterns-to-Extract-Relations-VC5VYiUUVe8.en.vtt	https://www.youtube.com/watch?v=VC5VYiUUVe8	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(9.3)-Supervised-Relation-Extraction	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(9.3)-Supervised-Relation-Extraction-y2I_cmpLNA0.en.vtt	https://www.youtube.com/watch?v=y2I_cmpLNA0	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
NLP-2012-Dan-Jurafsky-and-Chris-Manning-(9.4)-Semi-Supervised-and-Unsupervised-Relation-Extraction	stanford-nlp\NLP-2012-Dan-Jurafsky-and-Chris-Manning-(9.4)-Semi-Supervised-and-Unsupervised-Relation-Extraction-BWlEkR6RKN4.en.vtt	https://www.youtube.com/watch?v=BWlEkR6RKN4	PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ	None
Review-Session:-Midterm-Review	stanford-nlp\Review-Session---Midterm-Review-2DYxT4OMAmw.en.vtt	https://www.youtube.com/watch?v=2DYxT4OMAmw	PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6	This midterm review session covers work vectors representations, neural networks and RNNs. Also reviewed is backpropagation, gradient calculation and dependency parsing.  -------------------------------------------------------------------------------
