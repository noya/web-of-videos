WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.965
[MUSIC]

00:00:04.965 --> 00:00:06.197
Stanford University.

00:00:09.536 --> 00:00:11.690
&gt;&gt; Okay, hi everyone.

00:00:11.690 --> 00:00:16.800
So back with lecture 14, so
in today's lecture what I'm gonna do

00:00:16.800 --> 00:00:22.470
is introduce really the last
sort of major architecture for

00:00:22.470 --> 00:00:25.620
neural networks that we're
gonna teach you in this class.

00:00:25.620 --> 00:00:30.760
And so that's going to extend
beyond what we've seen with

00:00:30.760 --> 00:00:36.080
both recurrent neural networks and
convolutional neural networks.

00:00:36.080 --> 00:00:36.610
And today,

00:00:36.610 --> 00:00:42.260
what I'm gonna start to look at Is having
tree structured recursive neural networks.

00:00:42.260 --> 00:00:46.700
So this is a topic that is very
dear to both me and Richard.

00:00:46.700 --> 00:00:51.540
It's sort of dear to me as a linguist
cuz I sort of believe that

00:00:51.540 --> 00:00:56.570
languages have this basic tree structure,
as I'll explain in the coming minutes.

00:00:56.570 --> 00:01:00.890
And it's dear to Richard because
it's what his thesis was about.

00:01:00.890 --> 00:01:04.300
We'll talk [LAUGH] about
some of that work later on.

00:01:05.984 --> 00:01:12.130
So, there's some new stuff here, there's
some stuff that in some sense is the same.

00:01:12.130 --> 00:01:17.190
So, we kind of adopted the name
because of neural networks to refer to

00:01:18.330 --> 00:01:20.030
tree structured neural networks.

00:01:20.030 --> 00:01:23.070
But if you think about it, recursive and

00:01:23.070 --> 00:01:27.840
recurrent are kind of sort of come
from the same Latin root, and

00:01:27.840 --> 00:01:32.642
they're exactly the same
through the first five letters.

00:01:32.642 --> 00:01:37.300
And so, in some sense, it's kind of a form

00:01:37.300 --> 00:01:42.370
of recurrent network that is now done
over a tree topology, as I'll explain.

00:01:42.370 --> 00:01:43.380
And so, more recently,

00:01:43.380 --> 00:01:47.870
people have commonly referred to them as
tree RNNs, sort of emphasizing that more,

00:01:47.870 --> 00:01:52.180
what's different is the geometry
of what you're dealing with.

00:01:52.180 --> 00:01:57.440
And in the course of that I'll talk
also a bit about constituency parsing.

00:01:57.440 --> 00:02:01.000
So, I'll start off with
some of the motivations and

00:02:01.000 --> 00:02:04.350
looking at how these kind of
models can be used for parsing.

00:02:04.350 --> 00:02:09.050
We'll have the research highlight and then
I'll go on with some other stuff with some

00:02:09.050 --> 00:02:13.060
more applications and looking at some
of the sort of better architectures

00:02:13.060 --> 00:02:17.670
that you can then build for
tree recursive neural networks.

00:02:17.670 --> 00:02:21.350
Before getting under way
just quickly reminders, so

00:02:21.350 --> 00:02:25.900
there's some staffing
complications coming up so.

00:02:26.930 --> 00:02:29.620
For Richard,
he's gonna be away on Tuesday.

00:02:29.620 --> 00:02:34.080
So, his office hours are gonna
be after class on Thursday.

00:02:34.080 --> 00:02:37.430
So, come along then to talk to Richard.

00:02:37.430 --> 00:02:42.750
Conversely for me, I also have a couple
of irregularities in my schedule.

00:02:42.750 --> 00:02:47.150
So for tomorrow but the sort of,
the morning SCPD slot,

00:02:47.150 --> 00:02:48.598
there's a linguistic's faculty meeting.

00:02:48.598 --> 00:02:51.530
So, I'm gonna have to move that
to earlier, to nine to ten.

00:02:51.530 --> 00:02:56.440
The afternoon will be the same as
usual for our projects officer hours.

00:02:56.440 --> 00:02:57.290
But then next week,

00:02:57.290 --> 00:03:00.850
I'm going to be away at the end
of the week, Thursday and Friday.

00:03:00.850 --> 00:03:03.580
So, I'm gonna have to
sort of reschedule that.

00:03:03.580 --> 00:03:07.330
And I'm gonna move the afternoon
slot until the following Monday.

00:03:07.330 --> 00:03:12.230
So, look on the calendar and
get straight when those times are.

00:03:12.230 --> 00:03:16.790
But we do still really want people
coming and chatting to us and

00:03:16.790 --> 00:03:21.120
the various other final project
TAs about their projects.

00:03:21.120 --> 00:03:23.200
Assignment four.

00:03:23.200 --> 00:03:26.900
Make sure you're getting something
working using a GPU for our milestone.

00:03:26.900 --> 00:03:30.336
We're seeing a lot more people
using GPUs and that is great.

00:03:30.336 --> 00:03:35.890
Any problems stop by,
one of the TA's office hours or

00:03:35.890 --> 00:03:40.930
coding sessions and get both or
messages and get that sorted out.

00:03:40.930 --> 00:03:45.470
And then, just in general for
final project discussions, please come and

00:03:45.470 --> 00:03:47.430
talk to us about your projects.

00:03:47.430 --> 00:03:52.170
And we've sort of regarded as just really
really important for the final project.

00:03:52.170 --> 00:03:55.820
That you actually have something that
you can run by the end of this week.

00:03:55.820 --> 00:04:01.780
We hope everyone doing their final
projects is in the position where

00:04:01.780 --> 00:04:06.480
they have some data ready to go and they
can run some kind of baseline this week.

00:04:06.480 --> 00:04:10.410
Cuz if you aren't in that position,
it's pretty marginal.

00:04:10.410 --> 00:04:14.040
As whether that things could
possibly come to a good conclusion

00:04:14.040 --> 00:04:16.000
given the time available.

00:04:16.000 --> 00:04:18.930
Any questions about that,
talk to your project mentor.

00:04:20.460 --> 00:04:26.305
Okay, let me go on, so
I just thought I'd start with some

00:04:26.305 --> 00:04:32.945
general remarks about sort of what
kind of structures that we put on,

00:04:32.945 --> 00:04:38.370
language, when in some of these,
NLP and deep learning applications.

00:04:38.370 --> 00:04:40.830
This is just a fun picture for
the sake of it.

00:04:40.830 --> 00:04:47.900
But over at CMU they actually have this
lovely artwork which is the bag of words.

00:04:47.900 --> 00:04:51.020
And you have the bag with words inside it.

00:04:51.020 --> 00:04:55.930
And down on to the floor here,
have full and

00:04:55.930 --> 00:04:59.980
the function words they're
outside the bag of words.

00:04:59.980 --> 00:05:03.930
So, one model of language
that ends up being used

00:05:03.930 --> 00:05:08.460
quite a bit in deep learning and sometimes
very effective as we've discussed

00:05:08.460 --> 00:05:11.000
is you have nothing more
than a bag of words.

00:05:11.000 --> 00:05:16.480
And for some kind of semantic
similarity kind of objectives.

00:05:16.480 --> 00:05:21.850
The sad truth is that our state of the art
isn't really beyond a bag of words.

00:05:21.850 --> 00:05:24.730
So that people have used
clever bag of words models.

00:05:24.730 --> 00:05:28.390
Things like deep averaging networks and
get very good results.

00:05:28.390 --> 00:05:32.270
So, there were papers
at last year's IKWEA.

00:05:32.270 --> 00:05:35.054
So ICLR is this new conference
where a lot of deep learning

00:05:35.054 --> 00:05:39.174
work appears--international conference
on learning representations.

00:05:39.174 --> 00:05:44.440
And so,there was a paper last year from
people at the Toyota Technical Institute

00:05:44.440 --> 00:05:47.170
where essentially their
result was that for

00:05:47.170 --> 00:05:51.640
doing paraphrase detection things have
roughly the same meaning, that they could

00:05:51.640 --> 00:05:57.650
get better results with a sort of
deep averaging network of a sort than

00:05:57.650 --> 00:06:03.160
people had been able to get with any kind
of more complex structured neural model.

00:06:03.160 --> 00:06:05.910
I think that's a sad
result not a good result,

00:06:05.910 --> 00:06:08.640
but that's the current state of the art.

00:06:08.640 --> 00:06:14.570
On the other hand, in linguistics and
in some computational models,

00:06:14.570 --> 00:06:19.660
people attempt to use very
elaborated structures

00:06:19.660 --> 00:06:24.750
of language,
which capture a huge amount of detail.

00:06:24.750 --> 00:06:29.020
You can be at either of those extremes, or

00:06:29.020 --> 00:06:32.030
you can hope to be
somewhere in the middle.

00:06:32.030 --> 00:06:36.770
And if you wanna be somewhere in
the middle and have something that

00:06:36.770 --> 00:06:42.090
roughly captures one of the most
fundamental properties of language,

00:06:42.090 --> 00:06:46.200
it seems like you don't
wanna have word vectors, and

00:06:46.200 --> 00:06:50.130
you want to have something
that can minimally capture

00:06:50.130 --> 00:06:54.140
the main ideas of the semantic
interpretation of language.

00:06:54.140 --> 00:06:57.350
And the idea I want to get at there,

00:06:57.350 --> 00:07:02.220
is it seems the fundamental notion for
human languages is that we have this

00:07:02.220 --> 00:07:07.630
idea of composition where we can put
together the meaning of phrases.

00:07:07.630 --> 00:07:12.430
And so, we'd like to know about larger
units that are similar in meaning.

00:07:12.430 --> 00:07:16.070
So, if we have two pieces of text,

00:07:16.070 --> 00:07:21.370
perhaps paraphrase for example,
the snowboarder is leaping over a mogul or

00:07:21.370 --> 00:07:24.260
a person on a snowboard
jumps into the air.

00:07:24.260 --> 00:07:29.400
It sort of seems the first essential
point that a human being would notice and

00:07:29.400 --> 00:07:34.410
think is part of the solution here
is that person on a snowboard

00:07:34.410 --> 00:07:38.810
means roughly the same as
snowboarder that it's a paraphrase.

00:07:38.810 --> 00:07:44.010
And we can do that because we can take the
sequence of words, person on a snowboard

00:07:44.010 --> 00:07:48.250
and say that's a phrase and
we can put together a meaning for

00:07:48.250 --> 00:07:51.500
that phrase even if we
haven't heard it before and

00:07:51.500 --> 00:07:57.810
know that it's got this meaning that's
roughly the same as snowboarder.

00:07:57.810 --> 00:07:59.100
And so essentially,

00:07:59.100 --> 00:08:04.330
that's what human beings do every day when
they're listening to their friends, right?

00:08:04.330 --> 00:08:08.560
Every day, people are saying
to you different sentences.

00:08:08.560 --> 00:08:11.180
They might first off just say,
how's it going?

00:08:11.180 --> 00:08:13.723
And you've heard that 10,000 times before.

00:08:13.723 --> 00:08:17.287
But as soon as they get a bit
further into describing their day,

00:08:17.287 --> 00:08:21.660
they're gonna be saying sentences that
you've never heard before, and yet

00:08:21.660 --> 00:08:23.650
we can work out what they say.

00:08:23.650 --> 00:08:27.380
And we're not working out what they
say just as a bag of words of saying,

00:08:27.380 --> 00:08:29.380
mm, this is about a party.

00:08:29.380 --> 00:08:33.270
We're actually getting the details of
what they said and who said what to who.

00:08:33.270 --> 00:08:37.865
And we're doing that by starting off
by knowing the meanings of words and

00:08:37.865 --> 00:08:43.215
then doing a semantic composition where we
can put smaller units into bigger units,

00:08:43.215 --> 00:08:45.047
and work out their meaning.

00:08:45.047 --> 00:08:49.400
And so we'd like to have
models that can do the same.

00:08:49.400 --> 00:08:52.990
So at the very top level
this is compositionality,

00:08:52.990 --> 00:08:57.162
is to how you can put pieces
together into bigger parts, and

00:08:57.162 --> 00:09:00.790
then understand what
those bigger parts do.

00:09:00.790 --> 00:09:05.420
I think it's a problem that's especially
prominent when you start thinking about

00:09:05.420 --> 00:09:06.760
human languages.

00:09:06.760 --> 00:09:09.660
But I'd like to suggest
this is not only a problem

00:09:09.660 --> 00:09:11.520
that has to do with human languages.

00:09:11.520 --> 00:09:16.559
In many ways it's sort of a more
general cognitive capability.

00:09:16.559 --> 00:09:19.810
So that if you have something
like a complex picture,

00:09:19.810 --> 00:09:23.869
well that's also something that
has a compositional structure.

00:09:23.869 --> 00:09:29.882
So that you have pieces of stuff that you
have parts of a church that go together.

00:09:29.882 --> 00:09:33.788
You have people that go together into
a crowd or in front of this church.

00:09:33.788 --> 00:09:37.567
And then that also has a kind
of a compositional structure.

00:09:37.567 --> 00:09:42.507
So in general, it seems that for
language understanding in particular, but

00:09:42.507 --> 00:09:47.447
also for other kinds of artificial
intelligence, that we need to have models

00:09:47.447 --> 00:09:52.140
that have this kind of capability for
semantic compositionality.

00:09:52.140 --> 00:09:56.020
You can put together smaller
pieces into larger pieces and

00:09:56.020 --> 00:09:59.190
work out the meaning of
those larger pieces.

00:09:59.190 --> 00:10:03.500
And what I'd like to suggest is our
tree recursive neural networks.

00:10:03.500 --> 00:10:08.540
One model that you could think about as a
good model for understand compositionally.

00:10:10.300 --> 00:10:13.660
So there's this general idea
of sort of taking parts and

00:10:13.660 --> 00:10:17.420
putting them together into bigger
parts and understanding their meaning.

00:10:17.420 --> 00:10:20.650
There's a notion that's related to that,

00:10:20.650 --> 00:10:25.340
which goes slightly beyond that
which is the notion of recursion.

00:10:26.520 --> 00:10:30.295
So by far the most famous
linguist is Noam Chomsky.

00:10:30.295 --> 00:10:36.404
And so in some of Noam Chomsky's
recent work with colleagues

00:10:36.404 --> 00:10:41.931
they've tried to advance
this picture at in terms of.

00:10:41.931 --> 00:10:47.174
I mean, it's for
50 years it's been Chomsky's position that

00:10:47.174 --> 00:10:53.749
humans have this special innate born with
part of your brain structure ability for

00:10:53.749 --> 00:10:58.890
human language that sort of sets
us apart from other beings.

00:10:58.890 --> 00:11:02.560
And it's sort of actually seeing
that as having sort of specific

00:11:02.560 --> 00:11:04.850
brain structure for language.

00:11:04.850 --> 00:11:06.800
Not everyone else believes that.

00:11:06.800 --> 00:11:11.816
But they've been trying to sort of
put forward these proposals as to

00:11:11.816 --> 00:11:17.350
what is special in the sort of
capabilities of the humans for language.

00:11:17.350 --> 00:11:22.880
And Chomsky and colleagues have wanted to
claim that really the defining property is

00:11:22.880 --> 00:11:29.640
that humans have this ability, which you
see through language, to have recursion.

00:11:29.640 --> 00:11:33.590
So that's just like in your CS class,
right, when you have things going back and

00:11:33.590 --> 00:11:38.240
back to the same thing, looping over,
than you have recursive structure.

00:11:38.240 --> 00:11:43.740
And human languages have this kind
of recursive structure, it appears.

00:11:43.740 --> 00:11:45.360
So what's the idea of that?

00:11:45.360 --> 00:11:49.770
That if you have the man from
the company that you spoke with about

00:11:49.770 --> 00:11:55.210
the project yesterday that what we have
here, I think might have, no that's great.

00:11:55.210 --> 00:12:00.604
What we have here is sort of recursive
levels of the same kind of structure.

00:12:00.604 --> 00:12:03.777
So that project is a little noun phrase,

00:12:03.777 --> 00:12:08.401
the company that you spoke
about the project yesterday.

00:12:08.401 --> 00:12:14.218
That's a bigger noun phrase that contains
the smaller part noun phrase, the project.

00:12:14.218 --> 00:12:18.550
And then the man from the company that
you spoke with about the project is very

00:12:18.550 --> 00:12:23.590
that's an even bigger noun phrase that
contains my other two nouns phrases.

00:12:23.590 --> 00:12:27.125
So human languages have
this nesting of structure.

00:12:27.125 --> 00:12:30.940
Of where you sort of have the same units,
like noun phrases and

00:12:30.940 --> 00:12:33.700
clauses that will nest inside each other.

00:12:33.700 --> 00:12:38.670
And you can nest them deeper and
deeper, and that gives us the idea

00:12:38.670 --> 00:12:43.920
that recursion is a natural thing for
describing human languages.

00:12:43.920 --> 00:12:48.050
And that's essentially the sort
of basis of Chomsky's claim.

00:12:48.050 --> 00:12:52.730
Now, are human languages recursive?

00:12:52.730 --> 00:12:56.375
I mean, cognitively, that's actually
a little bit debatable, and

00:12:56.375 --> 00:13:00.102
there are active debates on
psycholinguistics and this kind of issue.

00:13:00.102 --> 00:13:04.269
I mean, it's sort of complex because,
really,

00:13:04.269 --> 00:13:10.634
as soon as you're thinking sentences
are only gonna be some finite length.

00:13:10.634 --> 00:13:14.300
No one's gonna say a sentence
longer than 300 words.

00:13:14.300 --> 00:13:20.020
You can never sort of prove that
things are fully recursive,

00:13:20.020 --> 00:13:24.710
because there's sort of a maximum depth
as to which things are gonna be embedded.

00:13:24.710 --> 00:13:27.390
And actually, there's slightly
more to it to it than that.

00:13:27.390 --> 00:13:31.710
It's a well known psycho-linguistic
observation that actually

00:13:31.710 --> 00:13:34.330
having things embedding in
the middle of the sentence.

00:13:34.330 --> 00:13:39.430
So I sort of deliberately the project
not right at the very right edge,

00:13:39.430 --> 00:13:41.310
but had something come after it.

00:13:41.310 --> 00:13:44.308
So when you're sort of having
more central embedding,

00:13:44.308 --> 00:13:46.940
that tends to be disfavored
in human languages.

00:13:46.940 --> 00:13:49.920
So although you get a lot of embedding,

00:13:49.920 --> 00:13:53.840
most of the embedding that you get tends
to have more of a chaining structure,

00:13:53.840 --> 00:13:56.380
where you have a right
branching kind of structure.

00:13:56.380 --> 00:13:59.624
And to the extent the structure
is purely chaining,

00:13:59.624 --> 00:14:03.016
then you don't actually need
to have full recursion to

00:14:03.016 --> 00:14:07.901
describe it because you can think of it
more as a kind of an iterative sequence.

00:14:07.901 --> 00:14:12.847
Anyway, some cognitive arguments
there cognitive science arguments.

00:14:12.847 --> 00:14:17.669
But nevertheless, if you're sort
of wanting to give a neat sort

00:14:17.669 --> 00:14:21.258
of natural description
of natural languages.

00:14:21.258 --> 00:14:24.348
It's sort of basically you end
up describing them recursively.

00:14:24.348 --> 00:14:28.715
Cuz what you want to say is well,
there are noun phrases which can expand to

00:14:28.715 --> 00:14:33.436
various things like a short noun phrase
like the man followed by a prepositional

00:14:33.436 --> 00:14:37.190
phrase which has a preposition
from followed by a noun phrase.

00:14:37.190 --> 00:14:38.920
And here's this big noun phrase.

00:14:38.920 --> 00:14:42.910
And inside this noun phrase
it's got a relative clause.

00:14:42.910 --> 00:14:47.550
And inside that it's got other noun
phrases like you and the project.

00:14:47.550 --> 00:14:52.150
So you kind of get these levels inside
each other heading down recursively.

00:14:52.150 --> 00:14:54.822
And you can and indeed people do,

00:14:54.822 --> 00:15:00.756
in things like news live sentences embed
them even more deeply than my example.

00:15:00.756 --> 00:15:05.914
And so thinking about these kind of
tree structures which have embedding

00:15:05.914 --> 00:15:11.166
inside them where we can have noun
phrases with noun phrases inside them.

00:15:11.166 --> 00:15:14.546
And so a natural way to think
about language structure and

00:15:14.546 --> 00:15:18.080
to think about things like how
we disambiguate sentences.

00:15:18.080 --> 00:15:23.054
We sort of talked before about
having ambiguities of attachment and

00:15:23.054 --> 00:15:26.190
we talked about dependencies before.

00:15:26.190 --> 00:15:29.803
The other way to these this and
think about them is to have these kind of

00:15:29.803 --> 00:15:32.557
constituency or
free structure representations.

00:15:32.557 --> 00:15:38.525
Which in computer science terms correspond
to context-free grammar representations.

00:15:38.525 --> 00:15:41.015
And then we have noun-phrased units and

00:15:41.015 --> 00:15:45.670
we can be saying with a spoon
is modifying the verb eats.

00:15:45.670 --> 00:15:50.460
It's a child of the verb phrase
constituent or the with meat

00:15:50.460 --> 00:15:54.920
here is a similar prepositional phrase
with the noun phrase inside it.

00:15:54.920 --> 00:15:59.640
But it's modifying the noun phrase
spaghetti to build a bigger noun phrase.

00:15:59.640 --> 00:16:03.660
And so as soon as we started using these
kind of structures in a context-free

00:16:03.660 --> 00:16:07.760
grammar kind of structure,
we have the ability for recursion, and

00:16:07.760 --> 00:16:10.300
human languages seem to indicate that.

00:16:11.810 --> 00:16:16.880
And we kind of want to refer to
these units when we do other tasks.

00:16:16.880 --> 00:16:21.507
So next Tuesday, I'm gonna talk
about co-reference resolution,

00:16:21.507 --> 00:16:24.137
which is how you refer back in the text or

00:16:24.137 --> 00:16:29.503
to the environment refer back to entities
that have already been established.

00:16:29.503 --> 00:16:33.968
And that sort of can be thought of as
sort of picking out pieces of structure

00:16:33.968 --> 00:16:37.654
in terms of this kind of constituency,
compositionality.

00:16:37.654 --> 00:16:40.538
So John and Jane went to a big festival.

00:16:40.538 --> 00:16:42.979
They enjoyed the trip and
the music there,.

00:16:42.979 --> 00:16:45.718
So they refers back to something, and

00:16:45.718 --> 00:16:51.122
it seems to refer back to this noun
phrase, John and Jane enjoyed the trip.

00:16:51.122 --> 00:16:55.971
So the trip's a noun phrase, which seem
to refer back to going to a big festival.

00:16:55.971 --> 00:17:00.031
And the music there, the there is

00:17:00.031 --> 00:17:04.820
again referring to this big festival.

00:17:04.820 --> 00:17:09.350
Okay, so and, finally,
having these kind of grammatical

00:17:09.350 --> 00:17:13.950
analyses of sentences is
clearly better for some tasks.

00:17:13.950 --> 00:17:19.380
It's capturing a very powerful prior of
what human language structure is like,

00:17:19.380 --> 00:17:24.790
and is then useful for understanding and
interpreting human languages.

00:17:24.790 --> 00:17:29.370
So in the start of the course,
we just had word vectors, and so

00:17:29.370 --> 00:17:34.760
we had word vectors for things like
Germany, France, Monday and Tuesday.

00:17:34.760 --> 00:17:39.710
And we sort of were able to capture word
semantic similarity in terms of our word

00:17:39.710 --> 00:17:40.387
vectors.

00:17:40.387 --> 00:17:42.633
What we'd like to be able to do is say,
no.

00:17:42.633 --> 00:17:47.038
As well as just single words,
we have larger constituents.

00:17:47.038 --> 00:17:51.940
So we have noun phrases like the country
of my birth or the place where I was born.

00:17:51.940 --> 00:17:57.910
And we'd also like to understand the
semantic similarity between those phrases.

00:17:57.910 --> 00:18:02.850
And the idea that we're going to
develop to answer how can we do

00:18:02.850 --> 00:18:07.885
that is that what we're gonna do is say,
well, what we'd like

00:18:07.885 --> 00:18:12.826
to be able to do is take bigger
units of linguistic structure,

00:18:12.826 --> 00:18:17.671
and also work out how to calculate
their meaning as vectors,

00:18:17.671 --> 00:18:21.591
and place them in exactly
the same vector space.

00:18:21.591 --> 00:18:24.858
So we're sort of hoping we
can take bigger phrases and

00:18:24.858 --> 00:18:28.633
say let's just stick those into
our vector space as well, and

00:18:28.633 --> 00:18:33.224
also represent their semantic similarity
as a kind of vector similarity.

00:18:33.224 --> 00:18:36.124
Where, of course,
this example's only two dimensional, and

00:18:36.124 --> 00:18:39.305
in practice, we'll be using 100,
200, 1000 dimensions.

00:18:39.305 --> 00:18:40.846
Yes, question?

00:18:40.846 --> 00:18:48.352
&gt;&gt; [INAUDIBLE]
&gt;&gt; Okay,

00:18:48.352 --> 00:18:51.908
so the question is why would we
want to put them in the same

00:18:51.908 --> 00:18:53.658
space as the word vectors?

00:18:53.658 --> 00:18:56.175
I mean, that's not a necessary thing.

00:18:56.175 --> 00:18:59.875
Obviously, you could say, no,
that's just not what I wanna do.

00:18:59.875 --> 00:19:04.457
I'm gonna have word vectors in one place
and phrase vectors in another place.

00:19:04.457 --> 00:19:10.498
The reason why a lot of the time
that seems a good idea is that,

00:19:10.498 --> 00:19:16.081
I mean, individual words can
capture a lot of meaning.

00:19:16.081 --> 00:19:20.576
And, in particular, they can sort of
bundle up a bunch of semantics that's

00:19:20.576 --> 00:19:25.299
often equivalent to things that you can
say in other ways with a phrase, right.

00:19:25.299 --> 00:19:30.034
So I guess I had the example right
at the beginning where I had

00:19:30.034 --> 00:19:33.552
a person on a snowboard, and snowboarder.

00:19:33.552 --> 00:19:37.377
It seems like, well,
those should be counted as paraphrases and

00:19:37.377 --> 00:19:38.636
mean the same thing.

00:19:38.636 --> 00:19:42.950
And I'm only gonna be easily able to
capture that kind of similarity if I'm

00:19:42.950 --> 00:19:47.543
using the same vector space to represent
both phrase meaning and word meaning.

00:19:50.391 --> 00:19:54.203
Okay, so that's our goal.

00:19:54.203 --> 00:19:58.252
And so the question is how
can we go about doing that?

00:19:58.252 --> 00:20:03.559
And for words what we did was
had a big lexicon of words, and

00:20:03.559 --> 00:20:09.533
said let's learn a meaning
representation for each one of them.

00:20:09.533 --> 00:20:11.227
And we were able to do that.

00:20:11.227 --> 00:20:17.453
I mean, that's clearly not possible for
phrases, like the place where I was born,

00:20:17.453 --> 00:20:22.997
because we just have an infinite number
of such phrases as they get longer.

00:20:22.997 --> 00:20:28.350
And so we can't possibly calculate and
store a vector for each phrase.

00:20:28.350 --> 00:20:35.660
And as we started to see last week is even
for words, in a lot of cases, it seems

00:20:35.660 --> 00:20:39.945
like it might actually turn out to be
sort of unappealing to store a vector for

00:20:39.945 --> 00:20:45.415
every word, especially when they're words
that have some morphological complexity,

00:20:45.415 --> 00:20:50.235
like snowboarder, which is snow, board.

00:20:50.235 --> 00:20:53.865
And so we started to talk about,
even words, how we might want to

00:20:53.865 --> 00:20:58.250
compose their meaning out of smaller
units as part of some neural network.

00:20:58.250 --> 00:21:00.650
So, again,
that's what we're gonna want to do for

00:21:00.650 --> 00:21:03.200
having these bigger phrases in language.

00:21:03.200 --> 00:21:06.320
So we're gonna have something
like the country of my birth.

00:21:06.320 --> 00:21:09.630
And what we'd like to be able
to do is semantic composition.

00:21:09.630 --> 00:21:14.640
We'd like to be able to use
the principle of compositionality,

00:21:14.640 --> 00:21:17.310
which is sort of a famous thing
from philosophy of language or

00:21:17.310 --> 00:21:22.240
semantics, which is saying you can
derive the meaning of a phrase or

00:21:22.240 --> 00:21:25.930
a sentence by starting with
the meaning of its words.

00:21:25.930 --> 00:21:29.195
And have some kind of,
then, composition function

00:21:29.195 --> 00:21:33.956
that you can then calculate meanings
of bigger units as you combine things.

00:21:33.956 --> 00:21:38.579
So what we'd like to be able to do is
put together my birth as two words, and

00:21:38.579 --> 00:21:43.131
have a meaning for that phrase,
a meaning for the phrase, country, and

00:21:43.131 --> 00:21:47.385
keep on calculating up, and
get some meaning for the whole phrase,

00:21:47.385 --> 00:21:50.624
which we could then represent
in the vector space.

00:21:52.875 --> 00:21:59.890
Okay, so if we build models of this type,
we can potentially hope to do two things.

00:21:59.890 --> 00:22:04.550
We can potentially use them both as
models that will build structure,

00:22:04.550 --> 00:22:08.050
that will actually build
sentence structure as they go.

00:22:08.050 --> 00:22:13.050
And they will also build semantics, that
they will build a meaning representation

00:22:13.050 --> 00:22:16.100
for these phrases as they build up.

00:22:16.100 --> 00:22:18.700
So the general picture of
what we're going to want to

00:22:18.700 --> 00:22:23.330
do is we're gonna start off with a bunch
of words, and their word vectors,

00:22:23.330 --> 00:22:24.910
which we'll look up in the lexicon.

00:22:24.910 --> 00:22:26.760
The cat sat on the mat.

00:22:26.760 --> 00:22:30.330
And then we're going to start
building phrase structure.

00:22:30.330 --> 00:22:32.950
So we're gonna say, that's a noun phrase.

00:22:32.950 --> 00:22:38.655
This is a noun phrase, prepositional
phrase, verb phrase, build a sentence.

00:22:38.655 --> 00:22:42.504
So we'll have a kind of a syntactic
phrase structure of the tree.

00:22:42.504 --> 00:22:48.279
And then we'll, using that, kind of
build up the semantic representations.

00:22:48.279 --> 00:22:49.390
And for that case,

00:22:49.390 --> 00:22:54.350
I just sort of knew what the right phrase
structure I wanted for the sentence was.

00:22:54.350 --> 00:22:58.695
And just sort of drew in those nodes and
calculated their semantics.

00:22:58.695 --> 00:23:02.710
Well, one of the questions is how can
we calculate that as we go along?

00:23:02.710 --> 00:23:04.785
And I'll come back to that in a minute.

00:23:04.785 --> 00:23:07.820
Then before doing that,
I just wanted to spend

00:23:07.820 --> 00:23:12.510
a couple of slides just sort of
going back over the connections and

00:23:12.510 --> 00:23:18.030
differences between the model types
that we've been looking at recently.

00:23:18.030 --> 00:23:23.420
So up at the top half, we now have
our tree recursive neural network.

00:23:23.420 --> 00:23:29.077
And in the bottom part,
we then have our recurrent neural network.

00:23:29.077 --> 00:23:34.787
Now, in some sense the kind of linear
sequence models that you get for

00:23:34.787 --> 00:23:41.089
recurrent networks, are kind of sort of
like a sort of a limit case of a tree,

00:23:41.089 --> 00:23:45.618
so that if you sort of stare
down from about this angle,

00:23:45.618 --> 00:23:50.670
what you're looking at actually
looks like a tree, right.

00:23:50.670 --> 00:23:54.197
If you sort of tip it,
it's sort of like this tree, but

00:23:54.197 --> 00:23:59.340
it's a tree that's always sort of
right branching down to the right.

00:23:59.340 --> 00:24:00.430
And, actually,

00:24:00.430 --> 00:24:04.180
it turns out that quite a lot of English
structure is right branching down

00:24:04.180 --> 00:24:08.730
to the right in most sentences that you
sort of get these pieces of constituency

00:24:08.730 --> 00:24:12.890
where you get left branching like
the country in this example.

00:24:12.890 --> 00:24:16.326
But if you look at
the details of these two

00:24:16.326 --> 00:24:20.988
models the details of the model
are kind of different.

00:24:20.988 --> 00:24:25.828
Because in this model we're
exclusively sort of building upwards.

00:24:25.828 --> 00:24:32.836
We're taking smaller pieces of structure
and then computing a representation for

00:24:32.836 --> 00:24:37.640
a larger piece of structure
that they can pose into.

00:24:37.640 --> 00:24:41.650
Whereas this model is sort of
actually a kind of a funny sort of

00:24:41.650 --> 00:24:44.750
mixed model when you think about
it comparing it to a tree,

00:24:44.750 --> 00:24:49.070
cuz this sort of the word vectors
are going up to compute something but

00:24:49.070 --> 00:24:52.010
then simultaneously,
we have something going down the tree.

00:24:52.010 --> 00:24:55.970
And that's sort of the idea that
Richard was mentioning last time.

00:24:55.970 --> 00:24:59.410
How the recurrent models
are really sort of

00:24:59.410 --> 00:25:02.900
capturing representations
of whole prefixes and

00:25:02.900 --> 00:25:06.330
you're not getting any representations
of smaller units than that.

00:25:07.440 --> 00:25:12.940
There are a couple of other pluses and
minuses to think about.

00:25:12.940 --> 00:25:15.550
So the problem of

00:25:15.550 --> 00:25:20.560
tree recursive neural nets is that
you have to get a tree structure.

00:25:20.560 --> 00:25:23.530
And so this is actually a huge problem.

00:25:23.530 --> 00:25:28.130
I mean if I had If I admit
right at the beginning tree

00:25:28.130 --> 00:25:31.780
recursive neural networks
have not swept the world.

00:25:31.780 --> 00:25:34.930
There's some really good linguistic
reasons to like them and

00:25:34.930 --> 00:25:36.880
we'll say some stuff about them.

00:25:36.880 --> 00:25:40.690
But if you just sort of go out
on arXiv and start looking at

00:25:40.690 --> 00:25:45.120
what people are using in neural networks
for language you have to look for

00:25:45.120 --> 00:25:47.790
a while to find people using
tree structured models, right?

00:25:47.790 --> 00:25:54.280
There's ten times as much use of the LSTMs
that we've talked about previously.

00:25:54.280 --> 00:25:58.360
And a big part of that
reason is because the user,

00:25:58.360 --> 00:26:02.000
tree recursive model,
you have to have a tree structure.

00:26:02.000 --> 00:26:04.610
And for
some of the things that we've talked about

00:26:04.610 --> 00:26:08.060
I think you can sort of immediately
get a sense of why that's problematic.

00:26:08.060 --> 00:26:12.020
Cuz putting a tree structure
over a sentence is making

00:26:12.020 --> 00:26:16.830
deterministic categorical choices as
to which words are going together to

00:26:16.830 --> 00:26:19.350
be constituents while other words aren't.

00:26:19.350 --> 00:26:24.330
And anywhere you're making categorical
choices that's a problem for

00:26:24.330 --> 00:26:28.100
learning a model simply by
running back propagation.

00:26:28.100 --> 00:26:32.770
And so that sort of puts
complexity into these models.

00:26:32.770 --> 00:26:36.710
It also means that they're kind of GPU
unfriendly, cuz there isn't just this

00:26:36.710 --> 00:26:40.660
sort of simple lock step computation,
like an LSTM gives you.

00:26:42.630 --> 00:26:45.710
So LSTMs have this very simple structure,

00:26:45.710 --> 00:26:48.660
cuz it doesn't matter
what the sentence is.

00:26:48.660 --> 00:26:50.720
The structure is always the same, right?

00:26:50.720 --> 00:26:55.170
You just have that same sequence model
that chugs along from left to right,

00:26:55.170 --> 00:26:58.190
which makes them very
computationally appealing.

00:26:58.190 --> 00:27:02.590
But of course, they have the disadvantage
that they're not actually representing

00:27:02.590 --> 00:27:04.140
any of the structure of the sentence.

00:27:05.250 --> 00:27:11.220
And if you want to get back to my original
picture with the CMU bag of words, I think

00:27:11.220 --> 00:27:15.950
there's just sort of a manifest sense for
human languages that if you just want to

00:27:15.950 --> 00:27:21.370
have this sort of first cut roughly
the structure of human languages write.

00:27:21.370 --> 00:27:25.840
What you gonna have to have is sort
of know which sub units of words

00:27:25.840 --> 00:27:29.368
goes together to have
behaviours constituents and

00:27:29.368 --> 00:27:33.490
the semantic parts out of which
bigger sentences are described.

00:27:35.340 --> 00:27:41.580
Okay, so conversely we can also
think about the relationship between

00:27:41.580 --> 00:27:48.370
the tree recursive neural networks and
convolutional neural networks.

00:27:48.370 --> 00:27:53.750
So these central difference there is
that the tree recursive neural networks

00:27:53.750 --> 00:27:58.290
calculate representations,
compositional vectors only for

00:27:58.290 --> 00:28:01.630
phrases that sort of make sense,
that are grammatical,

00:28:01.630 --> 00:28:05.435
which a linguist would say is part
of the structure of the sentence.

00:28:05.435 --> 00:28:08.790
Whereas what a convolutional
neural network does is say,

00:28:08.790 --> 00:28:13.440
okay let's just work out representations
that every pair of words,

00:28:13.440 --> 00:28:16.400
every triple words, every four words.

00:28:16.400 --> 00:28:19.600
Regardless of whether they
make any sense or not.

00:28:19.600 --> 00:28:22.380
But again there's actually
an advantage to that, right?

00:28:22.380 --> 00:28:25.250
That since you're not actually
having to make any choices, and

00:28:25.250 --> 00:28:28.250
you just do it for every pair of words,
and every triple of words.

00:28:28.250 --> 00:28:30.530
You don't need a parser, you have, again,

00:28:30.530 --> 00:28:35.750
you're back to this sort of uniform
computation without any choices.

00:28:35.750 --> 00:28:41.260
But it's not very linguistically or
cognitively plausible, I feel.

00:28:41.260 --> 00:28:46.260
To some extent, I actually think recurrent
models are more cognitively plausible

00:28:46.260 --> 00:28:50.090
as an alternative to tree structure
models and convolutional neural networks.

00:28:50.090 --> 00:28:55.800
So the sort of picture is that for
the CNN, you're sort of making

00:28:55.800 --> 00:29:00.550
a representation of every pair of words,
every triple of words, every four words.

00:29:00.550 --> 00:29:05.680
Where as the tree recursive neural
network is saying well some of those

00:29:05.680 --> 00:29:11.320
representations don't correspond to a
phrase and so we're gonna delete them out.

00:29:11.320 --> 00:29:15.250
So that for
the convolultional neural network,

00:29:15.250 --> 00:29:17.590
you have a representation for
every bigram.

00:29:17.590 --> 00:29:23.530
So you have a representation for there
speak and trigram there speak slowly.

00:29:23.530 --> 00:29:28.170
Whereas for the recursive neural network,
you only have representations for

00:29:28.170 --> 00:29:32.440
the sort of semantically meaningful
phrases like people there and

00:29:32.440 --> 00:29:36.930
speaks slowly going together to give
a representation for the whole sentence.

00:29:39.570 --> 00:29:46.300
Okay, so how do we go about calculating
things in the course of neural network.

00:29:46.300 --> 00:29:52.150
So the idea is when we wanna build
a representation of a larger unit

00:29:52.150 --> 00:29:57.070
what we're gonna do is take
the representation of its children and

00:29:57.070 --> 00:30:00.052
we're gonna have sort of binary trees for
what we're showing here.

00:30:00.052 --> 00:30:04.300
We gonna stick them through
some kind of neural network,

00:30:04.300 --> 00:30:08.820
and we're going to have
probably two things come out.

00:30:08.820 --> 00:30:13.620
One is going to be of
a vector that's representing

00:30:13.620 --> 00:30:18.160
what is going to be the meaning of
this larger unit if you construct it.

00:30:18.160 --> 00:30:22.428
But if we'd also like to parse at the same
time and work out good structures.

00:30:22.428 --> 00:30:26.970
We also wanna have some kind of score
as to say, is this a good constituent?

00:30:26.970 --> 00:30:30.780
Because that will allow us to
build a parser at the same time.

00:30:32.360 --> 00:30:34.070
So how we might we do that?

00:30:34.070 --> 00:30:38.291
If we sort of start doing it at
the simplest way possible just using

00:30:38.291 --> 00:30:42.620
the kind of rudimentary neural
networks that we've looked at.

00:30:42.620 --> 00:30:45.880
This seems like the kind of
idea what we could build so

00:30:45.880 --> 00:30:50.120
we could take the vector
representations of the two children

00:30:50.120 --> 00:30:54.900
which might be just words or might
already be phrases that you've built up.

00:30:54.900 --> 00:30:59.630
We could concatenate them to make them
into a bigger vector, have a linear layer,

00:30:59.630 --> 00:31:03.340
multiplied by a matrix, added
non-linearity, put that throw a tanh,

00:31:03.340 --> 00:31:08.120
and so we've just got the simplest
kind of single neural net layer.

00:31:08.120 --> 00:31:10.690
And that will then give us our
representation of the parent.

00:31:10.690 --> 00:31:13.630
And then we want to score that and well,

00:31:13.630 --> 00:31:17.980
one way we could score that is just
having a vector here that we could then

00:31:17.980 --> 00:31:23.720
multiply this representation by a vector
and that'll give us a score for phrase.

00:31:23.720 --> 00:31:29.030
And doing precisely that was the first
type of tree recursive neural network

00:31:29.030 --> 00:31:33.980
that Richard explored in his
work back in about 2011.

00:31:33.980 --> 00:31:35.660
Okay, but if we have just this.

00:31:36.950 --> 00:31:40.090
Then we're in a position
where we can use it

00:31:40.090 --> 00:31:43.400
to parse a sentence with the tree
recursive neural network.

00:31:43.400 --> 00:31:47.980
And so the easiest way to do that and
it's kind of similar in a way to what

00:31:47.980 --> 00:31:52.400
we did with the dependency
parsers sort of three weeks ago.

00:31:52.400 --> 00:31:58.490
Is to say what were gonna do is we gonna
run a greedy a parser we're going to look

00:31:58.490 --> 00:32:04.730
at what seems best and make hard decisions
on each action and then proceed along.

00:32:04.730 --> 00:32:10.540
So what we could do is we could start off
with the sentence the cat sat on the mat,

00:32:10.540 --> 00:32:13.850
and what we're gonna do in
a sense is kind of like

00:32:13.850 --> 00:32:17.910
what the first part of
a convolutional neural network does.

00:32:17.910 --> 00:32:20.570
We're gonna take each pair of words and

00:32:20.570 --> 00:32:25.900
we're going to calculate
a representation for that pair of words.

00:32:25.900 --> 00:32:28.650
But we've got one other
tool at our disposal now.

00:32:28.650 --> 00:32:31.990
That we're also calculating a score for

00:32:31.990 --> 00:32:36.750
these combinations and so,
we can say that the thing that scores

00:32:36.750 --> 00:32:41.160
best is putting together a phrase
is these two words on the left.

00:32:41.160 --> 00:32:44.950
So, why don't we just hard
commit to those and say, okay,

00:32:44.950 --> 00:32:47.400
we've got the cat as the constituent.

00:32:47.400 --> 00:32:53.408
With this semantic representation and
so then at that point we can

00:32:55.080 --> 00:32:58.900
for what to do next we have all
of the choices we had before and

00:32:58.900 --> 00:33:03.890
additionally we have a choice that we
can put the cat together with sat.

00:33:03.890 --> 00:33:08.130
So, that's a new choice that we can
evaluate and at this point we can say

00:33:08.130 --> 00:33:12.230
well, looks like the best thing to
do is to combine the mat together,

00:33:12.230 --> 00:33:16.870
cuz that's got a good score, so
we do that, and we commit to that.

00:33:16.870 --> 00:33:19.140
Then we thought one new
thing we could try,

00:33:19.140 --> 00:33:22.810
cuz we could have the mat
go together with on.

00:33:22.810 --> 00:33:26.260
And we can look at that and we could say,
yeah, that's a really good thing to do.

00:33:26.260 --> 00:33:30.390
On the mat,
that's a really good phrase to have found.

00:33:30.390 --> 00:33:34.520
So, the neural network will
commit to that one, and

00:33:34.520 --> 00:33:39.350
then we'll kind of keep on repeating and
we'll decide putting sat

00:33:39.350 --> 00:33:42.700
together would be a good idea sat
on the mat that's a predicate, and

00:33:42.700 --> 00:33:46.830
then we'll combine that together
with the cat and we're done.

00:33:46.830 --> 00:33:51.780
And so we sort of greedily incrementally
building up parse structures

00:33:51.780 --> 00:33:56.770
as we go along and working out
the parse structure of the sentence.

00:33:56.770 --> 00:34:01.155
And so, at the end of the day, that's
a parse tree, and we're gonna have a score

00:34:01.155 --> 00:34:06.635
for our parse tree, and that score for the
parse tree we're just gonna say, we made,

00:34:06.635 --> 00:34:11.310
we've got a score for each individual
decision as we put two node's together.

00:34:11.310 --> 00:34:14.950
And the tree has got a bunch of nodes in
it, and we're just going to sum those

00:34:14.950 --> 00:34:19.530
scores of each node decision, and
that will give us the score of a tree, and

00:34:19.530 --> 00:34:24.620
what we'd like to do is
find the very best tree for

00:34:24.620 --> 00:34:29.100
this bunch of words, and
we've kind of approximated this by

00:34:29.100 --> 00:34:32.620
doing this greedy algorithm where we
just committed to what looked like

00:34:32.620 --> 00:34:37.610
the best constituent to build at
every particular point in the time.

00:34:38.850 --> 00:34:43.820
And so, the final thing was then
sort of set up as a loss function,

00:34:43.820 --> 00:34:46.320
with a sort of max margin objective.

00:34:46.320 --> 00:34:52.300
Where you were sort of trying to
adjust the parameters of the model so

00:34:52.300 --> 00:34:57.010
that you're maximizing the scores of
the sentences that you have found.

00:34:57.010 --> 00:35:03.690
And then, you're considering what
the sort of structures you were finding,

00:35:03.690 --> 00:35:08.090
what incorrect decisions you'd made
versus what the gold structure for

00:35:08.090 --> 00:35:12.640
the sentence is meant to be in the sort
of gold structure in the tree bank

00:35:12.640 --> 00:35:17.910
that tells you what are the right answers
for it, and in this kind of a model,

00:35:17.910 --> 00:35:22.610
you'll sort of, in theory what you'd
like to do is to find the best tree for

00:35:22.610 --> 00:35:25.190
each sentence, according to your model.

00:35:25.190 --> 00:35:28.510
And then changing
the parameters of the model.

00:35:28.510 --> 00:35:33.210
So the model thinks the best tree is
the correct tree in the tree bank.

00:35:33.210 --> 00:35:36.400
And that's then gonna be
minimizing your loss.

00:35:36.400 --> 00:35:42.090
In practice, finding the best
tree according to your model,

00:35:42.090 --> 00:35:46.270
can require an exponential amount
of work and we can't do that.

00:35:46.270 --> 00:35:51.182
And so we're just substituting in
this greedy finding of a parse,

00:35:51.182 --> 00:35:55.400
that looks sort of good according
to our model, and using that

00:35:55.400 --> 00:36:00.110
in our loss function right here, the sort
of score of the parse that we found.

00:36:00.110 --> 00:36:02.490
There are obvious generalizations of this.

00:36:02.490 --> 00:36:08.620
Rather than sort of keeping just one
really best parse that you're finding, you

00:36:08.620 --> 00:36:13.460
could have a beam parser, and you could
explore some different possibilities.

00:36:13.460 --> 00:36:16.720
And you could sort of
have a ten best beam,

00:36:16.720 --> 00:36:19.370
and sort of explore a bunch
of parses to the end.

00:36:19.370 --> 00:36:22.220
And sort of then come up
with a better estimate

00:36:22.220 --> 00:36:24.990
of what is the best parse
according to your model.

00:36:24.990 --> 00:36:32.450
But the central thing to be aware of is to
what you can't do is standard result for

00:36:32.450 --> 00:36:36.500
parsing context free grammars,
when you have grammars with labels.

00:36:36.500 --> 00:36:40.690
Like noun phrase, verb phrase,
and things like that.

00:36:40.690 --> 00:36:46.110
Then what you can do is dynamic program,
context free grammar parsing,

00:36:46.110 --> 00:36:51.970
and so you can then do parsing context
free grammars in O(n^3) time and

00:36:51.970 --> 00:36:55.490
be guaranteed to have found
the optimal parse for

00:36:55.490 --> 00:36:58.690
your sentence according to your grammar.

00:36:58.690 --> 00:37:04.380
The problem is here, every time we're
putting together two constituents, we're

00:37:04.380 --> 00:37:08.630
running it through a little neural network
and we're getting a vector out here.

00:37:08.630 --> 00:37:12.330
And so for any way of putting
things together differently

00:37:12.330 --> 00:37:16.820
we're gonna get different vectors up here
and so there's no substitute that if

00:37:16.820 --> 00:37:20.560
you were actually wanting to guarantee
you'd found the best parse of a sentence

00:37:20.560 --> 00:37:24.800
that you'd have to do the exponential
amount of work of exploring every

00:37:24.800 --> 00:37:28.555
different possible way of putting things
together, which we don't want to do.

00:37:28.555 --> 00:37:34.040
but in general you can work pretty
effectively by sort of doing fairly

00:37:34.040 --> 00:37:39.210
greedy exploration, according, informed
by your model to find good structures.

00:37:39.210 --> 00:37:44.389
Okay, so this is our overall objective
function and we want to be changing

00:37:44.389 --> 00:37:49.401
the parameters of our model so
that it's wanting to choose this parse of

00:37:49.401 --> 00:37:54.980
the sentence the one that's the same
as the gold parse of the sentence.

00:37:54.980 --> 00:37:59.160
And so, the way we do that is again
by backpropagation algorithm.

00:38:00.850 --> 00:38:06.120
So, we'd sorted from the recurrent neural
networks we had back propagation through

00:38:06.120 --> 00:38:09.810
time where we're sorting of chugging back
through the time steps of your linear

00:38:09.810 --> 00:38:10.800
model.

00:38:10.800 --> 00:38:13.720
You can generalize that
to tree structures and

00:38:13.720 --> 00:38:19.035
actually that was done by
a couple of Germans in the 1990s.

00:38:19.035 --> 00:38:23.510
Goller and Kuchler then came up with
this algorithm called back propagation

00:38:23.510 --> 00:38:24.890
through structure.

00:38:24.890 --> 00:38:26.580
And in principle,

00:38:26.580 --> 00:38:32.230
it's the same as the back propagation
we've seen again and again and again.

00:38:32.230 --> 00:38:36.420
But it's sort of just
slightly more complex

00:38:36.420 --> 00:38:41.160
because you have to be getting things
working over a tree structure.

00:38:41.160 --> 00:38:44.638
It ends up that there
are three differences.

00:38:44.638 --> 00:38:52.000
For working out the updates to
the matrix W in your neural network.

00:38:53.090 --> 00:38:56.550
So, just like an RNN,
you're going to be summing up

00:38:56.550 --> 00:39:01.730
the derivatives of the sort of error
signals that you get coming into W,

00:39:01.730 --> 00:39:04.370
everywhere you see it
inside the tree structure.

00:39:05.510 --> 00:39:09.340
Something that's slightly different
when you back propagate down,

00:39:09.340 --> 00:39:12.410
essential back propagating
down a tree structure.

00:39:12.410 --> 00:39:14.510
We then have to split the derivatives and

00:39:14.510 --> 00:39:20.370
send them down both branches of the tree
structure to the next level below.

00:39:20.370 --> 00:39:24.250
And then when you're calculating
your error messages,

00:39:24.250 --> 00:39:27.440
you'll have an error message
coming in from the node above.

00:39:27.440 --> 00:39:32.660
You want to be adding to it,
the additional error from the node itself.

00:39:32.660 --> 00:39:34.500
And then, you wanna be splitting it and

00:39:34.500 --> 00:39:37.370
passing it down to the two
nodes down below you.

00:39:38.530 --> 00:39:41.670
In these slides,

00:39:41.670 --> 00:39:46.560
there are then some slides that
go through that in more detail.

00:39:46.560 --> 00:39:48.950
Summing derivatives of the nodes,

00:39:48.950 --> 00:39:54.120
splitting the derivatives at each node,
add error messages.

00:39:54.120 --> 00:39:59.150
And actually from Richard last year,
he wrote some Python code for

00:39:59.150 --> 00:40:01.990
doing back propagation through structure.

00:40:03.010 --> 00:40:04.710
I thought I wouldn't actually try and

00:40:04.710 --> 00:40:09.860
explain in any more details than that in
class right now, all the details of that.

00:40:09.860 --> 00:40:12.670
But you can look at these
slides on the website and

00:40:12.670 --> 00:40:15.290
chug through it in more detail than that.

00:40:15.290 --> 00:40:18.273
And I thought we could skip
straight across to Kevin,

00:40:18.273 --> 00:40:21.267
who's gonna be doing
today's research highlight.

00:40:28.021 --> 00:40:28.530
&gt;&gt; Okay.

00:40:28.530 --> 00:40:29.705
Hi everyone.

00:40:29.705 --> 00:40:33.672
I am Kevin and I am going to be presenting
deep reinforcement learning for

00:40:33.672 --> 00:40:38.110
dialogue generation, which is a paper
by some people here at Stanford.

00:40:38.110 --> 00:40:41.900
But some people elsewhere as well.

00:40:41.900 --> 00:40:44.880
So the goal of this
paper is to train a chat

00:40:44.880 --> 00:40:47.400
bot that can hold
a reasonable conversation.

00:40:47.400 --> 00:40:51.540
And the authors approached this task
in the sequence-to-sequence framework,

00:40:51.540 --> 00:40:55.220
where the input sequence
consists of a message, or

00:40:55.220 --> 00:40:58.250
perhaps several messages
from a conversation.

00:40:58.250 --> 00:41:00.960
And the output sequence is
a response to the message,

00:41:00.960 --> 00:41:04.540
and that's what the chat bot will say.

00:41:04.540 --> 00:41:09.240
So they use the exact same
encoder-decoder model, you saw for

00:41:09.240 --> 00:41:11.840
machine translation last week.

00:41:11.840 --> 00:41:15.490
You can train this model with
the exact same training objective,

00:41:15.490 --> 00:41:17.630
which is maximum likelihood estimation.

00:41:17.630 --> 00:41:22.380
So you find the data set of people talking
to each other, and you train the model by

00:41:22.380 --> 00:41:27.380
making it assign high probability
to the responses people say.

00:41:30.560 --> 00:41:32.180
So once you've trained a model like this,

00:41:32.180 --> 00:41:35.570
it's kind of fun to have the model
talk to itself and see what happens.

00:41:35.570 --> 00:41:39.420
So this is a real conversation
from the model in the paper.

00:41:39.420 --> 00:41:42.030
So the first chat bot says,
how old are you?

00:41:42.030 --> 00:41:46.960
And then the second one says I'm 16,
and the first one says 16?

00:41:46.960 --> 00:41:49.315
And then things kinda fall apart.

00:41:49.315 --> 00:41:52.390
&gt;&gt; [LAUGH]
&gt;&gt; So the second chat bot says I don't

00:41:52.390 --> 00:41:56.000
know what you're talking about, the first
chat bot says you don't know what you're

00:41:56.000 --> 00:41:59.095
saying, and the chat bots get
stuck in an infinite loop.

00:41:59.095 --> 00:42:04.350
&gt;&gt; [LAUGH]
&gt;&gt; So if we look over this dialogue

00:42:04.350 --> 00:42:08.490
we can sort of point to some problems,
that might be causing this issue.

00:42:08.490 --> 00:42:10.820
The first one is actually
the response I'm 16.

00:42:10.820 --> 00:42:15.630
Although it's kind of a reasonable follow
up to the question, it's not very helpful.

00:42:15.630 --> 00:42:19.490
So it'd be maybe better to say something
like, I'm 16, how old are you?

00:42:19.490 --> 00:42:22.560
And now you're giving more guidance
to your conversation partner,

00:42:22.560 --> 00:42:24.330
in what you should say next.

00:42:24.330 --> 00:42:28.190
The second issue here is this, I don't
know what you're talking about response,

00:42:28.190 --> 00:42:31.390
which actually is more or
less a reasonable reply.

00:42:31.390 --> 00:42:34.769
It still kind of makes sense,
but it's a very generic response.

00:42:36.120 --> 00:42:38.170
And really the main issue here is that,

00:42:38.170 --> 00:42:42.910
we're training our model to produce
sentences that have high probability.

00:42:42.910 --> 00:42:46.810
But that actually doesn't necessarily mean
sentences that are good and useful for

00:42:46.810 --> 00:42:48.050
the conversation.

00:42:48.050 --> 00:42:52.010
So with the, I don't know what you're
saying example, it is high probability cuz

00:42:52.010 --> 00:42:54.790
really no matter what you're
say to me I can respond with,

00:42:54.790 --> 00:42:57.370
I don't know what you're saying and
it sort of makes sense.

00:42:57.370 --> 00:43:01.130
So trained with maximum likelihood
estimation, the model thinks great

00:43:01.130 --> 00:43:05.320
this is a good response, and we want some
different objective to train the model.

00:43:07.650 --> 00:43:12.890
So that got a little bit messed up,
but the criteria we could think of for

00:43:12.890 --> 00:43:17.790
training a good response is that,
it is reasonable so it makes sense.

00:43:17.790 --> 00:43:20.970
But also that is non-repetitive so
we don't get in an infinite loop.

00:43:20.970 --> 00:43:22.920
And that it's easy to answer, so

00:43:22.920 --> 00:43:26.600
you say something a little bit
more helpful than just I'm 16.

00:43:26.600 --> 00:43:31.380
And in this paper,
the authors come up with ways of

00:43:31.380 --> 00:43:37.220
computationally scoring a response
according to these criteria.

00:43:37.220 --> 00:43:40.410
So they end up with a single scoring
function that takes the responses input,

00:43:40.410 --> 00:43:44.510
and returns some number indicating, did we
do a good job with this response or not.

00:43:46.420 --> 00:43:50.100
And then they train a model to
maximize the scoring function,

00:43:50.100 --> 00:43:51.760
using reinforcement learning.

00:43:51.760 --> 00:43:54.920
So I'm not going to go into detail
on how reinforcement learning works.

00:43:54.920 --> 00:43:58.120
But the main idea is that instead
of learning from an example, so

00:43:58.120 --> 00:44:02.120
how a human responded to a message,
you learn from a reward signal.

00:44:02.120 --> 00:44:05.880
So we start off with, as before,
encoding the message in a vector.

00:44:05.880 --> 00:44:10.900
But now instead of passing in
a human-generated or a response

00:44:10.900 --> 00:44:14.550
that a human said and try to increase this
probability according to the model, we're

00:44:14.550 --> 00:44:20.066
gonna just leave the model to its own
devices and have it produce a response.

00:44:20.066 --> 00:44:24.070
And then give it a reward signal,
which tells it, did it do a good job

00:44:24.070 --> 00:44:27.780
with the response or not, which is that
scoring function I mentioned earlier.

00:44:27.780 --> 00:44:30.810
So here it's negative, because I
don't know isn't a good response.

00:44:30.810 --> 00:44:32.920
And through reinforcement learning,

00:44:32.920 --> 00:44:37.839
the model will learn to not produce
these poor quality responses.

00:44:39.690 --> 00:44:42.530
And so now on to some results,
how well does this work?

00:44:42.530 --> 00:44:44.510
These first results
are quantitative results,

00:44:44.510 --> 00:44:49.150
where the author showed dialogues
produced by the system to humans, and

00:44:49.150 --> 00:44:53.695
had them say which of these
dialogues were better and

00:44:53.695 --> 00:44:56.745
here a positive number means the
reinforcement learning system did better.

00:44:56.745 --> 00:45:00.995
So you can see that humans thought
the reinforcement learned system,

00:45:00.995 --> 00:45:05.660
was better particularly at making
messages that are easy to answer, and

00:45:05.660 --> 00:45:08.950
also for the general quality
of a several turn dialog.

00:45:10.300 --> 00:45:13.110
We can also have our chat bots
talk to each other again, and

00:45:13.110 --> 00:45:15.180
here you see that it's doing a bit better.

00:45:15.180 --> 00:45:17.480
So the first chat bot ask who old are you?

00:45:17.480 --> 00:45:21.600
But now instead of saying I'm 16 only,
it also says why are you asking?

00:45:21.600 --> 00:45:24.140
So it's kind of helping
the conversation move along.

00:45:24.140 --> 00:45:29.525
But actually after a couple turns,
they end up in the same infinite loop.

00:45:29.525 --> 00:45:31.180
&gt;&gt; [LAUGH]
&gt;&gt; So this just kind of highlights,

00:45:31.180 --> 00:45:33.580
although reinforcement learning
is a useful technique,

00:45:33.580 --> 00:45:36.770
it doesn't kind of
magically fix everything.

00:45:36.770 --> 00:45:40.400
So to conclude reinforcement learning is
helpful when we monitor a model to do

00:45:40.400 --> 00:45:45.250
something, beyond just mimicking
the way humans perform a task.

00:45:45.250 --> 00:45:48.460
And it's been applied to
many areas beyond dialog.

00:45:48.460 --> 00:45:53.310
So if you're interested, there's a lot of
new and exiting work in that direction.

00:45:53.310 --> 00:45:57.766
Thank you.
&gt;&gt; [APPLAUSE]

00:46:00.785 --> 00:46:02.109
&gt;&gt; Okay.

00:46:02.109 --> 00:46:07.380
Yeah so, we'll have a bit more
reinforcement learning in this class,

00:46:07.380 --> 00:46:10.470
including I think next Tuesday,
it might come up.

00:46:10.470 --> 00:46:13.266
But maybe I should just
while we're on that topic,

00:46:13.266 --> 00:46:19.220
advertise there newest Stanford CS Faculty
Emma Brunskill started work yesterday.

00:46:19.220 --> 00:46:23.600
And in the spring she's gonna be teaching
a class on reinforcement learning.

00:46:23.600 --> 00:46:26.590
So if you wanna get a good dose
of reinforcement learning,

00:46:26.590 --> 00:46:27.581
there's an opportunity there.

00:46:29.180 --> 00:46:29.680
Okay.

00:46:32.460 --> 00:46:37.520
So what I wanted to do now was,
sort of show you a bit more about how we

00:46:37.520 --> 00:46:43.010
develop some of the ideas of having
this tree-recursive neural networks.

00:46:43.010 --> 00:46:48.790
I guess I haven't really shown anything
in the sort of quantitative results,

00:46:48.790 --> 00:46:54.140
of show big results tables for
that simple recursive neural network.

00:46:54.140 --> 00:47:01.630
But the summary of it was that, we could
do some sort of useful things with it for

00:47:01.630 --> 00:47:05.920
learning about paraphrases and
getting syntactic structures right.

00:47:05.920 --> 00:47:07.300
It sort of worked.

00:47:07.300 --> 00:47:11.100
Able to publish a paper on it and
all of those good things.

00:47:11.100 --> 00:47:17.000
It seemed like it wasn't
really fully adequate for

00:47:17.000 --> 00:47:20.390
doing all the things that
you wanted to do, for

00:47:20.390 --> 00:47:23.940
understanding sentences and
semantic composition.

00:47:23.940 --> 00:47:28.890
And there are a couple of ways in
which that was true, it appeared.

00:47:28.890 --> 00:47:31.730
And so for some of the later work, and

00:47:31.730 --> 00:47:34.270
only some of which I'm gonna
be able to show you today,

00:47:34.270 --> 00:47:39.466
we were then sort of starting to explore
better ways in which we could put sort of,

00:47:39.466 --> 00:47:44.290
more flexibility or
better neural units into this sort of same

00:47:44.290 --> 00:47:49.845
basic model of tree-recursive structure,
to be able to do a better job.

00:47:49.845 --> 00:47:52.840
And there are sort of a couple
of ways in which it seemed like,

00:47:52.840 --> 00:47:56.320
the model probably wasn't
doing what you want.

00:47:57.800 --> 00:48:02.520
The first one, the no interaction
between the input words is,

00:48:02.520 --> 00:48:06.020
I kind of think, a common issue that
happens with quite a lot of models,

00:48:06.020 --> 00:48:08.580
if you have just a single neural layer.

00:48:08.580 --> 00:48:11.600
We sort of mentioned this also when
we were talking about attention,

00:48:11.600 --> 00:48:15.080
that if you just sort of
concatenate C1 and C2.

00:48:15.080 --> 00:48:20.470
And put them through a single matrix,
multiply, and then a nonlinearity.

00:48:20.470 --> 00:48:25.272
That you can think of the weight
matrix as sort of being just

00:48:25.272 --> 00:48:28.509
segmented into two smaller matrices.

00:48:28.509 --> 00:48:35.179
When one W1 same matrix multiplies by C1,
and the W2 matrix multiplies by C2,

00:48:35.179 --> 00:48:40.025
and then you just sort of do
the element wise non linearity.

00:48:40.025 --> 00:48:42.434
Which sort of means that the two words,

00:48:42.434 --> 00:48:46.242
their meanings don't actually
really relate to each other.

00:48:46.242 --> 00:48:51.030
And hat sort of seems bad and
I'll come back to that

00:48:51.030 --> 00:48:55.021
as the sort of last
thing I touch on today.

00:48:55.021 --> 00:49:00.817
But before we get to that one, the other
thing that seems kind of dubious here is.

00:49:00.817 --> 00:49:05.409
For all semantic composition
we just have one composition

00:49:05.409 --> 00:49:07.942
function which has one matrix.

00:49:07.942 --> 00:49:11.819
So it doesn't matter whether we're
putting together an adjective and

00:49:11.819 --> 00:49:13.894
a noun or a verb and its direct object.

00:49:13.894 --> 00:49:17.924
Or even if we're putting together
the rest of a sentence with a period at

00:49:17.924 --> 00:49:18.737
the end of it.

00:49:18.737 --> 00:49:23.819
In every case we're using exactly the same
matrix multiply and saying, just multiply

00:49:23.819 --> 00:49:28.790
by that matrix and that'll put together
the meaning of your sentence for you.

00:49:28.790 --> 00:49:32.600
And that seems pretty wishful
when you think about it, and

00:49:32.600 --> 00:49:37.730
so an idea that seemed
kind of a neat idea was.

00:49:37.730 --> 00:49:40.470
Could we get something more powerful

00:49:40.470 --> 00:49:45.150
by allowing more flexibility in
the composition function for

00:49:45.150 --> 00:49:49.480
different kinds of syntactic
constructions in their composition?

00:49:49.480 --> 00:49:51.405
And so that led to the idea

00:49:51.405 --> 00:49:56.180
of Syntactically-Untied Tree
Recursive Neural Networks.

00:49:56.180 --> 00:50:00.031
Which actually proved to be
a very successful idea for

00:50:00.031 --> 00:50:03.977
building high quality parsers
that parsed very well.

00:50:03.977 --> 00:50:09.943
And essentially what this model did was
sort of argue that there's a reasonable

00:50:09.943 --> 00:50:16.105
separation that can be made between syntax
and semantics in the following sense.

00:50:16.105 --> 00:50:20.210
That there's sort of basic
syntactic structure of languages.

00:50:20.210 --> 00:50:24.872
So you have a noun phrase which
can have a smaller noun phrase,

00:50:24.872 --> 00:50:29.908
followed by a prepositional phrase,
like the man at the lectern.

00:50:29.908 --> 00:50:34.485
And that the prepositional phrase will be
a preposition followed by a noun phrase.

00:50:34.485 --> 00:50:38.863
That kind of syntactic structure
can be pretty well captured by

00:50:38.863 --> 00:50:41.510
actually a symbolic grammar.

00:50:41.510 --> 00:50:46.776
So we assumed in this model that we
did have a symbolic context free

00:50:46.776 --> 00:50:52.345
grammar backbone that was adequate for
basic syntactic structure.

00:50:52.345 --> 00:50:57.327
But the problem for
sort of traditional NLP in linguistics is,

00:50:57.327 --> 00:51:01.087
although such a backbone
is pretty adequate for

00:51:01.087 --> 00:51:06.446
telling you the possibilities for
building syntactic structure.

00:51:06.446 --> 00:51:11.885
It's not very good at working out which
structures that you should build or

00:51:11.885 --> 00:51:15.438
what is the meaning of
different kinds of units.

00:51:15.438 --> 00:51:20.094
So the suggestion is it's
perfectly fine to use discrete

00:51:20.094 --> 00:51:24.565
categorical structures for
the syntax of a language.

00:51:24.565 --> 00:51:29.835
But what we want to do is make use of
our soft vector representations for

00:51:29.835 --> 00:51:33.240
describing the meanings of languages.

00:51:33.240 --> 00:51:40.240
And so therefore we can sort of
start with that observation and

00:51:40.240 --> 00:51:46.030
then build the kind of flexibility
of composition that we're wanting.

00:51:46.030 --> 00:51:51.821
By saying well,
if we are sort of knowing about something

00:51:51.821 --> 00:51:57.019
about syntactic structures
in a categorical way.

00:51:57.019 --> 00:52:03.399
If I walk right over here, well we can
know the categories of the children,

00:52:03.399 --> 00:52:08.479
so maybe this is a preposition,
and that's a noun phrase.

00:52:08.479 --> 00:52:12.273
We can use our symbolic
grammar to sort of then say,

00:52:12.273 --> 00:52:16.607
okay these will go together
into a prepositional phrase.

00:52:16.607 --> 00:52:19.584
And so
since we know these categories here,

00:52:19.584 --> 00:52:24.917
we can then also use those categories
to decide a composition function.

00:52:24.917 --> 00:52:32.990
So we can decide, okay we're composing
together a preposition and a noun phrase.

00:52:32.990 --> 00:52:38.210
So let's use the composition function,
that's the right composition function for

00:52:38.210 --> 00:52:41.350
putting together a preposition and
a noun phrase.

00:52:41.350 --> 00:52:43.390
And so here now on this side,

00:52:43.390 --> 00:52:48.927
rather than just always using the same
W matrix for any cases of composition.

00:52:48.927 --> 00:52:51.601
Now we can say, let's use the W matrix for

00:52:51.601 --> 00:52:55.100
putting together a preposition and
a noun phrase.

00:52:55.100 --> 00:52:58.920
And that'll give us this bigger unit which
will have some category according to our

00:52:58.920 --> 00:53:00.078
syntactic grammar.

00:53:00.078 --> 00:53:04.181
And then we're gonna be putting
together an A and a P1 and so

00:53:04.181 --> 00:53:10.104
we'll be able to use the right composition
matrix to put together those categories.

00:53:14.232 --> 00:53:18.717
And there's some other good properties
of doing things this way from

00:53:18.717 --> 00:53:20.900
a practical sense.

00:53:20.900 --> 00:53:26.395
Doing simple PCFG parsing with
the categorical grammar is fast because

00:53:26.395 --> 00:53:32.085
we can do it just using the symbolic
categories and dynamic programming.

00:53:32.085 --> 00:53:35.618
And then we only have to be
doing the sort of deep learning

00:53:35.618 --> 00:53:39.690
on the structures that we know
are the ones that we want to build.

00:53:39.690 --> 00:53:44.847
So it's actually we are using syntax
to guide what we build rather

00:53:44.847 --> 00:53:51.020
than trying out every different way
of putting pairs of words together.

00:53:51.020 --> 00:53:55.540
So essentially we're using
the syntactic model to work out

00:53:55.540 --> 00:53:58.906
reasonably plausible structures for
the sentence.

00:53:58.906 --> 00:54:04.095
And then we're building the semantic
combination for those structures.

00:54:04.095 --> 00:54:08.594
And then using the semantics to do the
sort of harder decisions as to what does

00:54:08.594 --> 00:54:11.988
this prepositional phrase modify and
things like that.

00:54:11.988 --> 00:54:16.124
And so he called this result the
compositional vector grammar where it's

00:54:16.124 --> 00:54:19.860
a combination of a probabilistic
context-free grammar.

00:54:19.860 --> 00:54:25.519
Plus then using this tree structured
recursive neural networks grammar.

00:54:25.519 --> 00:54:30.675
And in this class we haven't really
talked about sort of the whole

00:54:30.675 --> 00:54:35.552
history of doing parsing for
natural language processing and

00:54:35.552 --> 00:54:38.780
the kind of grammars that people built.

00:54:38.780 --> 00:54:43.767
But in some sense you can think of
this as a generalization of the kind

00:54:43.767 --> 00:54:48.578
of things that people have been
involved in for the last decade for

00:54:48.578 --> 00:54:51.745
trying to improve the quality of parsers.

00:54:51.745 --> 00:54:56.022
So the starting point is you can just
have a context free grammar parser.

00:54:56.022 --> 00:55:00.733
And that works very badly for natural
language because you kind of can't do

00:55:00.733 --> 00:55:04.472
a good job of dealing with all
the syntactic ambiguities and

00:55:04.472 --> 00:55:08.235
deciding things like
prepositional phrase attachments.

00:55:08.235 --> 00:55:12.089
So back in 2003, Dan Klein and
me sort of said well,

00:55:12.089 --> 00:55:15.205
if we did some manual
feature engineering and

00:55:15.205 --> 00:55:19.798
we kind of split categories, and
we had fine grained categories.

00:55:19.798 --> 00:55:23.199
And so that we knew that it was not
just a prepositional phrase, but

00:55:23.199 --> 00:55:27.421
a prepositional phrase headed by all of
our prepositional phrase headed by for.

00:55:27.421 --> 00:55:32.927
We could actually just have a CFG parse
quite a lot better, and that was true.

00:55:32.927 --> 00:55:36.897
Then following on from that, a few years
after that, Slav Petrov said, well,

00:55:36.897 --> 00:55:40.518
maybe we could actually learn those
subcategories automatically, and

00:55:40.518 --> 00:55:42.280
that could help things along.

00:55:42.280 --> 00:55:44.150
And that did work, and

00:55:44.150 --> 00:55:49.290
simultaneously there was a whole line
of work on doing lexicalized parsers.

00:55:49.290 --> 00:55:55.040
Which sort of said, well a reasonable
way to represent the semantics

00:55:55.040 --> 00:55:59.500
of a phrase like,
the person at the lectern.

00:55:59.500 --> 00:56:02.230
Is to say,
what is the head word of that phrase?

00:56:02.230 --> 00:56:05.790
It's person, and
just represent the semantics

00:56:05.790 --> 00:56:09.740
of the person at the lectern
with the semantics of person.

00:56:09.740 --> 00:56:13.390
And that was a useful idea,
To help pausing and

00:56:13.390 --> 00:56:18.250
making dismbiguation decisions
because to some extent that's right.

00:56:18.250 --> 00:56:21.997
But on the other hand your
losing a lot because your saying

00:56:21.997 --> 00:56:25.745
the meaning of the person at
the lectern is just person and

00:56:25.745 --> 00:56:29.440
you've lost all the other
words of that at the lectern.

00:56:29.440 --> 00:56:33.770
And so, effectively for the CVGs,

00:56:33.770 --> 00:56:37.540
we're trying to sort of extend
that further and say, we'll no,

00:56:37.540 --> 00:56:43.290
rather than just having a sort of a finer
grains in syntactic representation,

00:56:43.290 --> 00:56:48.690
substituting in the head word and
using it as a semantic representation.

00:56:48.690 --> 00:56:52.630
We can actually calculate the semantics,
the meaning for a whole phrase, and

00:56:52.630 --> 00:56:57.680
then use that for doing our disambiguation
decisions in semantic parsing and

00:56:57.680 --> 00:57:00.170
that will be able to be more accurate.

00:57:00.170 --> 00:57:02.910
And to a first approximation,
that actually works.

00:57:02.910 --> 00:57:05.830
So here are some results from parsing.

00:57:05.830 --> 00:57:09.680
So, this is sort of trying to parse for

00:57:09.680 --> 00:57:14.065
context free grammar structures,
natural language sentences over a famous

00:57:14.065 --> 00:57:16.815
corporates of
Wall Street Journal articles.

00:57:16.815 --> 00:57:20.205
And what we're scoring here is
sort of an F1 measure as to

00:57:20.205 --> 00:57:22.645
whether you're getting
particular constituents right.

00:57:22.645 --> 00:57:26.902
So you're making constituecy claims
like that there's a noun phrase

00:57:26.902 --> 00:57:29.112
from words three to 12.

00:57:29.112 --> 00:57:31.262
And then that's either right or wrong.

00:57:31.262 --> 00:57:35.182
And so you can see how there's been
a succession of people gradually getting

00:57:35.182 --> 00:57:36.492
better at this task.

00:57:39.620 --> 00:57:44.420
So, if you just sort of have a plain CFG,
your score is about 72%.

00:57:44.420 --> 00:57:49.560
So how more kind of manually
feature engineered, whoops, sorry.

00:57:50.740 --> 00:57:52.670
Manually feature engineered,

00:57:52.670 --> 00:57:56.810
context free grammar was
considerably better, about 85%.

00:57:56.810 --> 00:58:03.240
Some of the ideas of having putting in
lexical heads were even better, 87%.

00:58:03.240 --> 00:58:07.700
The automatically splitting,
which sort of mixes syntax and

00:58:07.700 --> 00:58:11.560
lexical information,
was even better at about 90%.

00:58:11.560 --> 00:58:15.400
And, but by build, and
if you just have a plain RNN,

00:58:15.400 --> 00:58:19.790
it's sort of not that great, because
if you already just have one W matrix,

00:58:19.790 --> 00:58:23.040
you kind of can't model
a lot of composition.

00:58:23.040 --> 00:58:27.050
But by having this idea of this
syntactically untied RNN where you can

00:58:27.050 --> 00:58:32.740
learn these different composition
functions for different kinds of phrases,

00:58:32.740 --> 00:58:37.900
that that actually worked very nicely and
produced a strong, well performing parser.

00:58:37.900 --> 00:58:40.800
I mean, there are some
better parsing numbers where

00:58:40.800 --> 00:58:44.830
people have done various kinds of self
training in data orientation, and actually

00:58:44.830 --> 00:58:50.060
there's some more recent results since
2013 that I don't show in this slide.

00:58:50.060 --> 00:58:54.460
But nevertheless, this sort of proved
a successful way to sort of build,

00:58:54.460 --> 00:58:56.760
a sort of more semantically
sensitive parser.

00:58:56.760 --> 00:59:02.720
In some sense, the interest of
this isn't sort of just that,

00:59:02.720 --> 00:59:05.458
if can get parse structures right for
sentences.

00:59:05.458 --> 00:59:10.560
So the biggest interestingly
different thing here is,

00:59:10.560 --> 00:59:14.800
well actually we are computing a semantic,

00:59:14.800 --> 00:59:18.840
some meaning representation for
each phrase

00:59:18.840 --> 00:59:23.140
that gets back to that original idea
of understanding meaning similarities.

00:59:23.140 --> 00:59:25.760
And that's just something that by itself,

00:59:25.760 --> 00:59:28.750
that's sort of context free
grammar isn't giving you at all.

00:59:28.750 --> 00:59:32.350
And there's sort of some neat
things you can see out of that.

00:59:32.350 --> 00:59:36.110
I mean, one of the neat things you
can see out of this is just sort of,

00:59:36.110 --> 00:59:40.860
you can observe how
the soft grammar learns

00:59:40.860 --> 00:59:45.820
notions of where the information is,
and so what are head words and phrases.

00:59:45.820 --> 00:59:51.290
So this is as it starts to put
together pairs of words that you can

00:59:51.290 --> 00:59:56.850
see by the activations in the matrix,
as to where it's getting information from.

00:59:56.850 --> 01:00:00.260
And so there's something you
have to know to interpret this.

01:00:00.260 --> 01:00:05.639
So for training this model,
what Richard did was he started

01:00:05.639 --> 01:00:10.812
off the matrices with sort
of identity initialization.

01:00:10.812 --> 01:00:14.954
But they're sort of kind of two half
matrices with identity initialization

01:00:14.954 --> 01:00:19.425
because this is sort of the part of the
matrix that's multiplying the left child.

01:00:19.425 --> 01:00:23.415
And this is the part of the matrix
that's multiplying the right child.

01:00:23.415 --> 01:00:28.085
So they were initialized with identity
initializations we've sort of spoken about

01:00:28.085 --> 01:00:32.490
before that sort of has a similar effect
of allowing this sort of propagation of

01:00:32.490 --> 01:00:36.950
information at the beginning of training
to the kind of thing that an LSTM does.

01:00:36.950 --> 01:00:41.700
And so, if you're putting together
a noun phrase with a conjunction, so

01:00:41.700 --> 01:00:43.737
this is sort of something
like the student and.

01:00:45.420 --> 01:00:48.780
Well, it's correctly learning
that most of the information

01:00:48.780 --> 01:00:53.090
is coming from the student, and
there's relatively little coming from and.

01:00:53.090 --> 01:00:58.920
If you're putting together a possessive
pronoun and the rest of a noun phrase.

01:00:58.920 --> 01:01:03.280
So it's something like his cat.

01:01:03.280 --> 01:01:05.850
Most of the information
is coming from cat,

01:01:05.850 --> 01:01:07.885
with relatively little coming from his.

01:01:08.985 --> 01:01:12.625
And here are some other examples.

01:01:12.625 --> 01:01:15.365
If you're putting an adjective
together with a noun, so

01:01:15.365 --> 01:01:18.722
this is something like red chair.

01:01:18.722 --> 01:01:24.632
It's learning with your gain kind of quite
a lot of information from both sides.

01:01:24.632 --> 01:01:28.700
This is a whole adjective phrase and
a noun, so this is something like

01:01:28.700 --> 01:01:33.540
extremely dark movie.

01:01:33.540 --> 01:01:36.710
So you're again, getting lots
of information from both sides.

01:01:36.710 --> 01:01:39.420
And there's sort of some structure
here that you can sort of see

01:01:39.420 --> 01:01:44.030
the same dimensions seem to be marking
the kind of modifier meaning for

01:01:44.030 --> 01:01:47.150
both the adjective phrase and
just the plain adjective.

01:01:49.960 --> 01:01:51.670
So that's kind of cool.

01:01:51.670 --> 01:01:55.060
The more interesting thing
then is to sort of say, well,

01:01:55.060 --> 01:02:00.540
are we actually getting sort of a
semantics for these phrases and sentences

01:02:00.540 --> 01:02:05.400
that is capturing semantic similarity in
the way I claim right at the beginning?

01:02:05.400 --> 01:02:08.420
And actually that did
work reasonably well.

01:02:08.420 --> 01:02:13.290
So here is one sort of test that
we did to try and illustrate that.

01:02:13.290 --> 01:02:19.570
So basically we're saying okay, for any
sentence or any phrase we've calculated

01:02:19.570 --> 01:02:24.280
a meaning of that phrase so that we can
sort of place into our vector space.

01:02:24.280 --> 01:02:27.780
So just like for word vectors,
we can then say,

01:02:27.780 --> 01:02:32.380
what other sentences are placed
nearest together in the space?

01:02:32.380 --> 01:02:34.490
Cuz they should have the same meaning.

01:02:34.490 --> 01:02:39.330
So if the test sentences, all the figures
are adjusted for seasonal variations.

01:02:39.330 --> 01:02:43.360
The two closest of the sentences
in the Wall Street Journal corpus.

01:02:43.360 --> 01:02:46.820
All the numbers are adjusted for
seasonal fluctuations,

01:02:46.820 --> 01:02:51.170
all the figures are adjusted to
remove usual seasonal patterns.

01:02:51.170 --> 01:02:54.470
And this is kind of actually nice, right?

01:02:54.470 --> 01:02:59.430
That well, in some parts,
like all the figures are the same,

01:02:59.430 --> 01:03:01.450
all the numbers are very similar.

01:03:01.450 --> 01:03:04.760
But in other places it seems to have
learnt quite interesting things.

01:03:04.760 --> 01:03:07.220
So, are adjusted for seasonal variations,

01:03:07.220 --> 01:03:11.160
are adjusted to remove
usual seasonal patterns.

01:03:11.160 --> 01:03:17.360
So that's actually quite a different piece
of word choice and syntactic instruction.

01:03:17.360 --> 01:03:20.240
This learnt quite nicely that
they're very similar in meaning.

01:03:20.240 --> 01:03:24.270
Knight-Ridder wouldn't
comment on the offer.

01:03:24.270 --> 01:03:27.890
The two closest sentences
were Harsco declined to say

01:03:27.890 --> 01:03:29.485
what country placed the order.

01:03:29.485 --> 01:03:32.560
2.Coastal wouldn't disclose the terms.

01:03:32.560 --> 01:03:35.320
Those ones aren't quite so
excellent, you could say.

01:03:35.320 --> 01:03:37.080
I mean, to be fair, I mean,

01:03:37.080 --> 01:03:41.790
something that you have to be aware of is
that there are limits to how perfectly

01:03:41.790 --> 01:03:45.630
you can find other sentences that
mean roughly the same thing.

01:03:45.630 --> 01:03:50.382
Cuz this is only being run over
corpus of about 40,000 sentences so

01:03:50.382 --> 01:03:55.850
except the sort of fairly formulaic
utterances that get repeated quite a bit.

01:03:57.480 --> 01:04:01.450
Often you're gonna have to be choosing
sentences that sort of somewhat different.

01:04:01.450 --> 01:04:02.194
So you know,

01:04:02.194 --> 01:04:07.218
there probably aren't other sentences with
Knight-Ridder not commenting on the offer.

01:04:07.218 --> 01:04:11.160
So but you know, some of them
are perhaps a little bit too different.

01:04:11.160 --> 01:04:14.750
Declined to say what
country placed the order.

01:04:14.750 --> 01:04:15.430
But nevertheless,

01:04:15.430 --> 01:04:20.260
it does seem to have captured something as
to what the main semantics is going on.

01:04:20.260 --> 01:04:25.900
So, all of these, so
this first sentence is a company

01:04:25.900 --> 01:04:30.320
not wanting to say something
about some transaction.

01:04:30.320 --> 01:04:34.150
And both of these two closest sentences.

01:04:34.150 --> 01:04:38.910
Also a company not wanting to say
something about some transactions.

01:04:38.910 --> 01:04:41.870
So, there is a sort of meta-sense
in which it does seem to

01:04:41.870 --> 01:04:44.040
capture the semantic
similarity pretty well.

01:04:45.750 --> 01:04:50.770
Final example here is sales growing.

01:04:50.770 --> 01:04:55.960
And again, the two sentences that are
closest to that are both other sentences,

01:04:55.960 --> 01:04:58.670
when sales are growing further.

01:04:59.910 --> 01:05:05.100
So, that was kind of nice and
that still seemed to work pretty nicely.

01:05:05.100 --> 01:05:09.530
We still kind of weren't really
convinced that we're doing

01:05:09.530 --> 01:05:13.500
a great job at capturing
semantics of phrases.

01:05:13.500 --> 01:05:15.450
And there was still a worry.

01:05:16.460 --> 01:05:19.320
That things didn't work very well.

01:05:19.320 --> 01:05:22.270
So now, we change things so

01:05:22.270 --> 01:05:27.300
that we had different Ws depending on
whether we're combining an adjective and

01:05:27.300 --> 01:05:31.310
a noun, and a verb and its object,
or whatever like that, but

01:05:31.310 --> 01:05:36.580
otherwise we still had the problem that I
mentioned, if for that hadn't gone away.

01:05:36.580 --> 01:05:41.830
That when you're doing this
matrix vector multiply

01:05:41.830 --> 01:05:46.670
that what you're doing is you still got
kind of half of W as being multiplying

01:05:46.670 --> 01:05:50.830
itself by c1 and
half of W is multiplying itself by c2, and

01:05:50.830 --> 01:05:56.280
there is no real
interaction Between c1 and

01:05:56.280 --> 01:06:02.120
c2, and that just doesn't actually seem
what you want for natural language.

01:06:02.120 --> 01:06:02.620
Oops.

01:06:05.760 --> 01:06:06.835
Okay, sorry.

01:06:06.835 --> 01:06:09.185
That was a bit we did before.

01:06:09.185 --> 01:06:14.635
And so, in particular, you know,
what every semanticist has observed and

01:06:14.635 --> 01:06:20.680
worked to account for in symbolic
theories of semantics for the Last 40,

01:06:20.680 --> 01:06:25.920
50 years is what you actually get in
natural language is that you have words

01:06:25.920 --> 01:06:31.010
that act as operators of functions that
modify the meaning of the other words.

01:06:31.010 --> 01:06:34.890
So that if you have
something like very good, or

01:06:34.890 --> 01:06:38.940
extremely good, or quite good,
or any of those things.

01:06:38.940 --> 01:06:42.250
It seems like what you have is
you have good that has a meaning.

01:06:42.250 --> 01:06:45.520
And then very is some kind of operator or
function

01:06:45.520 --> 01:06:50.960
that'll modify the meaning of good, to
make it sort of more extreme and strong.

01:06:50.960 --> 01:06:54.680
Or weaker, depending on whether you're
saying very, extremely, quite, etc.

01:06:54.680 --> 01:06:59.810
So, it sort of seems like somehow we'd
like to be able to build neural networks

01:06:59.810 --> 01:07:03.920
that capture those kind of ideas
of composition for language.

01:07:05.090 --> 01:07:09.570
So, the last thing I want to mention
today, is this was sort of then

01:07:09.570 --> 01:07:14.940
version three of how might we
capture that composition, and

01:07:14.940 --> 01:07:19.895
so essentially,
if you have a vector here for good, and

01:07:19.895 --> 01:07:25.590
then you want to be able to modify it's
meaning with an operator, like very and

01:07:25.590 --> 01:07:31.040
how might you do that,
kind of a natural idea from sort of

01:07:31.040 --> 01:07:36.740
linear algebra to think about is,
well, what if I made very a matrix?

01:07:36.740 --> 01:07:40.530
Then I can do a matrix vector multiply,
and

01:07:40.530 --> 01:07:45.370
calculate a new vector, and
that could be a meaning of very good.

01:07:45.370 --> 01:07:49.060
And there had been some
previous work that for

01:07:49.060 --> 01:07:52.970
particular phrase combinations
had done precisely that.

01:07:52.970 --> 01:07:55.640
So, there's been a paper or
two that looked at,

01:07:55.640 --> 01:07:59.310
let's describe the meaning of
adjective noun combinations or

01:07:59.310 --> 01:08:04.050
adverb adjective combinations by doing
that kind of matrix-vector multiply.

01:08:04.050 --> 01:08:09.090
But we wanted something more general
that could be applied to whole sentences

01:08:09.090 --> 01:08:12.230
arbitrarily to come up with a meaning,
and so,

01:08:12.230 --> 01:08:17.090
this came up with a model where sort
of we were going to have matrixes and

01:08:17.090 --> 01:08:23.180
vectors and we were going to combine
them together in all ways to try and

01:08:23.180 --> 01:08:27.120
create sort of meanings for phrases, so.

01:08:27.120 --> 01:08:32.850
If we now had very good,what we gonna
say is well we are not quite sure

01:08:32.850 --> 01:08:37.911
when something is gonna be an operator and
when it's gonna be operated on.

01:08:37.911 --> 01:08:41.760
So let's just have it both ways and
see what comes out.

01:08:41.760 --> 01:08:46.960
So, each word is going to be represented
by both vector and the matrix,

01:08:46.960 --> 01:08:51.960
so very and good are both represented
by vector and the matrix and so then,

01:08:51.960 --> 01:08:58.180
to compute representation of the phrase
very good, what we are then going to do

01:08:58.180 --> 01:09:03.550
is we're going to multiply
the vector by the matrix.

01:09:03.550 --> 01:09:09.080
So, big a with little b and we're going
to multiply big b by little a and

01:09:09.080 --> 01:09:13.190
so, we're going to do both
vector matrix multiplies and

01:09:14.240 --> 01:09:19.540
then having done that we're going to
concatenate those as we've done before.

01:09:20.720 --> 01:09:25.830
And then we're gonna multiply it, put it
through a neural network layer just like

01:09:25.830 --> 01:09:31.660
before so we have another W matrix to
the decide which of these to use and

01:09:31.660 --> 01:09:34.680
how, it goes through a tanh and
that gives our parent representation.

01:09:34.680 --> 01:09:39.490
So at that point we've got a vector
representation for the parent.

01:09:40.820 --> 01:09:42.740
And that sort of looks hopeful.

01:09:42.740 --> 01:09:47.530
But well, we wanna keep on building this
up into a representation of whole phrases

01:09:47.530 --> 01:09:50.020
and we wanna be able to
build very good movie.

01:09:50.020 --> 01:09:53.590
And well, at that point,
we sort of conceptually wanna be using

01:09:53.590 --> 01:09:58.570
the word vector for movie and would like
to say well this is another operator and

01:09:58.570 --> 01:10:02.020
we'd like to multiply very good by movie.

01:10:02.020 --> 01:10:07.260
So, to do that, we're gonna have to also
have a matrix coming out for very good.

01:10:07.260 --> 01:10:09.790
And so we wanted to build one of those,
and so.

01:10:11.050 --> 01:10:16.360
We said well in addition to that,
what we could do is put

01:10:16.360 --> 01:10:21.670
together the two matrices A and
B that we got down here.

01:10:21.670 --> 01:10:25.260
We can concatenate them to
build a bigger matrix and

01:10:25.260 --> 01:10:27.750
do a matrix multiplier on that, and

01:10:27.750 --> 01:10:33.110
that would then give us a representation,
a matrix representation of the parent.

01:10:33.110 --> 01:10:39.910
And so formally now our parent has- will
now have both a vector and a matrix.

01:10:39.910 --> 01:10:45.000
So, I'll show you a bit about this model.

01:10:45.000 --> 01:10:52.320
It could do some quite interesting
things and it also had some weaknesses.

01:10:52.320 --> 01:10:55.980
And I think- In terms of
where the weaknesses are,

01:10:55.980 --> 01:10:58.080
if I give the game away
right at the beginning,

01:10:58.080 --> 01:11:01.850
a lot of the weaknesses were in
this part here for the matrices.

01:11:01.850 --> 01:11:04.270
Cuz we sort of had problems with that.

01:11:04.270 --> 01:11:08.090
I mean, firstly,
the matrices were kinda problematic,

01:11:08.090 --> 01:11:11.240
because matrices have a lot
of parameters in them.

01:11:11.240 --> 01:11:15.600
And so, that makes it hard to learn them
effectively, and that's an idea that

01:11:15.600 --> 01:11:19.690
perhaps be revisited using some ideas
that have come up since then, but

01:11:19.690 --> 01:11:25.750
secondly we didn't have a very good
way of composing matrices to build,

01:11:25.750 --> 01:11:28.910
picking new matrices so
that part of the model perhaps wasn't so

01:11:28.910 --> 01:11:34.420
great, but here is sort of a picture that
sort of shows you some of the things

01:11:34.420 --> 01:11:38.990
that you would like to be able to do and
whether models can do them.

01:11:38.990 --> 01:11:44.260
So, we're looking now at building two
word combinations, so, fairly annoying,

01:11:44.260 --> 01:11:49.300
fairly awesome, fairly sad,
not annoying, not awesome, not sad,

01:11:49.300 --> 01:11:54.190
unbelievably annoying,
unbelievably awesome, unbelievably sad.

01:11:54.190 --> 01:11:58.931
And then what we're wanting to
do is take those phrases and

01:11:58.931 --> 01:12:02.900
interpret their sentiment and
put a probability

01:12:02.900 --> 01:12:07.660
distribution over sentiment
scores between 1 and 10.

01:12:07.660 --> 01:12:12.070
So, 10 is extremely good,
and 1 is extremely bad.

01:12:13.300 --> 01:12:19.150
And for some pairs of words, we actually

01:12:19.150 --> 01:12:24.720
had some sort of empirical data that was
kind of connected to these meanings.

01:12:24.720 --> 01:12:28.230
The empirical data was kind of
a sort of distant supervision,

01:12:28.230 --> 01:12:30.180
not to be trusted very much.

01:12:30.180 --> 01:12:35.630
But this was sort of saying well suppose
we'd seen a review of a movie that

01:12:35.630 --> 01:12:42.660
said not said and that what rating
was being given to that movie and

01:12:42.660 --> 01:12:47.300
it was sometimes a bad rating,
occasionally a good rating.

01:12:47.300 --> 01:12:51.340
And that sort of was shown in that
one example for the red line.

01:12:51.340 --> 01:12:55.730
But what's perhaps more
interesting to see is that

01:12:55.730 --> 01:13:00.570
the sum of these
Combinations that the plain

01:13:00.570 --> 01:13:04.550
RNN is actually more effective than you
might have thought it first it will be.

01:13:04.550 --> 01:13:07.150
So if it's something like
unbelievably awesome,

01:13:08.170 --> 01:13:12.750
that can be captured pretty
well in the model captures,

01:13:12.750 --> 01:13:17.300
that unbelievably awesome that even
the basic RNN model is good at knowing,

01:13:17.300 --> 01:13:21.520
that means it's a very good movie and
very positive sentiment.

01:13:21.520 --> 01:13:26.050
We can even do some sort
of more interesting things.

01:13:26.050 --> 01:13:30.850
So if you have the phrase unbelievably
sad it turns out that that's kind of

01:13:30.850 --> 01:13:35.220
ambiguous that there many really good
movies that are unbelievably sad.

01:13:35.220 --> 01:13:38.850
So there's a lot of weight over here and
then, there are some cases

01:13:38.850 --> 01:13:42.938
where people say, a movie is unbelievably
sad, because it's just terrible.

01:13:42.938 --> 01:13:47.320
[LAUGH] And so, you're actually
getting this sort of U shape,

01:13:47.320 --> 01:13:50.750
where you get some weight on
both ends of the spectrum.

01:13:50.750 --> 01:13:55.876
And, interestingly, even the plain RNN,
and also our matrix vector

01:13:55.876 --> 01:14:01.030
RNN is able to capture that pretty well,
so that's kind of nice.

01:14:01.030 --> 01:14:06.410
But, there are some things
that the basic RNN just

01:14:06.410 --> 01:14:11.305
isn't able to capture right,
where our new model does a lot better.

01:14:11.305 --> 01:14:16.655
So if you look in these middle row ones,
like not annoying and not awesome.

01:14:16.655 --> 01:14:23.630
That, by itself, the word not just tends
to be a marker of negativity, right?

01:14:23.630 --> 01:14:27.150
People who go around saying not a lot,
negative people.

01:14:27.150 --> 01:14:31.240
So all else be equal if you
see the word not in something

01:14:31.240 --> 01:14:33.610
sentiment is more likely to be negative.

01:14:33.610 --> 01:14:37.990
And then the word like annoying
that's a negative sentiment word.

01:14:37.990 --> 01:14:42.530
And so for the basic RNN model if you put
those together they just have a kind of

01:14:42.530 --> 01:14:48.440
additive effect it turns out, so that's
the green line where it says not annoying,

01:14:48.440 --> 01:14:53.930
it predicts that means bad movie low
rating, whereas the result we'd like

01:14:53.930 --> 01:14:58.880
to have is that not is an operator and
it modifies the meaning of annoying and

01:14:58.880 --> 01:15:02.530
this means like it's not so
bad and it's not annoying.

01:15:02.530 --> 01:15:07.570
And the interesting thing about natural
languages is that they sort of don't work

01:15:07.570 --> 01:15:12.440
like sort of basic logic where basic
logic might tell you that not annoying

01:15:12.440 --> 01:15:17.190
means this is a good movie because it's
not annoying where if real human beings

01:15:17.190 --> 01:15:23.058
when they say words like not bad, or
not annoying, they mean it's sort of okay.

01:15:23.058 --> 01:15:26.034
And so,

01:15:26.034 --> 01:15:31.100
the distribution that the matrix
vector model comes up with

01:15:31.100 --> 01:15:35.240
is sort of flat, but it's sort of at least
basically right that it actually gives

01:15:35.240 --> 01:15:40.300
the highest probability to the midrange of
the distribution, which is kinda correct.

01:15:40.300 --> 01:15:44.640
And you see a similar
effect with not awesome,

01:15:44.640 --> 01:15:47.820
that the basic RNN isn't
able to capture that,

01:15:47.820 --> 01:15:52.370
it's still giving most of its weight
to saying I've seen the word awesome,

01:15:52.370 --> 01:15:57.150
this is a good movie, whereas the matrix
vector RNN is at least done sort of

01:15:57.150 --> 01:16:02.530
better and it's tapped down, giving weight
to meaning that it's a great movie.

01:16:02.530 --> 01:16:05.400
So it sort of seems like we're kinda doing

01:16:05.400 --> 01:16:08.600
better at being able to
model meaning combinations.

01:16:08.600 --> 01:16:09.100
Yes?

01:16:38.108 --> 01:16:42.887
Okay, so the question is, is it really
wise to be doing it both ways with

01:16:42.887 --> 01:16:48.225
the matrix and the vector or could you
actually use your syntactic structure and

01:16:48.225 --> 01:16:52.715
know which way to apply these two
things and do it only one way?

01:16:52.715 --> 01:16:55.780
Yeah, so, these results,
even though all my phrases have

01:16:55.780 --> 01:16:59.620
the operator on the left and
the thing being modified on the right.

01:16:59.620 --> 01:17:04.320
This is sort of running that
symmetric matrix vector model, and

01:17:04.320 --> 01:17:05.580
it's just doing it both ways.

01:17:05.580 --> 01:17:09.890
So I think you're totally right,
it wasn't something we did in this work.

01:17:09.890 --> 01:17:14.550
But it seems like you can very
reasonably say well wait a minute.

01:17:14.550 --> 01:17:18.260
Why can't you take both of these two
models that you've just shown us?

01:17:18.260 --> 01:17:21.570
If you're using the sort of
syntactically untied model,

01:17:21.570 --> 01:17:24.020
you know that if you're doing adjective

01:17:24.020 --> 01:17:28.280
noun combination you should treat
the thing on the left as the operator.

01:17:28.280 --> 01:17:31.300
And then you can just run
it in one direction and

01:17:31.300 --> 01:17:36.320
I mean, in general I think that'd
be a very reasonable thing to try.

01:17:36.320 --> 01:17:39.850
It sort of means that you have
to have complete coverage.

01:17:39.850 --> 01:17:43.190
And so you've decided in every
case of when two different

01:17:43.190 --> 01:17:44.780
categories come together.

01:17:44.780 --> 01:17:50.570
You have to decide for sure which is the
one you're going to treat as the operator

01:17:50.570 --> 01:17:53.310
and you know that might actually
require quite a bit of work to do.

01:17:53.310 --> 01:17:55.610
In principle you could do it and
that would work.

01:17:57.295 --> 01:18:03.290
Yea, so we're basically done for
today but just to show you

01:18:03.290 --> 01:18:08.300
sort of one other thing that we were able
to do with the matrix vector model, which

01:18:08.300 --> 01:18:13.920
was sort of a nice example of how we're
able to use this model to do an NLP task.

01:18:13.920 --> 01:18:18.319
So this was a task of learning
semantic relationships as

01:18:18.319 --> 01:18:21.228
a kind of relation extraction task.

01:18:21.228 --> 01:18:26.429
So, this was a data set that some people
had explored where you had sentences like,

01:18:26.429 --> 01:18:31.037
my apartment has a pretty large kitchen
and then what you meant to say was,

01:18:31.037 --> 01:18:34.856
what is the relationship,
between apartment and kitchen?

01:18:34.856 --> 01:18:38.332
And there were set of relationships
that they could have and

01:18:38.332 --> 01:18:42.711
one of them was that component whole
relationship and so the correct answer

01:18:42.711 --> 01:18:47.158
here was to say that the kitchen is a
component of the apartment and then there

01:18:47.158 --> 01:18:51.570
were various other relationships that
could be a tool what you were using.

01:18:51.570 --> 01:18:54.250
It could be the material
something was made out of and

01:18:54.250 --> 01:18:56.660
various other kinds of relationships.

01:18:56.660 --> 01:19:00.120
And so,
we explored using this matrix vector,

01:19:01.210 --> 01:19:04.590
recursive neural network to
learn these relationships.

01:19:04.590 --> 01:19:08.480
And so, the way that we were doing that
Is we were sort of building up semantic

01:19:08.480 --> 01:19:12.840
compositions using the matrix
vector RNN model, and so

01:19:12.840 --> 01:19:18.950
we build up this semantic compositions
until you reach the point where the two

01:19:20.560 --> 01:19:25.440
noun phrases of interest joined together
in the structure of the sentence.

01:19:25.440 --> 01:19:30.470
So the movie showed wars, so
this was the sort of the message,

01:19:30.470 --> 01:19:33.420
the content that's being
shown on this media.

01:19:34.950 --> 01:19:39.470
So, where they join together,
we'd say, okay, we've built

01:19:39.470 --> 01:19:44.320
up a semantic representation that
covers the movie showed wars.

01:19:44.320 --> 01:19:47.440
So at this point,
we then use another neural network,

01:19:47.440 --> 01:19:50.830
that's just a straight
classifier that says okay,

01:19:50.830 --> 01:19:55.110
classify the relationship here,
it's an example of message topic.

01:19:56.910 --> 01:20:03.000
So we built that model and this is
a nice example where it seemed like we

01:20:03.000 --> 01:20:07.700
weren't able to show, that again, having
this extra power gave us extra power.

01:20:07.700 --> 01:20:10.710
So here are just some results on that.

01:20:10.710 --> 01:20:13.555
So people had worked on
these data set previously.

01:20:13.555 --> 01:20:19.831
So as a sort of basic support
vector machine got about 60% F1,

01:20:19.831 --> 01:20:24.511
MaxEnt model so
it's like a logistic regression

01:20:24.511 --> 01:20:28.660
model with a lot of features, got 77%.

01:20:28.660 --> 01:20:34.140
SVM model with a huge amount of hand
built linguistic resources and features.

01:20:34.140 --> 01:20:40.090
So this is using everything, it's using
WordNet, dependency parses, Levin verb

01:20:40.090 --> 01:20:44.920
classes, PropBank, FrameNet, NomLex-Plus,
Google n-grams, paraphrases, TextRunner.

01:20:44.920 --> 01:20:46.350
Every feature and

01:20:46.350 --> 01:20:51.710
knowledge source you could possibly
think of to throw into it got 82.2%.

01:20:51.710 --> 01:20:55.950
So here are our results with
our neural network model.

01:20:55.950 --> 01:21:02.721
So the plain recursive neural network
got held a little under 75% so

01:21:02.721 --> 01:21:10.411
that's actually pretty good when all its
doing is learning its own semantics,

01:21:10.411 --> 01:21:16.770
representations that puts
things together but not quite.

01:21:16.770 --> 01:21:18.190
Winning the pack.

01:21:18.190 --> 01:21:21.930
So the matrix vector model actually
is clearly doing something useful,

01:21:21.930 --> 01:21:26.810
so it's sort of getting you
about 4% better scores.

01:21:26.810 --> 01:21:31.040
So that shows we have made some
progress in semantic representation.

01:21:31.040 --> 01:21:32.270
Of course, like everyone else,

01:21:32.270 --> 01:21:35.960
we wanted to have our model better
than the last people's model.

01:21:35.960 --> 01:21:40.280
So then we sort of built a model that sort
of put in a few semantic features, but

01:21:40.280 --> 01:21:43.810
only, sorry, a few extra features,
but only fairly basic ones.

01:21:43.810 --> 01:21:46.530
WordNet, part-of-speech, and
NER, and that was sort of, hey,

01:21:46.530 --> 01:21:51.440
I wanna push this just over the line, but
I think the main message is that you're

01:21:51.440 --> 01:21:57.320
sort of starting to get decent semantic
models of phrase relationships without

01:21:57.320 --> 01:22:02.080
actually having much more than just these
continuous representations of semantics.

01:22:02.080 --> 01:22:06.380
Okay, I'll stop there for now and
we'll get to more next week.

