WEBVTT
Kind: captions
Language: en

00:00:01.580 --> 00:00:05.660
The first step in any kind of question
answering is answer type detection and

00:00:05.660 --> 00:00:06.530
query formulation.

00:00:08.050 --> 00:00:11.410
So going back to our box diagram here,
our flowchart.

00:00:13.150 --> 00:00:16.190
We have a question, and the first thing
we're going to do in question processing

00:00:16.190 --> 00:00:17.990
is understand what's being asked here.

00:00:20.340 --> 00:00:23.420
There are as many as five things that
we normally extract from a question.

00:00:24.500 --> 00:00:26.880
Perhaps the most important
is the answer type.

00:00:26.880 --> 00:00:29.710
This is a named entity,
a person, or a place, or

00:00:29.710 --> 00:00:32.590
a date that tells us what we're
looking for in this factoid question.

00:00:33.890 --> 00:00:35.800
Query formulation, equally important.

00:00:35.800 --> 00:00:38.480
That's the set of words we're
going to send to the IR engine

00:00:38.480 --> 00:00:42.820
that tells us what to look for, what
passages are likely to have the answer.

00:00:42.820 --> 00:00:46.680
And then other kinds of things depending
on the system may also be extracted.

00:00:46.680 --> 00:00:49.350
So, question type classification
we want to know for

00:00:49.350 --> 00:00:51.150
example, is this a definition question,

00:00:51.150 --> 00:00:54.680
we might have to find the definition
in a dictionary or build one ourselves.

00:00:54.680 --> 00:00:57.370
Is it a math question,
we might want to answer that with

00:00:57.370 --> 00:01:00.980
mathematics directly rather than
going to find text snippets.

00:01:00.980 --> 00:01:03.100
Or a list question,
we're looking for lists of things so

00:01:03.100 --> 00:01:05.630
we might want to look for
for list sources.

00:01:05.630 --> 00:01:08.270
And there are other kinds of
things like focus detection, so

00:01:08.270 --> 00:01:11.540
find the question words that
are being replaced by the answer.

00:01:11.540 --> 00:01:13.040
Or relation extraction,

00:01:13.040 --> 00:01:15.260
find all the relations between
entities in the question.

00:01:15.260 --> 00:01:17.540
We talked about relation
extraction earlier and

00:01:17.540 --> 00:01:19.744
these are used by some systems and
not by others.

00:01:19.744 --> 00:01:25.090
So here's an example of the kinds of
things we can extract from questions,

00:01:25.090 --> 00:01:26.470
this is from a Jeopardy kind of question.

00:01:27.550 --> 00:01:30.250
So, they're the two states
you could be reentering

00:01:30.250 --> 00:01:32.578
if you're crossing
Florida's northern border.

00:01:32.578 --> 00:01:34.690
So here we're looking for
a state, a US state, so

00:01:34.690 --> 00:01:37.430
the answer type we are looking for
is a state.

00:01:37.430 --> 00:01:41.500
What we might want to send to
the IR engine is, two states,

00:01:41.500 --> 00:01:43.310
border, Florida, and north.

00:01:43.310 --> 00:01:47.320
These words are going to be good words to
find passages that might have the answer.

00:01:47.320 --> 00:01:51.350
The focus, the thing that we're
trying to answer, is two states.

00:01:52.670 --> 00:01:54.879
And the relations that we might extract,
or

00:01:54.879 --> 00:01:59.790
the relations that express what the answer
is, is the answer is some unknown thing

00:01:59.790 --> 00:02:03.650
which is in the borders relation
with Florida and north.

00:02:03.650 --> 00:02:05.630
So something that's north of Florida.

00:02:05.630 --> 00:02:10.580
So if we have databases that express
geographical information like

00:02:10.580 --> 00:02:13.990
what state borders what state, we might
look for this relation in those databases.

00:02:16.800 --> 00:02:20.750
So the first step, answer type detection,
here we just need named entities.

00:02:20.750 --> 00:02:23.450
So if I see a question like
who founded Virgin Airlines?

00:02:23.450 --> 00:02:24.990
The answer type is a person.

00:02:24.990 --> 00:02:28.590
If I see a question like, what Canadian
city has the largest population?

00:02:28.590 --> 00:02:30.200
The answer is a city.

00:02:30.200 --> 00:02:30.980
Relatively simple.

00:02:32.330 --> 00:02:34.710
And for
that we need an answer type taxonomy.

00:02:34.710 --> 00:02:38.630
A type of name entities that might
be useful in question answering.

00:02:38.630 --> 00:02:41.340
So for example here's
the taxonomy from Li and Roth.

00:02:41.340 --> 00:02:43.500
They talked about six course classes.

00:02:43.500 --> 00:02:46.020
We might ask about abbreviations or
entities,

00:02:46.020 --> 00:02:50.420
descriptions of entities,
people, places, and numbers.

00:02:50.420 --> 00:02:51.590
You know,
the kind of things we might have.

00:02:51.590 --> 00:02:54.820
And inside those we might have
more specific classes, so we might

00:02:54.820 --> 00:02:58.750
be asking about a city or a country or
a mountain as a type of location.

00:02:58.750 --> 00:03:01.820
Or we could be asking about a person or
a group of people and

00:03:01.820 --> 00:03:04.230
we could be asking about all sorts
of different kinds of entities.

00:03:06.210 --> 00:03:10.320
And here's their answer type
taxonomy showing some of

00:03:10.320 --> 00:03:15.290
the individual subtypes of
the major six entity types.

00:03:15.290 --> 00:03:20.110
So a numeric question could be a date
question or a distance question or

00:03:20.110 --> 00:03:22.030
a percent question and so on.

00:03:22.030 --> 00:03:24.500
Any of these kind of types
that we might want to find.

00:03:26.600 --> 00:03:29.560
And here's just showing you, it's in the
small font, so you can come back and look

00:03:29.560 --> 00:03:34.150
at it later, but the kind of answer types
that are in the Li and Roth Taxonomy.

00:03:34.150 --> 00:03:38.140
So we might have currencies, or diseases,
or foods, or instruments, and so on,

00:03:38.140 --> 00:03:39.959
and then some examples of each of these.

00:03:40.970 --> 00:03:44.680
Or for locations,
we might have mountains or states.

00:03:44.680 --> 00:03:47.740
And all sorts of things for
numbers, speeds, and sizes, and

00:03:47.740 --> 00:03:48.580
temperatures and so on.

00:03:51.840 --> 00:03:54.040
The Jeopardy system also
used a lot of answer types.

00:03:54.040 --> 00:03:57.150
And they did a nice analysis looking

00:03:57.150 --> 00:04:00.230
at 2,500 answer types
inside 20,000 questions.

00:04:00.230 --> 00:04:04.750
And what they found was that the most
frequent 200 answer types covers

00:04:04.750 --> 00:04:06.280
less than half of the data.

00:04:06.280 --> 00:04:08.990
Here's the 40 most frequent
Jeopardy answer types.

00:04:08.990 --> 00:04:12.780
So you see in Jeopardy, you tend to
be asking about people or movies or

00:04:12.780 --> 00:04:14.880
countries or cities and so on.

00:04:14.880 --> 00:04:18.050
Here's more people, authors, and so on.

00:04:18.050 --> 00:04:20.970
But still it's a pretty broad
distribution of possible answer types.

00:04:20.970 --> 00:04:24.691
So we're going to need a large number
of answer type detectors to really get

00:04:24.691 --> 00:04:27.924
a large set of questions for
something like Jeopardy or even for

00:04:27.924 --> 00:04:29.401
easier factoid questions.

00:04:30.882 --> 00:04:33.540
How do we do answer type detection?

00:04:33.540 --> 00:04:37.090
Like almost everything we've seen so
far, we can do hand-written rules,

00:04:37.090 --> 00:04:39.720
we can do machine learning or
we can do hybrids of the two.

00:04:39.720 --> 00:04:43.939
And we're going to see all three
of this in modern systems.

00:04:43.939 --> 00:04:45.345
So for example, for

00:04:45.345 --> 00:04:50.990
some kinds of answers we might do very
well with regular expression rules.

00:04:50.990 --> 00:04:56.129
If we see who and then a form of to be,
and then a named entity, person,

00:04:56.129 --> 00:05:00.939
then our guess is that we're asking,
this is a person question.

00:05:00.939 --> 00:05:07.198
Or if we see in an answer
PERSON (YEAR-YEAR),

00:05:07.198 --> 00:05:13.164
we know that we're looking here for
a person.

00:05:17.622 --> 00:05:21.625
In other kind of rules, we're going to
be using the question headword.

00:05:21.625 --> 00:05:26.785
And the headword is generally the head of
the first noun phrase after the wh-word.

00:05:26.785 --> 00:05:30.075
So here we have wh-word, which,
and then the headword is city.

00:05:30.075 --> 00:05:34.140
Or here we have wh-word, what, and

00:05:34.140 --> 00:05:37.968
here's the noun phrase the state flower
of California and its head is flower.

00:05:37.968 --> 00:05:42.290
So this headword often will tell
us a lot about the answer type.

00:05:42.290 --> 00:05:45.460
This tells us we're looking for city and
it tells us we're looking for a flower.

00:05:48.740 --> 00:05:51.950
But more often rather than simply
writing hand-written rules,

00:05:51.950 --> 00:05:54.330
we treat the problem as machine learning.

00:05:54.330 --> 00:05:56.190
So we define a taxonomy of question types.

00:05:56.190 --> 00:05:57.400
We've seen some already.

00:05:57.400 --> 00:06:01.380
We annotate trading data for each question
type, and now we'll train classifiers

00:06:01.380 --> 00:06:04.330
using some rich set of features which
might include those hand-written rules we

00:06:04.330 --> 00:06:07.870
talked about to decide what
question type a question is.

00:06:07.870 --> 00:06:09.630
What's the answer type of
a particular question.

00:06:11.190 --> 00:06:14.886
And the features we're going to use for
these answer types, the words or phrases

00:06:14.886 --> 00:06:19.087
in the answer, the parts-of-speech tag, we
might use the headwords we talked about,

00:06:19.087 --> 00:06:22.672
named entities, semantically related
words and all of this kind of regular

00:06:22.672 --> 00:06:25.945
expressions we can hand-write for
particular question patterns.

00:06:30.589 --> 00:06:32.460
The next step in Factoid Q/A.

00:06:32.460 --> 00:06:35.160
Now we've done answer type detection.

00:06:35.160 --> 00:06:37.310
The next step is query formulation.

00:06:37.310 --> 00:06:42.084
How do we decide what words to send to
the IR engine to return documents and

00:06:42.084 --> 00:06:43.193
then passages?

00:06:45.283 --> 00:06:50.552
And one well-known keyword selection
algorithm from Moldovan et al,

00:06:50.552 --> 00:06:55.467
uses a number of heuristics,
each of which tell you which keywords

00:06:55.467 --> 00:07:00.790
in the question might be important
keywords to put in the query.

00:07:00.790 --> 00:07:03.140
So, if we see words in quotations,

00:07:03.140 --> 00:07:06.280
that's a very likely word
that people are looking for.

00:07:06.280 --> 00:07:09.690
And another important thing to look for
is proper names and

00:07:09.690 --> 00:07:11.290
then other kinds of nominals.

00:07:11.290 --> 00:07:13.250
And maybe less important verbs.

00:07:13.250 --> 00:07:15.450
And then even less important adverbs.

00:07:15.450 --> 00:07:17.620
And maybe all other words
might be even less important.

00:07:17.620 --> 00:07:20.585
So we have a ranking of what words
are important to put in the query.

00:07:22.215 --> 00:07:25.595
So for example,
here's a slide from Mihai Surdeanu.

00:07:25.595 --> 00:07:27.485
So we have a question like,

00:07:27.485 --> 00:07:31.265
who coined the term "cyberspace"
in his novel "Neuromancer"?

00:07:31.265 --> 00:07:34.369
Well, we might throw out some stop words.

00:07:35.450 --> 00:07:38.050
So who, and, the, and, in, and his.

00:07:38.050 --> 00:07:41.080
And now we might say, well,
"cyberspace" and "Neuromancer",

00:07:41.080 --> 00:07:45.290
those are probably things we definitely
want to be putting in the query.

00:07:45.290 --> 00:07:48.100
Term and novel are nominals, and

00:07:48.100 --> 00:07:52.380
we saw nominals are an important thing,
right, we ranked them as rank 4.

00:07:52.380 --> 00:07:54.660
And now a verb might be rank 7.

00:07:54.660 --> 00:07:58.960
So we might say extract
from this that we have

00:07:58.960 --> 00:08:02.990
two terms that are extremely likely we
want to be in the query and something that

00:08:02.990 --> 00:08:07.540
is a little less likely, couple of less
likely things and even less likely.

00:08:07.540 --> 00:08:09.280
So now we can form
the query in various ways,

00:08:09.280 --> 00:08:12.650
we can try just sending
the things of rank 1, or

00:08:12.650 --> 00:08:17.580
we can send and go until we have enough
query words to make a long query.

00:08:17.580 --> 00:08:21.000
Or we can send the things of rank 1 and
see how many queries we get back, and

00:08:21.000 --> 00:08:24.300
if there's not enough,
add in more query terms and so on.

00:08:24.300 --> 00:08:28.140
So what we do with these ranking of
queries depends on exactly what database

00:08:28.140 --> 00:08:31.130
we're querying, whether it's the web or
a smaller database and so on.

00:08:33.755 --> 00:08:39.940
So we've seen the first step in
factoid-based, IR-based, factoid

00:08:39.940 --> 00:08:43.880
question answering, which is extracting
an answer type from the question and

00:08:43.880 --> 00:08:46.600
extracting the query terms that we're
going to send to the IR engine.

