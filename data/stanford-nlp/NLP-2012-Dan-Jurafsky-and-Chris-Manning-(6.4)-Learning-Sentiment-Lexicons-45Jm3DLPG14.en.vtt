WEBVTT
Kind: captions
Language: en

00:00:00.750 --> 00:00:04.466
While it's great that there's
sentiment lexicons available, for

00:00:04.466 --> 00:00:08.191
lots of other purposes, we like to
build our own sentiment lexicon.

00:00:08.191 --> 00:00:12.324
And the way we do this is often
by semi-supervised learning.

00:00:12.324 --> 00:00:15.074
And the idea of semi-supervised
learning is we have some

00:00:15.074 --> 00:00:16.570
small amount of information.

00:00:16.570 --> 00:00:21.230
Maybe we have a few labeled examples or
maybe we have a few hand built patterns.

00:00:21.230 --> 00:00:25.533
And from that set of data we'd like
to bootstrap a complete lexicon.

00:00:25.533 --> 00:00:29.000
And we might want to do learning of
lexicons instead of taking an online

00:00:29.000 --> 00:00:32.768
lexicon if we're looking at a particular
domain that maybe doesn't match

00:00:32.768 --> 00:00:37.270
the domain of the lexicon that was built,
or we're trying to do a particular task.

00:00:37.270 --> 00:00:42.172
Or maybe we just think that our
online lexicons might not have enough

00:00:42.172 --> 00:00:46.226
words that are relevant to
the topic we're looking at.

00:00:46.226 --> 00:00:51.197
One of the earliest ways of inducing this
kind of sentiment lexicon was proposed

00:00:51.197 --> 00:00:54.177
in 1997 by Hatzivassiloglou and McKeown.

00:00:54.177 --> 00:00:58.326
And I'm going to show you this because,
although the paper is old,

00:00:58.326 --> 00:01:02.477
this intuition is included in almost
all modern ways of doing this

00:01:02.477 --> 00:01:05.729
semi-supervised learning
of getting a lexicon.

00:01:05.729 --> 00:01:10.586
And their intuition very simple is that
two adjectives if they're conjoined by

00:01:10.586 --> 00:01:13.774
the word and
they probably have the same polarity and

00:01:13.774 --> 00:01:17.048
if they're conjoined by the word but,
they don't.

00:01:17.048 --> 00:01:21.573
So if you see a very high frequency
of fair and legitimate or corrupt and

00:01:21.573 --> 00:01:25.960
brutal probably fair and
legitimate are both on the same polarity.

00:01:27.010 --> 00:01:29.780
So we might suspect that fair and

00:01:29.780 --> 00:01:33.990
brutal are just less likely to
occur on the web or in some corpus.

00:01:33.990 --> 00:01:36.431
So if we see a lot of
something occurring with and,

00:01:36.431 --> 00:01:39.002
maybe the two are likely
to have the same sentiment.

00:01:39.002 --> 00:01:45.138
But if we see two words linked by but,
they probably have different sentiments.

00:01:45.138 --> 00:01:50.206
So fair but brutal is more likely
to occur than fair and brutal.

00:01:50.206 --> 00:01:52.202
And here's they use this intuition.

00:01:52.202 --> 00:01:58.390
They first labeled by hand
a seed set of 1300 adjectives.

00:01:58.390 --> 00:02:01.717
And so they had about a similar number
of positive and negative adjectives.

00:02:01.717 --> 00:02:05.049
So central, clever, or
famous, or thriving.

00:02:05.049 --> 00:02:09.992
And negative adjectives like ignorant or
listless or unresolved.

00:02:13.928 --> 00:02:15.279
And now from the seed set,

00:02:15.279 --> 00:02:19.593
they expand that to any adjective that's
conjoined with a word in their scene set.

00:02:19.593 --> 00:02:23.832
So for example, we can go to Google and
we can type in,

00:02:23.832 --> 00:02:27.709
was nice and, and
look at what words occur next.

00:02:27.709 --> 00:02:33.883
And what do we see after, was nice and,
well we see, was nice and helpful.

00:02:33.883 --> 00:02:37.992
So that tells us that nice, and helpful
are likely to have the same sentiment.

00:02:37.992 --> 00:02:41.824
And here we see nice and classy.

00:02:41.824 --> 00:02:45.123
So that tells us that nice and
classy might have the same sentiment.

00:02:45.123 --> 00:02:50.487
And we can do that for all sorts of words
that occur conjoined with our seed set.

00:02:50.487 --> 00:02:55.406
And we take any word that occurs
frequently enough in the right conjunction

00:02:55.406 --> 00:02:57.055
with our seed set words.

00:02:57.055 --> 00:03:02.345
And now we can build
from that a classifier.

00:03:02.345 --> 00:03:06.680
And the job of the classifier
is just to assign for

00:03:06.680 --> 00:03:11.244
each pair of words,
how similar the two words are.

00:03:11.244 --> 00:03:15.296
And so we can give the classifier
the count of the two words occurring with

00:03:15.296 --> 00:03:19.214
an and in between them, and a count
of the two words occurring with a but

00:03:19.214 --> 00:03:20.224
in between them.

00:03:20.224 --> 00:03:25.108
And the classifier can learn that nice and
helpful are somewhat similar, nice and

00:03:25.108 --> 00:03:28.859
fair are very similar, fair and
corrupt are very dissimilar,

00:03:28.859 --> 00:03:31.420
marked them in red with a dotted line.

00:03:31.420 --> 00:03:34.680
Because maybe but occurs much more
often between these two, and, and

00:03:34.680 --> 00:03:36.958
occurs more often between these two,
and so on.

00:03:36.958 --> 00:03:41.614
So we can get between any pair of words
a number that indicates similarity.

00:03:41.614 --> 00:03:45.619
And now, we can just cluster the graph.

00:03:45.619 --> 00:03:48.845
And use any kind of clustering
algorithm and we get for

00:03:48.845 --> 00:03:53.790
the words that tend to be linked together,
helpful and nice, and fair and class,

00:03:53.790 --> 00:03:57.302
will get that these are linked together,
and brutal, and

00:03:57.302 --> 00:04:00.266
corrupt, and
irrational are linked together.

00:04:00.266 --> 00:04:05.910
And we can get our
output polarity lexicon.

00:04:05.910 --> 00:04:08.720
And here I've shown you
an output polarity lexicon.

00:04:08.720 --> 00:04:11.878
And of course it will have
some mistakes in it, so

00:04:11.878 --> 00:04:15.046
see if you can find
the mistakes in this lexicon.

00:04:15.046 --> 00:04:16.950
Here are some of the mistakes.

00:04:16.950 --> 00:04:20.357
So we have disturbing as a positive word,
or

00:04:20.357 --> 00:04:25.065
strange as a positive word, or
pleasant as a negative word.

00:04:25.065 --> 00:04:30.959
So of course there's going to be errors
in any of these kind of automatic,

00:04:30.959 --> 00:04:33.722
semi-supervised algorithms.

00:04:33.722 --> 00:04:39.363
So while the and McEwan algorithm
automatically finds the sentiment or

00:04:39.363 --> 00:04:44.331
the polarity of individual words,
it doesn't do well with phrases,

00:04:44.331 --> 00:04:48.056
and we'd like Often to get
phrases as well as words.

00:04:48.056 --> 00:04:52.174
So the Turney algorithm is
another way to bootstrap in

00:04:52.174 --> 00:04:54.837
a semi-supervised way lexicon.

00:04:54.837 --> 00:04:59.271
And what this does is extract a bunch of
phrases from reviews, learn the polarity

00:04:59.271 --> 00:05:03.050
of the reviews, and then take all
the phrases that occur in a review,

00:05:03.050 --> 00:05:06.526
take their average polarity, and
use that to rate the review.

00:05:06.526 --> 00:05:08.730
So, let's look at these stages
in the Turney Algorithm.

00:05:10.600 --> 00:05:15.114
First, we're going to extract
every two word phrase that

00:05:15.114 --> 00:05:18.440
has a particular set
of part of speech tag.

00:05:18.440 --> 00:05:22.076
And, we haven't talked about
parts of speech yet, but, so,

00:05:22.076 --> 00:05:24.488
this is adject to the tag for adjectives.

00:05:24.488 --> 00:05:28.373
So if the first word is an adjective and
the second word,

00:05:28.373 --> 00:05:31.443
this means noun and
this means plural noun.

00:05:31.443 --> 00:05:36.143
So if the first word is an adjective,
so an adjective followed by a noun or

00:05:36.143 --> 00:05:40.629
a plural noun will extract that phrase,
whatever the third word is.

00:05:41.830 --> 00:05:45.962
Or the first word is an adverb RB
means adverb and the second word is

00:05:45.962 --> 00:05:50.621
an adjective, and the last word is not
a noun we'll extract that phrase so

00:05:50.621 --> 00:05:55.304
adverb adjective, adjective adjective,
noun adjective Adverb verb.

00:05:55.304 --> 00:05:56.625
So these are particular phrases.

00:05:56.625 --> 00:05:58.750
So we're going to run our
part of speech tagger.

00:05:58.750 --> 00:06:00.909
I'll talk about that in a few lectures.

00:06:00.909 --> 00:06:06.110
And assign for each word a part of speech,
adjective, noun, and so on.

00:06:06.110 --> 00:06:09.616
And then we'll extract two word
phrases that meet these criterion.

00:06:09.616 --> 00:06:11.985
The first word is this tag,
the second word is this tag.

00:06:11.985 --> 00:06:14.446
The third word has some constraints so
we don't extract it.

00:06:14.446 --> 00:06:17.175
And now we look at all those phrases.

00:06:17.175 --> 00:06:22.470
And our goal is, for each of those phrases
we've extracted to measure its polarity.

00:06:22.470 --> 00:06:25.373
So how positive or
negative is a particular phrase?

00:06:25.373 --> 00:06:30.319
And the intuition of the Tourney Algorithm
is just like the Hatzivassiloglou and

00:06:30.319 --> 00:06:33.460
McKeown algorithm to
think about co-occurance.

00:06:33.460 --> 00:06:37.593
So we ask, well a phrase is
positive if it co-occurs a lot,

00:06:37.593 --> 00:06:42.440
nearby on the web or some large corpus,
with the word excellent.

00:06:42.440 --> 00:06:46.013
A negative phrase is likely to co-occur
more often with a word like poor.

00:06:46.013 --> 00:06:48.579
So how are we measure this co-occurance?

00:06:48.579 --> 00:06:52.951
The standard way to measure this
kind of co-occurance is with

00:06:52.951 --> 00:06:55.312
pointwise mutual information.

00:06:55.312 --> 00:06:57.274
Pointwise Mutual Information.

00:06:57.274 --> 00:07:01.045
And that's a variant of a standard
information theoretic measure called

00:07:01.045 --> 00:07:02.209
mutual information.

00:07:02.209 --> 00:07:06.582
The mutual information between two
random variables is the sum over

00:07:06.582 --> 00:07:11.568
all the values the two variables can take
of the joint probability of the two,

00:07:11.568 --> 00:07:15.885
times the log of the joined,
over the individual probabilities.

00:07:15.885 --> 00:07:19.392
So, pointwise mutual information
takes this intuition for

00:07:19.392 --> 00:07:24.012
mutual information and just asks a very
simple, computes a very simple ratio.

00:07:24.012 --> 00:07:26.770
The probability of two events, x and y,

00:07:26.770 --> 00:07:30.758
divided by the product of
the individual probabilities.

00:07:30.758 --> 00:07:34.517
So, what Pointwise mutual information
is asking, it's a ratio, is,

00:07:34.517 --> 00:07:38.833
"How much more do events x and y co-occur
than if they were independent?" If they

00:07:38.833 --> 00:07:43.113
were independent they would have these
independent multiplied probabilities.

00:07:43.113 --> 00:07:48.384
And how much does the joint occur more
often than we'd expect from independents?

00:07:48.384 --> 00:07:50.741
That's the intuition of
pointwise mutual information.

00:07:50.741 --> 00:07:54.161
So looking at pointwise
mutual information,

00:07:54.161 --> 00:07:57.149
I've just repeated the equation here.

00:07:57.149 --> 00:08:00.052
We can look at it between two words.

00:08:00.052 --> 00:08:03.952
We say how much more do these
two words word one and word two,

00:08:03.952 --> 00:08:08.008
co-occur than if they were
independent by taking the ratio,

00:08:08.008 --> 00:08:13.390
the probability of the two words occurring
together, divided by the probability

00:08:13.390 --> 00:08:17.770
of each word separately and multiply,
and we take the log of that.

00:08:17.770 --> 00:08:18.885
How do we estimate this?

00:08:18.885 --> 00:08:22.925
Well, the way Turney did it originally
is by using the Altavista search engine.

00:08:22.925 --> 00:08:26.992
And we're going to estimate
the probability of a word just by

00:08:26.992 --> 00:08:29.405
how many hits we see for that word.

00:08:29.405 --> 00:08:34.312
And we're going to estimate
the probability of two words by how often

00:08:34.312 --> 00:08:36.419
word1 occurs near word2.

00:08:36.419 --> 00:08:38.582
So Altavista has the near operator,

00:08:38.582 --> 00:08:41.458
that lets us check if a word
is near another word.

00:08:41.458 --> 00:08:45.649
And in each case we're going to want to
normalize to get a real probability from

00:08:45.649 --> 00:08:46.509
these counts.

00:08:46.509 --> 00:08:51.071
And by our definition from the previous
slide, Pointwise Mutual Information,

00:08:51.071 --> 00:08:53.161
it's the probability of the joint.

00:08:53.161 --> 00:08:58.177
So that's hits of word one
near word two over n squared,

00:08:58.177 --> 00:09:03.511
divided by hits of word one over n and
hits of word two over n,

00:09:03.511 --> 00:09:10.380
and these n's are going to cancel, and
we end up simply with this equation.

00:09:11.590 --> 00:09:14.330
So, how many times do the words
occur near each other,

00:09:14.330 --> 00:09:17.270
and how many times do they occur
individually, and multiply together.

00:09:18.800 --> 00:09:22.490
So once we have a measure
of concurrence of

00:09:22.490 --> 00:09:27.230
how much a phrase concurs with another
word, we can add the term in its polarity.

00:09:27.230 --> 00:09:31.200
So in the equation for
polarity in the algorithm is just,

00:09:31.200 --> 00:09:35.830
how much is the information in any phrase

00:09:35.830 --> 00:09:39.960
like the word excellent we subtract it's
mutual information with phrase poor.

00:09:39.960 --> 00:09:45.892
So how much more does the phrase appear
with excellent than poor or vice versa.

00:09:45.892 --> 00:09:47.750
And just doing a little algebra.

00:09:47.750 --> 00:09:54.397
Here’s the definition of points mutual
information of a phrase with excellent,

00:09:54.397 --> 00:09:58.732
how often it occurs near
the word excellent divided by

00:09:58.732 --> 00:10:04.126
the individual number of hits of
the phrase itself in excellent and

00:10:04.126 --> 00:10:10.577
then subtract the same thing for poor,
and of course by the definition of logs,

00:10:10.577 --> 00:10:15.970
we can bring things inside the log and
turn the minus into a divide,

00:10:15.970 --> 00:10:19.483
and then we can do some
messing with terms.

00:10:19.483 --> 00:10:24.041
So we have hits of phrase here,
and we have hit of phrase there.

00:10:24.041 --> 00:10:30.438
And so, in the end, we can get our formula
for deciding the polarity of a phrase.

00:10:30.438 --> 00:10:34.151
It's just how many times does
the phrase occur near excellent,

00:10:34.151 --> 00:10:38.137
times how many times it occurs with,
the word poor, of course over,

00:10:38.137 --> 00:10:43.580
how many times the phrase occurs near poor
over how many times excellent occurs.

00:10:43.580 --> 00:10:47.329
These are constants that we can get once,
and then for

00:10:47.329 --> 00:10:50.842
each phrase we can compute
these two quantities.

00:10:50.842 --> 00:10:57.484
And using the Tourney Algorithm, here's
a positive review, obviously of a bank.

00:10:57.484 --> 00:11:01.709
And so here's a phrase like online
service, adjective noun phrase.

00:11:01.709 --> 00:11:04.647
And here's the polarity assigned by it,
2.8.

00:11:04.647 --> 00:11:07.805
Here's another one direct deposit, 1.3.

00:11:07.805 --> 00:11:11.434
Here's some negative phrases
with negative polarity, so

00:11:11.434 --> 00:11:16.166
the phrases occur more often near the word
poor than near the word excellent.

00:11:16.166 --> 00:11:19.207
So inconveniently located
has a negative polarity.

00:11:19.207 --> 00:11:22.332
On average though,
just showing you a subset,

00:11:22.332 --> 00:11:27.647
more of the positive phrases occur in this
review than in the negative phrases And

00:11:27.647 --> 00:11:30.010
the average polarity is positive.

00:11:30.010 --> 00:11:33.446
So, this is a thumbs-up review.

00:11:33.446 --> 00:11:38.455
A thumbs-down review, you can see
that phrases like virtual monopoly,

00:11:38.455 --> 00:11:42.353
negative polarity,
lesser evil, negative polarity.

00:11:42.353 --> 00:11:47.176
Other problems, negative polarity
all occur more frequently and

00:11:47.176 --> 00:11:52.083
on average have a more negative
polarity than the positive polarity

00:11:52.083 --> 00:11:54.580
words that occur in this review and

00:11:54.580 --> 00:11:59.076
we end up with a review that has
an average negative polarity.

00:11:59.076 --> 00:12:04.711
So the Turney Algorithm with evaluated
on various kinds of review sites and

00:12:04.711 --> 00:12:08.826
does a better job than just
the majority class baseline

00:12:08.826 --> 00:12:11.696
predicting the polarity of a review.

00:12:11.696 --> 00:12:15.241
So what's important about the Turney
Algorithm is that it lets us look at

00:12:15.241 --> 00:12:17.693
phrases, learn phrases
rather than just words.

00:12:17.693 --> 00:12:22.097
And what's true about in general about
these unsupervised algorithms is we can

00:12:22.097 --> 00:12:26.710
learn domain-specific information that
might not be in some online dictionary.

00:12:26.710 --> 00:12:29.430
So if I go back to the previous slide,

00:12:29.430 --> 00:12:35.490
if we're doing banking a word
like direct deposit or

00:12:35.490 --> 00:12:41.490
virtual monopoly simply might not be in an
online polarity dictionary or online web.

00:12:42.550 --> 00:12:45.670
So we need to use some of these
semi supervised algorithms for

00:12:45.670 --> 00:12:50.850
learning The polarity
of these kind of words.

00:12:50.850 --> 00:12:54.977
Finally, I'll mention briefly a third
algorithm for learning polarity and

00:12:54.977 --> 00:12:56.064
this uses WordNet.

00:12:56.064 --> 00:12:58.967
Again that's the online thesaurus that
we'll talk about in detail later.

00:12:58.967 --> 00:13:03.821
And the intuition of using these
online thesaurus' is similar to

00:13:03.821 --> 00:13:08.425
what we've seen in the first
two semi supervised algorithm.

00:13:08.425 --> 00:13:11.890
We’ll start with a positive seed set and
a negative seed set, so when I

00:13:11.890 --> 00:13:16.027
have words like good in the positive seed
set and terrible in the negative seed set.

00:13:16.027 --> 00:13:20.556
And now we use the thesaurus just very
simply to find synonyms and antonyms.

00:13:20.556 --> 00:13:23.599
So we add synonyms of
positive words like well and

00:13:23.599 --> 00:13:26.653
antonyms of negative words
to the positive set.

00:13:26.653 --> 00:13:30.176
And to the negative set, which we
started out with words like terrible,

00:13:30.176 --> 00:13:32.214
now we add synonyms of all of those words.

00:13:32.214 --> 00:13:34.546
So maybe awful is a synonym of terrible,
and

00:13:34.546 --> 00:13:38.274
antonyms of our positive words to
the negative set and we just repeat.

00:13:38.274 --> 00:13:41.838
And the sets grow as we keep adding
synonyms and antonyms to it.

00:13:41.838 --> 00:13:45.087
And then each of the algorithms
that make use of WordNet for

00:13:45.087 --> 00:13:49.133
learning clarity will have various
ways of filtering out bad examples or

00:13:49.133 --> 00:13:52.069
problems with word sentences and
things like that.

00:13:52.069 --> 00:13:59.476
So in summary, learning lexicons can help
us deal with domain specific issues.

00:13:59.476 --> 00:14:02.285
In banking,
we might have a word like direct deposit.

00:14:02.285 --> 00:14:06.221
That's just not going to be
a standard online polarity lexicon.

00:14:06.221 --> 00:14:09.121
And we can be more robust in
general as new names are, people

00:14:09.121 --> 00:14:13.440
start using new names or new company name
that might not be in some training data.

00:14:13.440 --> 00:14:17.622
But we might be able to learn it from the
way I prefer, the data we are looking at.

00:14:17.622 --> 00:14:20.733
And again, intuition of all these
algorithms is really the same.

00:14:20.733 --> 00:14:25.169
We start with some seed set, we find other
words that have similar polarity to that

00:14:25.169 --> 00:14:27.306
seed set in some semi-automatic way.

00:14:27.306 --> 00:14:32.536
And the ways you've seen are using what
other words are conjoined with and

00:14:32.536 --> 00:14:37.952
or but, using words that just occur
nearby to words like poor or excellent.

00:14:37.952 --> 00:14:43.480
That's our received set there, or
using WordNet synonyms or antonyms.

