WEBVTT
Kind: captions
Language: en

00:00:00.600 --> 00:00:05.172
In this section, I'm going to look at how
you can get features from text that you

00:00:05.172 --> 00:00:09.962
can use inside discriminative models for
various kinds of classification tasks.

00:00:12.630 --> 00:00:17.670
So in these slides and in most maxent
work, by feature what we're meaning

00:00:17.670 --> 00:00:22.549
is an elementary piece of evidence
that links between what we observe,

00:00:22.549 --> 00:00:26.964
which is the data piece d and
a category c that we want to present.

00:00:26.964 --> 00:00:33.650
So a feature is a function
with a bounded real value.

00:00:33.650 --> 00:00:38.748
So what we can do is write
that we have a feature,

00:00:38.748 --> 00:00:43.972
f, which is mapping from
the space of classes and

00:00:43.972 --> 00:00:47.680
pieces of data onto a real number.

00:00:51.611 --> 00:00:56.550
So here then are a couple of examples
of the kind of features that we have.

00:00:57.910 --> 00:01:02.920
So let's look at these features, with
respect to some particular pieces of data.

00:01:04.040 --> 00:01:07.310
Okay, so the first feature,
the purple feature,

00:01:07.310 --> 00:01:10.360
is saying that the class' location.

00:01:10.360 --> 00:01:16.230
So in these example pieces of data,
I'm assuming that I'm looking at the last

00:01:16.230 --> 00:01:21.290
word in the sequence, and then the class
above it is being shown in orange.

00:01:21.290 --> 00:01:24.780
So the feature picks out examples
where the class is location,

00:01:24.780 --> 00:01:27.775
so that's the two pieces
of data on the left.

00:01:27.775 --> 00:01:34.609
And the previous word is in,
and the word is capitalized.

00:01:34.609 --> 00:01:39.632
So all three of those criteria are true
of these two pieces of data, but

00:01:39.632 --> 00:01:45.694
aren't true of the two pieces of data on
the right, really, for multiple reasons.

00:01:45.694 --> 00:01:51.480
Both because the class is wrong, and
the preceding word is also wrong.

00:01:53.320 --> 00:01:57.780
Okay, so then if we go on and
look at the second feature.

00:01:57.780 --> 00:02:03.290
It's again saying the class' location,
and for the rest of the feature,

00:02:03.290 --> 00:02:06.970
we can put in just anything that
seems like it'll be useful.

00:02:06.970 --> 00:02:11.500
So we might think it's a useful feature
to know whether a word has in it,

00:02:11.500 --> 00:02:13.660
something like accent and
Latin characters, so

00:02:13.660 --> 00:02:19.100
it's not just plain a to z, but
has some other characters in there.

00:02:19.100 --> 00:02:23.340
So here we've sort of noticed that
some names has things like accented

00:02:23.340 --> 00:02:24.470
letters in them.

00:02:24.470 --> 00:02:29.560
So this feature then will be
true of this piece of data, and

00:02:29.560 --> 00:02:32.000
again it's not true of any
of the other pieces of data.

00:02:34.610 --> 00:02:37.453
Okay, so then let's look at feature three.

00:02:37.453 --> 00:02:44.647
So feature three says,
the class is DRUG and the word ends in c.

00:02:44.647 --> 00:02:51.250
So, that's a feature that's true of this
piece of data, but not any of the others.

00:02:51.250 --> 00:02:55.430
So in general, that that's what's
happening, we're imagining for

00:02:55.430 --> 00:03:00.604
our training we will have data which
already gives us the right answers.

00:03:00.604 --> 00:03:04.760
There will be some words, and
that they will have a class.

00:03:04.760 --> 00:03:09.779
And so in this example, we then also
assuming that we have a particular

00:03:09.779 --> 00:03:14.559
position that we're looking at,
so that this is the basic word w.

00:03:14.559 --> 00:03:19.298
And then when we want to we can refer
to something like word- 1 here,

00:03:19.298 --> 00:03:22.262
to ask features about other nearby words.

00:03:22.262 --> 00:03:28.920
And so then our feature will then
ask some question about the class.

00:03:28.920 --> 00:03:29.959
Is it a drug?

00:03:29.959 --> 00:03:32.402
And some question about the words,

00:03:32.402 --> 00:03:37.760
where normally it won't sort of just
ask for the complete sequence of words.

00:03:37.760 --> 00:03:39.680
But might ask for features of them,

00:03:39.680 --> 00:03:43.680
like an individual word,
or something in-between.

00:03:43.680 --> 00:03:45.385
Like in this example we gave,

00:03:45.385 --> 00:03:49.217
where we're just looking at whether
the word ends in the letter c.

00:03:49.217 --> 00:03:54.615
At that point, the next thing
is that the model will assign

00:03:54.615 --> 00:04:00.233
to each feature a weight,
where the weight is a real number,

00:04:00.233 --> 00:04:04.878
so it might be something like 0.3 or- 0.2.

00:04:04.878 --> 00:04:09.450
So this isn't the value of the feature,
this is the weight of the feature.

00:04:09.450 --> 00:04:16.620
And so a positive weight votes that
this configuration is likely correct.

00:04:16.620 --> 00:04:19.650
It's the kind of thing
that happens in real text.

00:04:19.650 --> 00:04:25.480
So that's something like for
feature 1, well if the preceding word

00:04:25.480 --> 00:04:30.590
is in, and the word is capitalized,

00:04:30.590 --> 00:04:33.554
well that's indeed a good indicator
that the word is a location.

00:04:34.763 --> 00:04:38.625
So if a feature one that matches
these two pieces of data,

00:04:38.625 --> 00:04:41.185
we'd expect it to have a positive weight.

00:04:45.202 --> 00:04:49.365
Then the other choice is you
can have a negative weight.

00:04:49.365 --> 00:04:53.780
So the negative weight votes that
a configuration is likely incorrect.

00:04:53.780 --> 00:04:57.598
So we could have another feature, for

00:04:57.598 --> 00:05:02.489
example, which was kind of like feature 1,
but

00:05:02.489 --> 00:05:07.857
might be feature 14,
which said the class = DRUG,

00:05:07.857 --> 00:05:13.070
and the rest of
the condition was the same.

00:05:13.070 --> 00:05:17.190
And so that feature would match

00:05:17.190 --> 00:05:20.970
a different classification
where we had in Arcadia.

00:05:20.970 --> 00:05:24.590
And we were saying Arcadia was a drug.

00:05:25.700 --> 00:05:30.380
And feature 14 would
match that configuration.

00:05:30.380 --> 00:05:35.600
But what we'd like to say,
is that that's unlikely to be correct, and

00:05:35.600 --> 00:05:40.739
we could express that by giving
a negative weight like- 0.6 to it.

00:05:42.984 --> 00:05:45.890
Later on when we're working with features,

00:05:45.890 --> 00:05:48.954
we can crucially make
use of two expectations.

00:05:48.954 --> 00:05:54.690
So an expectation is an actual or
predicted count of a feature firing.

00:05:54.690 --> 00:05:59.730
And we have two expectations,
one is from our supervised data, we can

00:05:59.730 --> 00:06:06.320
just actually look how often a particular
feature is satisfied by pieces of data.

00:06:06.320 --> 00:06:09.160
And so we'll refer to that
as the empirical count or

00:06:09.160 --> 00:06:11.790
the empirical expectation of the feature.

00:06:11.790 --> 00:06:12.680
So that's this guy.

00:06:12.680 --> 00:06:17.880
We simply just look through every piece
of data that we're trading off and

00:06:17.880 --> 00:06:22.290
we ask,
is the feature true of that piece of data?

00:06:22.290 --> 00:06:24.080
And we count the number
of times it's true,

00:06:24.080 --> 00:06:26.320
and that's our empirical expectation.

00:06:28.680 --> 00:06:32.115
The other expectation is the model
expectation of the feature.

00:06:32.115 --> 00:06:37.310
We'll look at this more in a minute, but
what we're going to have is a probability

00:06:37.310 --> 00:06:42.280
distribution over pairs
of a class on a data set.

00:06:42.280 --> 00:06:46.029
And so what we're going to do
is using that distribution,

00:06:46.029 --> 00:06:50.279
then we're going to consider all
the classes and pieces of data.

00:06:50.279 --> 00:06:54.127
And then say, well given that,
what is the expected value of

00:06:54.127 --> 00:06:58.202
f based on the probabilities of
different configurations, and

00:06:58.202 --> 00:07:01.310
what the value of f is for
those configurations.

00:07:05.558 --> 00:07:10.214
In the particular case of natural
language processing applications,

00:07:10.214 --> 00:07:14.920
what we find is that usually a feature
is of a very particular form.

00:07:14.920 --> 00:07:19.850
So the feature consists of
firstly an indicator function,

00:07:19.850 --> 00:07:23.950
a yes/no boolean matching function
of properties of the input.

00:07:23.950 --> 00:07:28.050
And secondly,
it specifies a particular class.

00:07:28.050 --> 00:07:35.338
So the arbitrary feature is just
a feature of a class data pair,

00:07:35.338 --> 00:07:39.889
and it's returning some real number.

00:07:39.889 --> 00:07:45.230
But in practice the features that we
define, have this very particular form.

00:07:45.230 --> 00:07:48.470
So we have a matching
predicate against the data, so

00:07:48.470 --> 00:07:52.840
that's something like ends in the letter
c and there's a capitalized word.

00:07:52.840 --> 00:07:59.620
And that's conjoined together with saying,
that particular class is matched.

00:07:59.620 --> 00:08:04.790
And the return value of the feature
can in general, be a real number.

00:08:04.790 --> 00:08:10.101
But our features here,
logical boolean predicates,

00:08:10.101 --> 00:08:14.380
and so
their return value is either 0 or 1.

00:08:14.380 --> 00:08:19.335
Now every feature that we're going
to present in this class is of

00:08:19.335 --> 00:08:23.831
exactly this form, and
that's true of 99% of how these

00:08:23.831 --> 00:08:29.160
features have been used in
natural language processing work.

00:08:29.160 --> 00:08:36.727
And so we can equally say that phi(d)
is a feature of the data d when for

00:08:36.727 --> 00:08:41.859
each class, cj, the conjunction phi(d) and

00:08:41.859 --> 00:08:46.230
c = cj is a feature of a class data pair.

00:08:46.230 --> 00:08:49.160
That's our fi feature pair.

00:08:49.160 --> 00:08:51.237
So a lot of the time what we'll find,

00:08:51.237 --> 00:08:54.660
is that we'll think in term
of these phi(d) features.

00:08:54.660 --> 00:08:58.469
But you should remember,
that the actual math and

00:08:58.469 --> 00:09:03.907
programming we write is going to be
working in terms of these fi features,

00:09:03.907 --> 00:09:09.527
where this i index is being particular
to both matching a data predicate,

00:09:09.527 --> 00:09:11.722
and some particular class.

00:09:16.823 --> 00:09:20.398
Nevertheless, a good way
to think about things,

00:09:20.398 --> 00:09:26.200
is that each features identifies a subset
of the data and suggests a label for it.

00:09:26.200 --> 00:09:28.600
And that's what we saw
in the examples before.

00:09:30.182 --> 00:09:34.550
In feature-based models, the decision
about a data point is based entirely on

00:09:34.550 --> 00:09:36.972
the features that
are active at that point.

00:09:36.972 --> 00:09:40.854
So let's look at a couple of examples,
Ven OP applications and

00:09:40.854 --> 00:09:43.794
the kind of features that get defined for
them.

00:09:43.794 --> 00:09:46.982
One of the simplest cases
is text categorization.

00:09:46.982 --> 00:09:52.902
So we have an article which has data like,
stocks hit a yearly low,

00:09:52.902 --> 00:09:58.520
and it's assigned some topical class here,
business.

00:09:58.520 --> 00:10:03.100
And so typically in these kind of
text categorization applications,

00:10:03.100 --> 00:10:07.160
the features are just the words
that occur in the articles.

00:10:07.160 --> 00:10:12.300
So each word type that occurs
in the article will be a feature

00:10:12.300 --> 00:10:18.020
of a phi feature and so
then a complete f feature will be

00:10:18.020 --> 00:10:22.550
the word stocks occurred,
and the class is business.

00:10:22.550 --> 00:10:25.937
Or the word stocks occurred,
and the class is sports.

00:10:28.363 --> 00:10:33.153
Word-sense disambiguation is the task of
determining the sense of the words in

00:10:33.153 --> 00:10:33.804
context.

00:10:33.804 --> 00:10:38.610
So for example, whether usage of the word
bank is referring to the bank of a river

00:10:38.610 --> 00:10:40.715
or to the financial institution.

00:10:40.715 --> 00:10:44.324
In making a classifier that
decides senses of words,

00:10:44.324 --> 00:10:48.976
in practice it comes out kind of
like a text categorization example,

00:10:48.976 --> 00:10:55.160
where we regard the context of the word as
this little mini document around the word.

00:10:55.160 --> 00:11:00.400
So here we have the observed data,
the sequence of words

00:11:00.400 --> 00:11:04.890
is the word we want to disambiguate, and
here it has the particular class and

00:11:04.890 --> 00:11:08.850
the training data,
this is an instance of the money one.

00:11:08.850 --> 00:11:12.842
So we could just use the same
kind of features as here,

00:11:12.842 --> 00:11:17.836
a bag of words, set of features of
the words around in the context.

00:11:17.836 --> 00:11:22.518
But we can also use more particular
features that look at particular things

00:11:22.518 --> 00:11:23.690
in the context.

00:11:23.690 --> 00:11:28.191
So we could have a feature that says,
the word before is restructure,

00:11:28.191 --> 00:11:30.113
the word afterwards is debt.

00:11:30.113 --> 00:11:33.502
And we could have other kinds
of features if we wanted to too,

00:11:33.502 --> 00:11:37.169
like we can have a feature that
the length of the sentence is 12.

00:11:37.169 --> 00:11:41.792
You should really think that you can make
features in any way you want that'll be

00:11:41.792 --> 00:11:44.440
good in predicting what the class is.

00:11:44.440 --> 00:11:49.590
And commonly in practice what you'll find
is word sense disambiguation systems,

00:11:49.590 --> 00:11:54.290
have both bag of words features like this,
and they have

00:11:54.290 --> 00:11:58.870
features that ask about particular words
that are adjacent on the left and right.

00:11:58.870 --> 00:12:01.670
And it's been shown that actually
on both of those types is useful.

00:12:03.840 --> 00:12:07.630
Here's one more example that's slightly
different, which is when we're working out

00:12:07.630 --> 00:12:12.280
the part of speech of a word in context,
whether it's a noun or a verb.

00:12:12.280 --> 00:12:15.970
And so here's fall which can
be a verb to fall down, or

00:12:15.970 --> 00:12:21.010
a noun, and in this particular
case its actual class is noun.

00:12:21.010 --> 00:12:23.105
So if we're wanting to do
part of speech taking,

00:12:23.105 --> 00:12:28.375
we're likely to want to know particular
things about a very narrow context,

00:12:28.375 --> 00:12:31.220
and things in particular positions.

00:12:31.220 --> 00:12:33.770
So we'd want to know what
word it is that we're taking,

00:12:33.770 --> 00:12:37.520
the current word is fall,
it's likely to be a good indicator,

00:12:37.520 --> 00:12:41.340
whether it's a verb or
a noun what the previous word is.

00:12:41.340 --> 00:12:46.320
And this example points in the direction
of when we want to do a sequence

00:12:46.320 --> 00:12:50.110
of classifying decisions, where we
actually want to classify each word.

00:12:50.110 --> 00:12:54.390
And that's a topic that we'll return
to later when we show how to build

00:12:54.390 --> 00:12:55.820
sequence models.

00:12:55.820 --> 00:12:58.680
But the easiest way to think about
it is that we're just going to give

00:12:58.680 --> 00:13:01.040
each word a part of speech in turn.

00:13:01.040 --> 00:13:05.300
So once we're deciding, this word's
part of speech, we can assume that we've

00:13:05.300 --> 00:13:09.110
already given parts of speech
to the words that proceed it.

00:13:09.110 --> 00:13:13.660
So we can also use as a feature for
deciding this word's part of speech,

00:13:13.660 --> 00:13:16.070
what the part of speech
of the previous word was.

00:13:16.070 --> 00:13:20.262
And so this is the feature here that's
saying the previous tag is adjective.

00:13:20.262 --> 00:13:26.410
So looking at a couple of
examples in more detail,

00:13:26.410 --> 00:13:31.060
let's just go through a couple of bits
of work on feature based classifiers.

00:13:31.060 --> 00:13:36.330
So Zhang and Oles was one well known piece
of work for doing text categorization.

00:13:36.330 --> 00:13:41.500
And so the features that they used
are precisely bag of words features.

00:13:41.500 --> 00:13:45.420
So the features are precisely presence
of a word in the document, and

00:13:45.420 --> 00:13:47.300
the document class.

00:13:47.300 --> 00:13:51.810
They actually don't use every
word that occurs in the document.

00:13:51.810 --> 00:13:56.420
And so a common refinement is to do
a process of feature selection, where you

00:13:56.420 --> 00:14:01.330
pick out a particular subset of words that
are deemed to be reliable indicators.

00:14:01.330 --> 00:14:03.745
You might be dropping very rare words or

00:14:03.745 --> 00:14:08.225
also dropping extremely common words that
are viewed to be semantically empty.

00:14:09.615 --> 00:14:14.905
The test set that they use is a well
known text categorization dataset,

00:14:14.905 --> 00:14:17.640
the Reuters newswire dataset.

00:14:17.640 --> 00:14:21.250
And here just some indicative
results of what they find.

00:14:21.250 --> 00:14:28.250
So they build a Naive Bayes model, which
gets 77% F1 across the different classes.

00:14:28.250 --> 00:14:31.490
And then they compare several
discriminative classifiers.

00:14:32.630 --> 00:14:34.340
They build a linear regression model.

00:14:34.340 --> 00:14:39.920
Now despite the fact that linear
regression models shouldn't be right for

00:14:39.920 --> 00:14:44.310
doing these kind of categorical
text prediction tasks because of

00:14:44.310 --> 00:14:49.210
various reasons, such as the numbers going
out of bounds and not being probabilities.

00:14:49.210 --> 00:14:53.450
Actually what you can
see is that the linear

00:14:53.450 --> 00:14:58.640
regression works already much
better than the Naive Bayes model.

00:14:58.640 --> 00:15:05.240
In fact, what they find is it works almost
as well as the logistic regression model.

00:15:05.240 --> 00:15:06.580
The logistic regression model,

00:15:06.580 --> 00:15:09.020
the fraction beta, but
actually, not very much.

00:15:11.830 --> 00:15:15.990
They also train a support vector machine
model, which is another very common and

00:15:15.990 --> 00:15:20.350
popular discriminative classifier,
used widely for text base models,

00:15:20.350 --> 00:15:22.170
like text categorization.

00:15:22.170 --> 00:15:25.432
It's performance is almost
indistinguishably different from

00:15:25.432 --> 00:15:27.950
the logistic regression model.

00:15:27.950 --> 00:15:34.800
And, so that's something interesting
that comes out in a lot of recent work.

00:15:34.800 --> 00:15:39.811
So you can see that the big difference
here is between the Naive Bayes model and

00:15:39.811 --> 00:15:42.180
all of the discriminant models.

00:15:42.180 --> 00:15:45.000
All the discriminant
models do much better, and

00:15:45.000 --> 00:15:50.490
in turn the differences between
the discriminative models are very small.

00:15:50.490 --> 00:15:54.270
And so a lot of the time,
yes you want to use an appropriate model,

00:15:54.270 --> 00:15:57.812
but it doesn't actually matter
very much which model you choose.

00:15:57.812 --> 00:16:01.720
What's going to matter much more is the
quality of the features that you define.

00:16:04.550 --> 00:16:08.770
Another thing that the paper emphasises
that we'll come back to, is the importance

00:16:08.770 --> 00:16:13.580
of regularization or smoothing for
successful use of discriminative models.

00:16:13.580 --> 00:16:17.699
That was something that wasn't used
in much of the very early NLP and

00:16:17.699 --> 00:16:21.973
IR work on discriminative models
that turns out to be very important.

00:16:24.980 --> 00:16:28.076
There are many places where you
can use a maxent classifier.

00:16:28.076 --> 00:16:32.838
It's whenever you have some data points
that you want to assign to one of a number

00:16:32.838 --> 00:16:33.940
of classes.

00:16:33.940 --> 00:16:36.638
So let's just look through
a few more examples.

00:16:36.638 --> 00:16:39.490
So here's a fairly straightforward one.

00:16:39.490 --> 00:16:44.474
Which is where, what you want to do is
decide whether a period is the end of

00:16:44.474 --> 00:16:50.395
sentence or an abbreviation, so you might
have something like i.e., you choose.

00:16:52.624 --> 00:16:54.401
And we have this period here, and

00:16:54.401 --> 00:16:58.420
what we'd like to say is that this
period isn't the end of sentence.

00:16:58.420 --> 00:17:00.980
And we can kind of think that there
are some ways that we could tell that

00:17:00.980 --> 00:17:03.950
by seeing this abbreviation beforehand.

00:17:03.950 --> 00:17:06.730
And so we'll be wanting to make features,

00:17:06.730 --> 00:17:10.730
then look at the stuff to the left
of the period, and perhaps also

00:17:10.730 --> 00:17:14.955
things to the right of the period such as,
this word isn't capitalized.

00:17:14.955 --> 00:17:18.154
We've already talked a bit
about sentiment analysis,

00:17:18.154 --> 00:17:22.578
as to whether someone is giving a positive
or negative review, and we can make

00:17:22.578 --> 00:17:26.952
a discriminative classifier for
that by putting in features for the words.

00:17:26.952 --> 00:17:30.096
And perhaps not the kinds of
features like word pair features,

00:17:30.096 --> 00:17:32.540
different parts of speech and
things like that.

00:17:34.470 --> 00:17:37.370
Prepositional phrase attachment is
the tasks of working out whether

00:17:37.370 --> 00:17:43.720
a prepositional phrase, like with a beard
is modifying the particular noun or verb.

00:17:43.720 --> 00:17:46.830
And that's getting us into
the realm of syntactic decisions.

00:17:46.830 --> 00:17:51.350
Or more in general one way,
in general to make parsing decisions for

00:17:51.350 --> 00:17:54.990
the structure of the sentence,
is to build classifiers for

00:17:54.990 --> 00:17:57.860
the particular decisions that
are involved in making the classifier.

00:18:01.460 --> 00:18:05.130
Okay, I hope that's given you a good sense
of what the features are that are used in

00:18:05.130 --> 00:18:07.810
modern discriminative NLP systems, and

00:18:07.810 --> 00:18:10.950
some idea of the kind of applications
to which they've been applied.

