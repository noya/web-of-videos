WEBVTT
Kind: captions
Language: en

00:00:00.730 --> 00:00:06.640
Let's walk through a detailed worked
example in Multinomial Naive Bayes.

00:00:07.700 --> 00:00:11.970
So, for this example,
when I put up here the equations for

00:00:11.970 --> 00:00:17.240
Naive Bayes, so the probability
of a class is the number of

00:00:17.240 --> 00:00:20.790
documents with that class over
the total number of documents.

00:00:20.790 --> 00:00:23.140
And the likelihood of
a word given a class,

00:00:23.140 --> 00:00:27.600
let's just do simple add 1 smoothing, the
count of the word occurring in that class

00:00:27.600 --> 00:00:32.930
divided by the count of all words in
that class, and with add 1 smoothing.

00:00:32.930 --> 00:00:37.282
And let's assume that we have four
training documents, 1, 2, 3, 4,

00:00:37.282 --> 00:00:38.646
and one test document.

00:00:38.646 --> 00:00:42.520
And here are the documents,
they're simplified, obviously, documents.

00:00:42.520 --> 00:00:45.781
This document has only three words,
Chinese Beijing Chinese.

00:00:45.781 --> 00:00:50.450
And this document has three words,
Chinese Chinese Shanghai, and so on.

00:00:50.450 --> 00:00:53.650
And let's say we just have two classes,
Chinese and Japanese.

00:00:53.650 --> 00:00:58.369
Our job is to do Asian
news topic classification.

00:01:00.970 --> 00:01:05.168
So three of our training documents
are in the class China, and

00:01:05.168 --> 00:01:07.500
one of them is in the class Japan.

00:01:07.500 --> 00:01:12.180
And our question is what's
the class of this test document?

00:01:14.870 --> 00:01:16.760
All right, so let's do some computation.

00:01:16.760 --> 00:01:18.700
First thing we're going to
do is compute the priors.

00:01:19.890 --> 00:01:26.776
So we need to compute P(c), called the
class China, and P(j) in the class Japan.

00:01:26.776 --> 00:01:31.685
So P(c) is how many times does the class
Chinese occur in our training set,

00:01:31.685 --> 00:01:34.750
3, out of how

00:01:34.750 --> 00:01:38.030
many total classes are there in our trade
documents are there in our training set?

00:01:38.030 --> 00:01:38.700
4.

00:01:38.700 --> 00:01:44.315
So 3 of the 4 training documents,
so that's 3/4 are about China.

00:01:44.315 --> 00:01:51.055
So our prior probability of a document
being in the topic China is 3/4.

00:01:52.980 --> 00:01:53.830
How about Japan?

00:01:56.380 --> 00:01:59.570
Well, there's only 1 document
in our training set about Japan

00:02:01.580 --> 00:02:02.830
out of the 4 documents.

00:02:02.830 --> 00:02:04.995
So the probability of Japan is 1/4.

00:02:06.350 --> 00:02:09.160
So we've seen how to compute
our prior probabilities here.

00:02:10.535 --> 00:02:11.870
Let's move on to the likelihoods.

00:02:13.180 --> 00:02:15.460
Let's compute each of these probabilities.

00:02:15.460 --> 00:02:20.086
What's the probability of the word
Chinese given the class c?

00:02:20.086 --> 00:02:23.160
What's the probability of the word
Chinese given the class j, and so on.

00:02:25.792 --> 00:02:29.560
All right, so,
the probability of Chinese is,

00:02:30.660 --> 00:02:36.100
how many times does the word Chinese
occur in our training set of

00:02:36.100 --> 00:02:39.360
documents that are in the class China,
okay?

00:02:39.360 --> 00:02:44.470
So this word Chinese, how many times
does it occur in these three documents?

00:02:44.470 --> 00:02:48.030
1, 2, 3, 4, 5.

00:02:48.030 --> 00:02:49.400
So we have 5.

00:02:49.400 --> 00:02:52.220
We have add one smoothing,
so we're adding 1.

00:02:52.220 --> 00:02:56.540
And how many total words
are there in our training set?

00:02:56.540 --> 00:03:03.710
1, 2, 3, 4, 5, 6, 7,
8 that are in our Chinese class.

00:03:03.710 --> 00:03:06.480
And then we're going to add the vocabulary
size V, again, we're doing add one

00:03:06.480 --> 00:03:12.680
smoothing, so add the vocabulary size V,
and our vocabulary is 6.

00:03:12.680 --> 00:03:16.879
1, 2, 3, 4, 5, 6.

00:03:16.879 --> 00:03:23.250
So that's (5+1)/(8+6) = 6/14 = 3/7.

00:03:23.250 --> 00:03:26.270
And we'll do the same thing for
the word Tokyo.

00:03:29.550 --> 00:03:35.922
Tokyo doesn't occur at all in our
three classes, it has a count of 0.

00:03:35.922 --> 00:03:38.260
But we're doing add one smoothing,
so we'll add 1, and

00:03:38.260 --> 00:03:40.130
that's the same denominator.

00:03:40.130 --> 00:03:43.970
The same number of total words and
vocabulary size in our Chinese class, so

00:03:43.970 --> 00:03:46.556
that will be 1/14.

00:03:46.556 --> 00:03:49.890
And the same exact thing is true for
the word Japan,

00:03:49.890 --> 00:03:51.129
doesn't occur in our training set.

00:03:53.320 --> 00:03:56.470
Now let's turn to the class j for Japan.

00:03:57.540 --> 00:04:02.608
So now the word Chinese does occur once.

00:04:06.695 --> 00:04:10.670
And then we'll do, so it's once,
plus 1 for add one smoothing.

00:04:10.670 --> 00:04:14.550
And we'll divide by the count
of the words in this class, and

00:04:14.550 --> 00:04:19.030
there's three words in this
meta document of one document.

00:04:19.030 --> 00:04:20.890
And then, again,
we add the vocabulary size.

00:04:22.700 --> 00:04:24.137
And so, we've got 2/9.

00:04:25.839 --> 00:04:30.510
And we can compute the next
two numbers the same way.

00:04:30.510 --> 00:04:35.010
So now we have our priors, and
we have our conditional probabilities.

00:04:35.010 --> 00:04:40.130
We're ready to decide which class is
more likely for our test document.

00:04:40.130 --> 00:04:44.340
So for our test document,
we'll call that document 5,

00:04:44.340 --> 00:04:51.300
we need to compute our prior and
our likelihoods.

00:04:51.300 --> 00:04:55.830
So our prior is 3/4,
the prior of being Chinese for

00:04:55.830 --> 00:05:00.360
document 5 is 3/4,
that's the prior for Chinese, times,

00:05:00.360 --> 00:05:04.250
the word Chinese occurs 3 times, 1, 2, 3.

00:05:04.250 --> 00:05:07.745
And each one of those gets
the probability of Chinese given 3.

00:05:07.745 --> 00:05:11.423
So that's 3/7, 3/7, 3/7.

00:05:12.920 --> 00:05:14.680
Then the word Tokyo occurs.

00:05:14.680 --> 00:05:17.020
That's got probability 1/14.

00:05:17.020 --> 00:05:21.496
Then the word Japan, 1/14, and
we multiply all that together,

00:05:21.496 --> 00:05:24.000
we get approximately 0.0003.

00:05:24.000 --> 00:05:30.480
Notice that we say that this probability
is proportional to this product

00:05:30.480 --> 00:05:37.680
because we are computing the arc
max between these two classes.

00:05:37.680 --> 00:05:42.870
We're computing the class which maximizes
the product of the two probabilities.

00:05:42.870 --> 00:05:45.700
But the actual probability
has a denominator in it.

00:05:45.700 --> 00:05:50.240
It would have to be divided
by P of a document.

00:05:50.240 --> 00:05:52.430
And we're just skipping that part.

00:05:52.430 --> 00:05:54.984
And so, we're actually not
computing the probability,

00:05:54.984 --> 00:05:57.520
we're computing the numerator
of the probability.

00:05:57.520 --> 00:06:02.624
But since document 5 has the same P
of document 5 in both the Chinese and

00:06:02.624 --> 00:06:06.724
Japanese classes,
weÂ´re just going to not compute that.

00:06:06.724 --> 00:06:09.879
So we have a proportional to and
not an equal sign here.

00:06:11.130 --> 00:06:15.315
Good, and then, for the probability of
document of class Japanese given document

00:06:15.315 --> 00:06:20.720
5, now we have the prior for
document Japanese.

00:06:20.720 --> 00:06:26.610
And we multiply that by the probability
of Chinese, given the class Japanese.

00:06:26.610 --> 00:06:32.130
So that's 2/9 times 2/9 times 2/9.

00:06:32.130 --> 00:06:37.250
And then the probability of Tokyo,
given Japanese, that's another 2/9.

00:06:37.250 --> 00:06:39.645
And then Japan,
given Japanese, another 2/9.

00:06:40.790 --> 00:06:43.910
And so,
we get a slightly lower probability.

00:06:46.860 --> 00:06:55.600
So, in this example, our model would
choose which class for this document?

00:07:00.358 --> 00:07:07.824
It would choose Chinese,
because 0.0003 is bigger than 0.0001.

00:07:11.855 --> 00:07:16.116
Now we've talked about Naive Bayes, where
we're using each word as a feature and

00:07:16.116 --> 00:07:17.920
we're using all of the words.

00:07:17.920 --> 00:07:21.360
But in lots of examples of Naive Bayes,
we're going to use richer features than

00:07:21.360 --> 00:07:25.452
just words, and we're going to use
specific kinds of words and other things.

00:07:25.452 --> 00:07:30.370
So SpamAssassin is a Naive Bayes
classifier for spam detection, and

00:07:30.370 --> 00:07:34.190
it looks for things like is
the phrase Generic Viagra mentioned?

00:07:34.190 --> 00:07:36.192
Is the phrase Online Pharmacy mentioned?

00:07:36.192 --> 00:07:40.782
Are there regular expression for
millions of dollars mentioned?

00:07:40.782 --> 00:07:44.700
Is there a phrase impress and
nearby the word girl?

00:07:44.700 --> 00:07:46.740
Does the from have a lot of numbers in it?

00:07:46.740 --> 00:07:48.040
Is the subject in all caps?

00:07:48.040 --> 00:07:51.630
So all sorts of different features
that we can use to combine,

00:07:51.630 --> 00:07:56.060
and you can look at the SpamAssassin
website to see a common set of features.

00:07:59.169 --> 00:08:03.290
So in summary,
Naive Bayes is actually not that naive.

00:08:03.290 --> 00:08:04.960
It's a very fast algorithm.

00:08:04.960 --> 00:08:07.190
It has low storage requirements.

00:08:07.190 --> 00:08:10.540
It's pretty robust to irrelevant features,
they tend to cancel each other out.

00:08:11.830 --> 00:08:15.690
It works well in domains where you have
lots of equally important features.

00:08:15.690 --> 00:08:18.430
And this turns out to be a problem for
some other classifiers.

00:08:18.430 --> 00:08:22.633
In particular, decision trees, which
have some advantages in numeric domains,

00:08:22.633 --> 00:08:25.706
don't work well if lots of
features are equally important.

00:08:29.919 --> 00:08:33.948
If the independence assumptions hold,
if the asssumed independence is correct,

00:08:33.948 --> 00:08:37.934
then it turns out that Naive Bayes is in
fact the optimal classifier for a problem.

00:08:37.934 --> 00:08:42.100
Of course, that's rare that these
independence assumptions are really true,

00:08:42.100 --> 00:08:43.630
but if they happen to be true or

00:08:43.630 --> 00:08:46.708
close to true, it turns out
Naive Bayes is in fact optimal.

00:08:46.708 --> 00:08:47.719
And in general,

00:08:47.719 --> 00:08:52.203
Naive Bayes is just a good dependable
baseline for text classification,

00:08:52.203 --> 00:08:56.630
although we will see other classifiers
that give much better accuracy.

