WEBVTT
Kind: captions
Language: en

00:00:00.610 --> 00:00:04.710
In our baseline algorithm we used all
the words to do Sentiment Analysis.

00:00:04.710 --> 00:00:07.530
But well, there's lots of information
about which words have which kind

00:00:07.530 --> 00:00:10.580
of sentiment that we might
want to make use of in addition.

00:00:10.580 --> 00:00:11.990
And, these are called sentiment lexicons.

00:00:13.580 --> 00:00:16.760
One sentiment lexicon is
the General Inquirer.

00:00:16.760 --> 00:00:19.704
It's been around for
quite a long time, since 1966.

00:00:21.000 --> 00:00:24.340
And I pointed you here
at the Home page and

00:00:24.340 --> 00:00:27.500
the list of categories for
the General Inquirer.

00:00:27.500 --> 00:00:30.000
And you can see the spreadsheet
that lists all the words.

00:00:31.600 --> 00:00:35.378
Let's go look at the General Inquirer.

00:00:35.378 --> 00:00:40.825
So, here's the General Inquirer
categories and here, for example,

00:00:40.825 --> 00:00:49.020
you can see, Make this a little larger.

00:00:49.020 --> 00:00:53.330
Here you can see Positiv and
Negativ lists of words.

00:00:53.330 --> 00:00:54.220
Let's go look at one of them.

00:00:54.220 --> 00:00:55.400
Let's look at the Positiv list.

00:00:58.260 --> 00:01:01.390
So, here's some lists of words.

00:01:01.390 --> 00:01:05.400
Ability, Abide, Able,
Abound, Absolve, and so on.

00:01:05.400 --> 00:01:09.210
So, here's Positiv words
from this sentiment list.

00:01:14.100 --> 00:01:16.576
So, in addition to Positiv and Negativ,

00:01:16.576 --> 00:01:21.270
the General Inquirer also has lots of
other lists of kinds of classes or words.

00:01:21.270 --> 00:01:25.522
Strong vs Weak, Overstated versus
Understated, words about Pleasure,

00:01:25.522 --> 00:01:28.770
Cognitive Orientation,
all sorts of other words.

00:01:28.770 --> 00:01:32.450
So, we can use it not just for
the simple polarity questions that we're

00:01:32.450 --> 00:01:35.830
talking about right now, but
more rich sentiment kind of questions.

00:01:38.430 --> 00:01:40.528
LIWC, the Linguistic Inquiry and
Word Count,

00:01:40.528 --> 00:01:46.070
is a database developed by
James Pennebaker and his colleagues.

00:01:46.070 --> 00:01:48.000
And here we have lots of classes,

00:01:48.000 --> 00:01:52.300
70 classes of words talking about
negative emotion or positive emotion.

00:01:52.300 --> 00:01:56.760
Words like bad, or weird, or hate,
Cognitive Processes, all the Pronouns,

00:01:56.760 --> 00:01:59.050
first person, second person Pronouns.

00:01:59.050 --> 00:02:03.660
Words having to do with Negation,
like no or never, Quantifiers, and so on.

00:02:03.660 --> 00:02:05.513
And LIWC has a small charge but

00:02:05.513 --> 00:02:09.978
has a large list of words that people
often use for sentiment analysis.

00:02:09.978 --> 00:02:15.378
The MPQA Subjectivity Cues Lexicon
by Wilson and

00:02:15.378 --> 00:02:18.938
Wiebe, and their colleagues.

00:02:18.938 --> 00:02:22.125
Gives you, again,
a list of polarity items,

00:02:22.125 --> 00:02:24.998
your positive words and negative words.

00:02:24.998 --> 00:02:29.426
And words in this lexicon are also
annotated for intensity, for

00:02:29.426 --> 00:02:31.478
how strong and weak they are.

00:02:31.478 --> 00:02:36.954
Another polarity lexicon that's available
on the web is Bing Liu's Opinion Lexicon,

00:02:36.954 --> 00:02:38.878
and I've pointed you at that.

00:02:38.878 --> 00:02:42.170
Again, another list of positive or
negative words.

00:02:44.940 --> 00:02:46.940
Finally, we haven't talked about WordNet.

00:02:46.940 --> 00:02:51.190
We'll talk about WordNet later, but
WordNet is an online thesaurus, and

00:02:51.190 --> 00:02:54.890
the entries in WordNet have also
been labelled for their polarity.

00:02:55.900 --> 00:03:00.440
So for example,
the word estimable "may be computed or

00:03:00.440 --> 00:03:05.270
estimated", is labeled
as neither Positive or

00:03:05.270 --> 00:03:10.370
Negative, but
Objective in the SentiWordNet.

00:03:10.370 --> 00:03:14.460
But the word estimable, meaning
"deserving of respect or high regard",

00:03:14.460 --> 00:03:19.660
that's a mostly Positive, although
sometimes not, sometimes Objective word.

00:03:19.660 --> 00:03:23.020
So we can see that each word
gets a label for how Positive,

00:03:23.020 --> 00:03:25.390
Negative, or Objective it is.

00:03:25.390 --> 00:03:27.610
And again, you can go look at that here,

00:03:27.610 --> 00:03:30.930
and you have to fill out
a form to download that.

00:03:30.930 --> 00:03:33.280
And we'll talk about
WordNet itself a bit later.

00:03:35.180 --> 00:03:37.360
So each of these lexicons
has different things in it.

00:03:38.480 --> 00:03:42.310
But, they overlap in all
talking about polarity.

00:03:42.310 --> 00:03:48.770
And Chris Potts ran a lovely correlation
between these, looking at whether

00:03:48.770 --> 00:03:52.330
the polarity, if a word is in multiple
lexicons, does it have the same polarity?

00:03:52.330 --> 00:03:56.440
And you can see that,
with the exception of SentiWordNet,

00:03:56.440 --> 00:04:01.830
which has a whole lot of different things
going on in it, in general, if a word

00:04:01.830 --> 00:04:07.590
is in multiple lexicons, the disagreements
between the lexicons are very small.

00:04:07.590 --> 00:04:13.000
So most of the time for
the Opinion Lexicon,

00:04:13.000 --> 00:04:17.410
the General Inquirer lexicon, for
LIWC, for the MPQA, in general, for

00:04:17.410 --> 00:04:21.980
all of these you find pretty similar
sentiments if you're just doing polarity.

00:04:21.980 --> 00:04:24.489
Obviously, if you're doing more
complicated things then they're going to

00:04:24.489 --> 00:04:25.098
start to differ.

00:04:29.258 --> 00:04:35.360
We might want to look at each of words and
talk about what the polarity is of words.

00:04:35.360 --> 00:04:38.528
Like, words that we get from these
lexicons if we're looking at a database

00:04:38.528 --> 00:04:39.041
like IMDB.

00:04:39.041 --> 00:04:41.770
And there's some nice research
by Chris Pott's looking at this.

00:04:41.770 --> 00:04:43.179
So, he asked the question,

00:04:43.179 --> 00:04:46.075
how likely is each word to
appear in each sentiment class?

00:04:46.075 --> 00:04:48.430
And let's look at IMDB
where there's 10-stars.

00:04:48.430 --> 00:04:52.810
So, a word like bad could appear in
1-star reviews with a certain count,

00:04:52.810 --> 00:04:56.510
2-star reviews with a certain count,
3-star, and so on.

00:04:57.720 --> 00:05:02.010
Can we use that to understand what's
the sentiment of that word bad,

00:05:02.010 --> 00:05:06.750
just by counting how often it occurs in
different reviews of different stars.

00:05:06.750 --> 00:05:09.390
And as he pointed out,
you can't just use raw counts.

00:05:10.440 --> 00:05:14.515
Here, this shows you, along the x-axis,
as we look at the different categories so

00:05:14.515 --> 00:05:17.778
1-star, 2-star, 3-star, 10-star.

00:05:17.778 --> 00:05:21.650
And here's the count of times that the
word bad occurs, the adjective bad occurs.

00:05:21.650 --> 00:05:24.770
And you can see it's
mostly in 1-star reviews.

00:05:24.770 --> 00:05:29.030
But it actually occurs more often in
10-star reviews than in 2-star reviews,

00:05:29.030 --> 00:05:32.740
which seems like a problem because bad
should be really, a negative word.

00:05:32.740 --> 00:05:37.139
But that's because there are just a lot
more 9 and 10-star reviews, or 8 and

00:05:37.139 --> 00:05:40.130
10-star reviews than
there are 2-star reviews.

00:05:40.130 --> 00:05:43.360
It turns out that reviews
tend to skew positive.

00:05:44.460 --> 00:05:46.330
So we can't use the raw counts.

00:05:46.330 --> 00:05:48.432
Instead, we're going to
use the likelihood.

00:05:48.432 --> 00:05:52.139
We're going to take the frequency
of the word in the class and

00:05:52.139 --> 00:05:56.310
we're going to divide it by the total
number of words in that class.

00:05:56.310 --> 00:05:59.649
And that will solve the problem of
classes like 9 and 10, in general,

00:05:59.649 --> 00:06:03.670
being bigger, because we're computing the
likelihood condition on the class size.

00:06:06.070 --> 00:06:08.970
Now, an additional thing we often
want to do is compare these numbers for

00:06:08.970 --> 00:06:10.090
different words.

00:06:10.090 --> 00:06:12.600
Some words are very frequent,
some words are less frequent.

00:06:12.600 --> 00:06:17.310
And so to do this, we want to do a scale
of likelihood where we take the likelihood

00:06:17.310 --> 00:06:20.880
of the word given the class and just
divide by the probability of the word.

00:06:20.880 --> 00:06:22.610
So now,
if a word is particularly frequent or

00:06:22.610 --> 00:06:25.870
particularly rare,
we can still compare them with each other.

00:06:25.870 --> 00:06:27.509
So we compute the scale of likelihoods.

00:06:29.320 --> 00:06:33.638
And if you look at that, we can see,
here's the word good or the word amazing.

00:06:33.638 --> 00:06:38.742
We can see that as for amazing,
as review numbers, as the stars go up from

00:06:38.742 --> 00:06:44.538
1-star to 10-star, the word is much
more frequently use as we get higher up.

00:06:44.538 --> 00:06:48.338
For great, similarly, or
not strong as amazing.

00:06:48.338 --> 00:06:54.878
For awesome, again, we see a very sharp
rise in its use for 10-star reviews.

00:06:54.878 --> 00:06:58.270
For good, it turns out to be
used mostly in the middle.

00:06:58.270 --> 00:07:01.020
A good movie is not great,
and it's not terrible, and

00:07:01.020 --> 00:07:02.550
that's what we might
expect from the word good.

00:07:03.750 --> 00:07:07.005
And similarly for bad reviews.

00:07:07.005 --> 00:07:10.725
So again, a word like depressed,
more often,

00:07:10.725 --> 00:07:13.715
are going to occur in these negative
reviews, the 1, 2, and 3 reviews.

00:07:13.715 --> 00:07:17.865
A word like bad, again, occurring
in these 1, 2, and 3-star reviews.

00:07:17.865 --> 00:07:20.405
Terrible, in these 1,
2, and 3-star reviews.

00:07:20.405 --> 00:07:25.928
So we can look at, along the x-axis,
the review quality 1 through 10 and

00:07:25.928 --> 00:07:31.130
along the y-axis the scale likelihood
to see the polarity of the word.

00:07:33.560 --> 00:07:40.960
So Potts also asked whether we can see
sentiment in other words than good or bad.

00:07:40.960 --> 00:07:44.870
He looked at logical negation,
words like no,

00:07:44.870 --> 00:07:49.720
not, never and the n't of isn't,
and didn't, and so on.

00:07:49.720 --> 00:07:51.540
Are those associated
with negative sentiment?

00:07:51.540 --> 00:07:56.700
Now, what he did, again, is he
counted negation in online reviews and

00:07:56.700 --> 00:08:00.398
looked at them,
how they matched the review rating

00:08:03.278 --> 00:08:07.176
And just like the word bad or
the word terrible,

00:08:07.176 --> 00:08:12.437
you can see that these negation
words like no, not, never occur

00:08:12.437 --> 00:08:18.480
more frequently in these low star reviews,
either in the IMDB database or

00:08:18.480 --> 00:08:22.890
other databases which
are only from 1 to 5-stars.

00:08:22.890 --> 00:08:27.550
So, in these lexicons, we can see lots
of words are positive and negative.

00:08:27.550 --> 00:08:30.680
But there might be more sophisticated
features like, let's say,

00:08:30.680 --> 00:08:35.110
this kind of logical negation
also is a good cue for sentiment.

